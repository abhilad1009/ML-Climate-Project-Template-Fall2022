{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kits_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TRVZ5_G7k8O0",
        "yDxrOSrmhynQ",
        "H8vZZKWph7-p"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84874918c30d4acd882cdc6b722ec2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_71cddd069aca437c9aef7a564a12b96b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9390b98724943569395f1f83fa338d5",
              "IPY_MODEL_0c9fdaa2c5aa400b8ef2e58644667be9",
              "IPY_MODEL_39abfe6d73064765b920117ea0ceeba8"
            ]
          }
        },
        "71cddd069aca437c9aef7a564a12b96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d9390b98724943569395f1f83fa338d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f3f51c736084f119fec200bc566c855",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87d5b5228a3b4b4bb686a31527bf7f15"
          }
        },
        "0c9fdaa2c5aa400b8ef2e58644667be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_34bcb4b2ef934ade9ee01aea741da72c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcf90d17b6ee4242b39222babd2109fa"
          }
        },
        "39abfe6d73064765b920117ea0ceeba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39e0ab0884104b1dae45d7809f8142c3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_738f6cbc33d9401d8465eb71c9b3f74f"
          }
        },
        "6f3f51c736084f119fec200bc566c855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87d5b5228a3b4b4bb686a31527bf7f15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34bcb4b2ef934ade9ee01aea741da72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcf90d17b6ee4242b39222babd2109fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39e0ab0884104b1dae45d7809f8142c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "738f6cbc33d9401d8465eb71c9b3f74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRVZ5_G7k8O0"
      },
      "source": [
        "# data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZBgYcS0fPvq",
        "outputId": "02cc8fc7-dd61-4c0e-f1f0-fc6456a5a0d2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfNTQ0OpfYnY"
      },
      "source": [
        "import os, json, pandas as pd, numpy as np\n",
        "np.random.seed(42)\n",
        "file_list = list(os.listdir('drive/MyDrive/kits_split'))\n",
        "np.random.shuffle(file_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpAleBW8fYZo",
        "outputId": "245b7b12-fa01-4c1c-ea20-6e0017a58a4f"
      },
      "source": [
        "cases = list(range(300))\n",
        "np.random.shuffle(cases)\n",
        "train_set = cases[:int(len(cases)*0.8)]\n",
        "val_set = cases[int(len(cases)*0.8):]\n",
        "print(len(train_set), len(val_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "240 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wJABm0_gc4_",
        "outputId": "6690ef85-b7cd-4685-a5a5-3990d06baf95"
      },
      "source": [
        "train_set = [\"case_\"+str(\"00000\"+str(i))[-5:] for i in train_set]\n",
        "val_set = [\"case_\"+str(\"00000\"+str(i))[-5:] for i in val_set]\n",
        "train_filenames = [i for i in file_list if i[:10] in train_set]\n",
        "val_filenames = [i for i in file_list if i[:10] in val_set]\n",
        "print(train_filenames[:5], val_filenames[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['case_00276_adj_6_seg.nii.gz', 'case_00071_adj_6_img.nii.gz', 'case_00151_random_5_img.nii.gz', 'case_00213_adj_1_seg.nii.gz', 'case_00103_adj_9_seg.nii.gz'] ['case_00293_random_4_seg.nii.gz', 'case_00063_adj_3_seg.nii.gz', 'case_00091_random_0_img.nii.gz', 'case_00086_adj_2_img.nii.gz', 'case_00091_random_3_seg.nii.gz']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D3fsRlwi02_"
      },
      "source": [
        "json.dump({\"train_files\":train_filenames, \"val_files\":val_filenames}, open(\"drive/MyDrive/kits_training_split.json\", \"w\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDxrOSrmhynQ"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gcFaApAhwOv"
      },
      "source": [
        "!pip install torchio[plot]\n",
        "!pip install -q monai==0.5.2\n",
        "!pip install -q pytorch-lightning==1.2.10\n",
        "!pip install -q gdown==3.6.4 matplotlib==3.2.2 pandas==1.1.5 seaborn==0.11.1\n",
        "!git clone https://github.com/srg9000/surface-distance.git\n",
        "!pip install surface-distance/ --force-reinstall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhdhinZAh9UC"
      },
      "source": [
        "# Fetch Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkJ_4QDXiAW7"
      },
      "source": [
        "!cp -r ./drive/MyDrive/kits_split/ .\n",
        "!cp ./drive/MyDrive/kits_training_split.json ."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8vZZKWph7-p"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqoa0q1qh7ZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056f7c8f-392c-464a-e2ac-1beb3982d6f1"
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import random_split, DataLoader, Dataset\n",
        "import monai\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import torchio as tio\n",
        "# import surface_distance\n",
        "import pytorch_lightning as pl\n",
        "import gc\n",
        "# from surface_distance import compute_surface_distances\n",
        "import seaborn as sns; sns.set()\n",
        "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "torch.manual_seed(14041931)\n",
        "print('TorchIO version:', tio.__version__)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TorchIO version: 0.18.47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKGdD3w8kFOR"
      },
      "source": [
        "# Data loader and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry_4dgeVyoiB"
      },
      "source": [
        "file_data = json.load(open('kits_training_split.json'))\n",
        "train_filenames = file_data['train_files']\n",
        "val_filenames = file_data['val_files']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyF_B4DKvyPy"
      },
      "source": [
        "class KitsDataset(Dataset, pl.LightningDataModule):\n",
        "    def __init__(self, root_dir, filenames, mode):\n",
        "        self.root_dir = root_dir\n",
        "        self.filenames = filenames\n",
        "        self.data = self.filenames # list(os.listdir(self.root_dir))\n",
        "        self.data_input = [i for i in self.data if 'img' in i]\n",
        "        self.data_labels = [i.replace('img', 'seg') for i in self.data_input]\n",
        "        self.mode = mode\n",
        "        self.preprocess = self.get_preprocessing_transform()\n",
        "        self.augment = self.get_augmentation_transform()\n",
        "        if mode == 'train':\n",
        "            self.transform = tio.Compose([self.preprocess, self.augment])\n",
        "        else:\n",
        "            self.transform = self.preprocess\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def get_preprocessing_transform(self):\n",
        "        preprocess = tio.Compose([\n",
        "            tio.RescaleIntensity((-1, 1)),\n",
        "            # tio.CropOrPad((512, 512)),\n",
        "            tio.EnsureShapeMultiple(8),  # for the U-Net\n",
        "            tio.OneHot(num_classes=4),\n",
        "            \n",
        "        ])\n",
        "        return preprocess\n",
        "        \n",
        "    def get_augmentation_transform(self):\n",
        "        augment = tio.Compose([\n",
        "            tio.RandomAffine(p=0.2),\n",
        "            tio.RandomGamma(p=0.4),\n",
        "            tio.RandomNoise(p=0.4),\n",
        "            tio.OneOf([\n",
        "                tio.RandomMotion(p=0.3),\n",
        "                tio.RandomBiasField(p=0.25),\n",
        "                tio.RandomGhosting(p=0.2)\n",
        "            ]),\n",
        "            tio.OneOf([\n",
        "                tio.RandomMotion(p=0.2),\n",
        "                tio.RandomSpike(p=0.2)\n",
        "            ])\n",
        "        ])\n",
        "        return augment\n",
        "\n",
        "    def __getitem__(self, idxs):\n",
        "        subjects = []\n",
        "        if isinstance(idxs, int):\n",
        "            idxs = [idxs]\n",
        "        for idx in idxs:\n",
        "            if self.mode == 'test':\n",
        "                subject = tio.Subject(\n",
        "                    image=tio.ScalarImage(self.root_dir+self.data_input[idx])\n",
        "                )\n",
        "            else:\n",
        "                subject = tio.Subject(\n",
        "                    image=tio.ScalarImage(self.root_dir+self.data_input[idx]),\n",
        "                    label=tio.LabelMap(self.root_dir+self.data_labels[idx])\n",
        "                )\n",
        "            subjects.append(subject)\n",
        "        return subjects[0]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_roCPqGikIpr"
      },
      "source": [
        "# Create custom dataloader, load all files dynamically\n",
        "class KitsDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, root_dir='./kits_split/', batch_size=4, train_filenames=[], val_filenames=[]):\n",
        "        super().__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.train_filenames = train_filenames\n",
        "        self.val_filenames = val_filenames\n",
        "        self.test_filenames = val_filenames\n",
        "        self.train_set = KitsDataset(self.root_dir, self.train_filenames, mode='train')\n",
        "        self.val_set = KitsDataset(self.root_dir, self.val_filenames, mode='val')\n",
        "        self.test_set = KitsDataset(self.root_dir, self.val_filenames, mode='test')\n",
        "\n",
        "    # def get_preprocessing_transform(self):\n",
        "    #     preprocess = tio.Compose([\n",
        "    #         tio.RescaleIntensity((-1, 1)),\n",
        "    #         tio.CropOrPad(self.get_max_shape(self.subjects + self.test_subjects)),\n",
        "    #         tio.EnsureShapeMultiple(8),  # for the U-Net\n",
        "    #         tio.OneHot(),\n",
        "    #     ])\n",
        "    #     return preprocess\n",
        "    \n",
        "    # def get_augmentation_transform(self):\n",
        "    #     augment = tio.Compose([\n",
        "    #         tio.RandomAffine(),\n",
        "    #         # tio.RandomGamma(p=0.5),\n",
        "    #         # tio.RandomNoise(p=0.5),\n",
        "    #         # tio.RandomMotion(p=0.1),\n",
        "    #         # tio.RandomBiasField(p=0.25),\n",
        "    #     ])\n",
        "    #     return augment\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_set, self.batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_set, self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_set, self.batch_size)\n",
        "    "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMnPz4M5yTOY"
      },
      "source": [
        "data = KitsDataModule(\n",
        "    root_dir='./kits_split/',\n",
        "    train_filenames = train_filenames,\n",
        "    val_filenames = val_filenames,    \n",
        "    batch_size=4\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj7xREbfkWG0"
      },
      "source": [
        "# Model definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkh4FPsskYA6"
      },
      "source": [
        "# https://github.com/luuuyi/CBAM.PyTorch/blob/master/model/resnet_cbam.py\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, submodule, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.submodule = submodule\n",
        "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool3d(1)\n",
        "           \n",
        "        self.fc = nn.Sequential(nn.Conv3d(in_planes, in_planes // 16, 1, bias=False),\n",
        "                               nn.ReLU(),\n",
        "                               nn.Conv3d(in_planes // 16, in_planes, 1, bias=False))\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.submodule(x)\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "        print(\"CA output = \", out.shape, flush=True)\n",
        "        return y*self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, submodule, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.submodule = submodule\n",
        "        self.conv1 = nn.Conv3d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.conv2 = nn.Conv3d(4, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.submodule(x)\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        # x = self.gelu(x)\n",
        "        # x = self.conv2(x)\n",
        "        return y*self.sigmoid(x)\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_c=32, out_c=32, kernel_size=3, activation=nn.GELU):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv3d(n_c, out_c, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.batchnorm = nn.BatchNorm3d(out_c)\n",
        "        self.activation = activation()\n",
        "        self.conv2 = nn.Conv3d(out_c, out_c, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.batchnorm2 = nn.BatchNorm3d(out_c)\n",
        "        self.activation2 = activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.activation2(x)\n",
        "        return x"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvPK0w84kgvh"
      },
      "source": [
        "# Copyright 2020 - 2021 MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import warnings\n",
        "from typing import Sequence, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from monai.networks.blocks.convolutions import Convolution, ResidualUnit\n",
        "from monai.networks.layers.factories import Act, Norm\n",
        "from monai.networks.layers.simplelayers import SkipConnection\n",
        "from monai.utils import alias, export\n",
        "\n",
        "__all__ = [\"UNet\", \"Unet\", \"unet\"]\n",
        "\n",
        "\n",
        "@export(\"monai.networks.nets\")\n",
        "@alias(\"Unet\")\n",
        "class UNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dimensions: int,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        channels: Sequence[int],\n",
        "        strides: Sequence[int],\n",
        "        kernel_size: Union[Sequence[int], int] = 3,\n",
        "        up_kernel_size: Union[Sequence[int], int] = 3,\n",
        "        num_res_units: int = 0,\n",
        "        act: Union[Tuple, str] = Act.PRELU,\n",
        "        norm: Union[Tuple, str] = Norm.INSTANCE,\n",
        "        dropout=0.0,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Enhanced version of UNet which has residual units implemented with the ResidualUnit class.\n",
        "        The residual part uses a convolution to change the input dimensions to match the output dimensions\n",
        "        if this is necessary but will use nn.Identity if not.\n",
        "        Refer to: https://link.springer.com/chapter/10.1007/978-3-030-12029-0_40.\n",
        "\n",
        "        Args:\n",
        "            dimensions: number of spatial dimensions.\n",
        "            in_channels: number of input channels.\n",
        "            out_channels: number of output channels.\n",
        "            channels: sequence of channels. Top block first. The length of `channels` should be no less than 2.\n",
        "            strides: sequence of convolution strides. The length of `stride` should equal to `len(channels) - 1`.\n",
        "            kernel_size: convolution kernel size, the value(s) should be odd. If sequence,\n",
        "                its length should equal to dimensions. Defaults to 3.\n",
        "            up_kernel_size: upsampling convolution kernel size, the value(s) should be odd. If sequence,\n",
        "                its length should equal to dimensions. Defaults to 3.\n",
        "            num_res_units: number of residual units. Defaults to 0.\n",
        "            act: activation type and arguments. Defaults to PReLU.\n",
        "            norm: feature normalization type and arguments. Defaults to instance norm.\n",
        "            dropout: dropout ratio. Defaults to no dropout.\n",
        "\n",
        "        Note: The acceptable spatial size of input data depends on the parameters of the network,\n",
        "            to set appropriate spatial size, please check the tutorial for more details:\n",
        "            https://github.com/Project-MONAI/tutorials/blob/master/modules/UNet_input_size_constrains.ipynb.\n",
        "            Typically, when using a stride of 2 in down / up sampling, the output dimensions are either half of the\n",
        "            input when downsampling, or twice when upsampling. In this case with N numbers of layers in the network,\n",
        "            the inputs must have spatial dimensions that are all multiples of 2^N.\n",
        "            Usually, applying `resize`, `pad` or `crop` transforms can help adjust the spatial size of input data.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        if len(channels) < 2:\n",
        "            raise ValueError(\n",
        "                \"the length of `channels` should be no less than 2.\")\n",
        "        delta = len(strides) - (len(channels) - 1)\n",
        "        if delta < 0:\n",
        "            raise ValueError(\n",
        "                \"the length of `strides` should equal to `len(channels) - 1`.\")\n",
        "        if delta > 0:\n",
        "            warnings.warn(f\"`len(strides) > len(channels) - 1`, the last {delta} values of strides will not be used.\")\n",
        "        if isinstance(kernel_size, Sequence):\n",
        "            if len(kernel_size) != dimensions:\n",
        "                raise ValueError(\n",
        "                    \"the length of `kernel_size` should equal to `dimensions`.\")\n",
        "        if isinstance(up_kernel_size, Sequence):\n",
        "            if len(up_kernel_size) != dimensions:\n",
        "                raise ValueError(\n",
        "                    \"the length of `up_kernel_size` should equal to `dimensions`.\")\n",
        "\n",
        "        self.dimensions = dimensions\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.channels = channels\n",
        "        self.strides = strides\n",
        "        self.kernel_size = kernel_size\n",
        "        self.up_kernel_size = up_kernel_size\n",
        "        self.num_res_units = num_res_units\n",
        "        self.act = act\n",
        "        self.norm = norm\n",
        "        self.dropout = dropout\n",
        "        # self.ca1 = ChannelAttention(16)\n",
        "        # self.ca1 = ChannelAttention(16)\n",
        "        # self.sa1 = SpatialAttention()\n",
        "        # self.sa2 = SpatialAttention()\n",
        "        # self.sa3 = SpatialAttention()\n",
        "\n",
        "        def _create_block(\n",
        "            inc: int,\n",
        "            outc: int,\n",
        "            channels: Sequence[int],\n",
        "            strides: Sequence[int],\n",
        "            is_top: bool) -> nn.Sequential:\n",
        "            \"\"\"\n",
        "            Builds the UNet structure from the bottom up by recursing down to the bottom block, then creating sequential\n",
        "            blocks containing the downsample path, a skip connection around the previous block, and the upsample path.\n",
        "\n",
        "            Args:\n",
        "                inc: number of input channels.\n",
        "                outc: number of output channels.\n",
        "                channels: sequence of channels. Top block first.\n",
        "                strides: convolution stride.\n",
        "                is_top: True if this is the top block.\n",
        "            \"\"\"\n",
        "            c = channels[0]\n",
        "            s = strides[0]\n",
        "\n",
        "            subblock: nn.Module\n",
        "            if len(channels) > 2:\n",
        "                # continue recursion down\n",
        "                subblock = _create_block(\n",
        "                    c, c, channels[1:], strides[1:], False)\n",
        "                subblock = SpatialAttention(subblock)\n",
        "                upc = c * 2\n",
        "            else:\n",
        "                # the next layer is the bottom so stop recursion, create the bottom layer as the sublock for this layer\n",
        "                subblock = self._get_bottom_layer(c, channels[1])\n",
        "                subblock = ChannelAttention(subblock, in_planes=c)\n",
        "                upc = c + channels[1]\n",
        "\n",
        "            # create layer in downsampling path\n",
        "            down = self._get_down_layer(inc, c, s, is_top)\n",
        "            # create layer in upsampling path\n",
        "            up = self._get_up_layer(upc, outc, s, is_top)\n",
        "            return nn.Sequential(down, SkipConnection(subblock), up)\n",
        "\n",
        "        self.model = _create_block(\n",
        "            in_channels, out_channels, self.channels, self.strides, True)\n",
        "\n",
        "    def _get_down_layer(self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        strides: int,\n",
        "        is_top: bool) -> nn.Module:\n",
        "        \"\"\" \n",
        "        Args:\n",
        "            in_channels: number of input channels.\n",
        "            out_channels: number of output channels.\n",
        "            strides: convolution stride.\n",
        "            is_top: True if this is the top block.\n",
        "        \"\"\"\n",
        "        if self.num_res_units > 0:\n",
        "            return ResidualUnit(\n",
        "                self.dimensions,\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                strides=strides,\n",
        "                kernel_size=self.kernel_size,\n",
        "                subunits=self.num_res_units,\n",
        "                act=self.act,\n",
        "                norm=self.norm,\n",
        "                dropout=self.dropout,\n",
        "            )\n",
        "        return Convolution(\n",
        "            self.dimensions,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            strides=strides,\n",
        "            kernel_size=self.kernel_size,\n",
        "            act=self.act,\n",
        "            norm=self.norm,\n",
        "            dropout=self.dropout,\n",
        "        )\n",
        "\n",
        "    def _get_bottom_layer(self, in_channels: int, out_channels: int) -> nn.Module:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_channels: number of input channels.\n",
        "            out_channels: number of output channels.\n",
        "        \"\"\"\n",
        "        return self._get_down_layer(in_channels, out_channels, 1, False)\n",
        "\n",
        "    def _get_up_layer(self, in_channels: int, out_channels: int, strides: int, is_top: bool) -> nn.Module:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_channels: number of input channels.\n",
        "            out_channels: number of output channels.\n",
        "            strides: convolution stride.\n",
        "            is_top: True if this is the top block.\n",
        "        \"\"\"\n",
        "        conv: Union[Convolution, nn.Sequential]\n",
        "\n",
        "        conv = Convolution(\n",
        "            self.dimensions,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            strides=strides,\n",
        "            kernel_size=self.up_kernel_size,\n",
        "            act=self.act,\n",
        "            norm=self.norm,\n",
        "            dropout=self.dropout,\n",
        "            conv_only=is_top and self.num_res_units == 0,\n",
        "            is_transposed=True,\n",
        "        )\n",
        "\n",
        "        if self.num_res_units > 0:\n",
        "            ru = ResidualUnit(\n",
        "                self.dimensions,\n",
        "                out_channels,\n",
        "                out_channels,\n",
        "                strides=1,\n",
        "                kernel_size=self.kernel_size,\n",
        "                subunits=1,\n",
        "                act=self.act,\n",
        "                norm=self.norm,\n",
        "                dropout=self.dropout,\n",
        "                last_conv_only=is_top,\n",
        "            )\n",
        "            conv = nn.Sequential(conv, ru)\n",
        "\n",
        "        return conv\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "Unet = unet = UNet\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tLhv-QpknPD"
      },
      "source": [
        "class Model(pl.LightningModule):\n",
        "    def __init__(self, net, criterion, learning_rate, optimizer_class):\n",
        "        super().__init__()\n",
        "        self.lr = learning_rate\n",
        "        self.net = net\n",
        "        self.criterion = criterion\n",
        "        self.optimizer_class = optimizer_class\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = self.optimizer_class(self.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "    \n",
        "    def prepare_batch(self, batch):\n",
        "        print(batch)\n",
        "        return batch['image']['data'], batch['label']['data']\n",
        "    \n",
        "    def infer_batch(self, batch):\n",
        "        x, y = self.prepare_batch(batch)\n",
        "        y_hat = self.net(x)\n",
        "        return y_hat, y\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        print(batch)\n",
        "        y_hat, y = self.infer_batch(batch)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        print(batch)\n",
        "        y_hat, y = self.infer_batch(batch)\n",
        "        loss = self.criterion(y_hat, y)\n",
        "        self.log('val_loss', loss)\n",
        "        return loss"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm4CY5wUknMR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8583d540-1cb2-47be-98e3-d2984f2d5591"
      },
      "source": [
        "unet = UNet(\n",
        "    dimensions=3,\n",
        "    in_channels=1,\n",
        "    out_channels=3,\n",
        "    channels=(8, 16, 32, 16),\n",
        "    strides=(2, 2, 2), \n",
        ")\n",
        "\n",
        "# TODO: Create custom criterion / use multiple\n",
        "model = Model(\n",
        "    net=unet,\n",
        "    criterion=monai.losses.DiceCELoss(softmax=True),\n",
        "    learning_rate=1e-3,\n",
        "    optimizer_class=torch.optim.AdamW,\n",
        ")\n",
        "\n",
        "early_stopping = pl.callbacks.early_stopping.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    # gpus=1,\n",
        "    # precision=16,\n",
        "    callbacks=[early_stopping],\n",
        "    # amp_backend = ,\n",
        ")\n",
        "\n",
        "trainer.logger._default_hp_metric = False"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rebohytHl9hr"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PTYhsUml_Xz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640,
          "referenced_widgets": [
            "84874918c30d4acd882cdc6b722ec2e7",
            "71cddd069aca437c9aef7a564a12b96b",
            "d9390b98724943569395f1f83fa338d5",
            "0c9fdaa2c5aa400b8ef2e58644667be9",
            "39abfe6d73064765b920117ea0ceeba8",
            "6f3f51c736084f119fec200bc566c855",
            "87d5b5228a3b4b4bb686a31527bf7f15",
            "34bcb4b2ef934ade9ee01aea741da72c",
            "bcf90d17b6ee4242b39222babd2109fa",
            "39e0ab0884104b1dae45d7809f8142c3",
            "738f6cbc33d9401d8465eb71c9b3f74f"
          ]
        },
        "outputId": "49536fd8-b6a7-4ff4-b622-fe7829998d70"
      },
      "source": [
        "start = datetime.now()\n",
        "print('Training started at', start)\n",
        "trainer.fit(model=model, datamodule=data)\n",
        "print('Training duration:', datetime.now() - start)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name      | Type       | Params\n",
            "-----------------------------------------\n",
            "0 | net       | UNet       | 64.6 K\n",
            "1 | criterion | DiceCELoss | 0     \n",
            "-----------------------------------------\n",
            "64.6 K    Trainable params\n",
            "0         Non-trainable params\n",
            "64.6 K    Total params\n",
            "0.258     Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training started at 2021-08-18 06:28:29.225802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84874918c30d4acd882cdc6b722ec2e7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'image': {'path': ['kits_split/case_00091_random_0_img.nii.gz', 'kits_split/case_00086_adj_2_img.nii.gz', 'kits_split/case_00091_adj_8_img.nii.gz', 'kits_split/case_00091_adj_6_img.nii.gz'], 'stem': ['case_00091_random_0_img', 'case_00086_adj_2_img', 'case_00091_adj_8_img', 'case_00091_adj_6_img'], 'type': ['intensity', 'intensity', 'intensity', 'intensity']}, 'label': {'path': ['kits_split/case_00091_random_0_seg.nii.gz', 'kits_split/case_00086_adj_2_seg.nii.gz', 'kits_split/case_00091_adj_8_seg.nii.gz', 'kits_split/case_00091_adj_6_seg.nii.gz'], 'stem': ['case_00091_random_0_seg', 'case_00086_adj_2_seg', 'case_00091_adj_8_seg', 'case_00091_adj_6_seg'], 'type': ['label', 'label', 'label', 'label']}}\n",
            "{'image': {'path': ['kits_split/case_00091_random_0_img.nii.gz', 'kits_split/case_00086_adj_2_img.nii.gz', 'kits_split/case_00091_adj_8_img.nii.gz', 'kits_split/case_00091_adj_6_img.nii.gz'], 'stem': ['case_00091_random_0_img', 'case_00086_adj_2_img', 'case_00091_adj_8_img', 'case_00091_adj_6_img'], 'type': ['intensity', 'intensity', 'intensity', 'intensity']}, 'label': {'path': ['kits_split/case_00091_random_0_seg.nii.gz', 'kits_split/case_00086_adj_2_seg.nii.gz', 'kits_split/case_00091_adj_8_seg.nii.gz', 'kits_split/case_00091_adj_6_seg.nii.gz'], 'stem': ['case_00091_random_0_seg', 'case_00086_adj_2_seg', 'case_00091_adj_8_seg', 'case_00091_adj_6_seg'], 'type': ['label', 'label', 'label', 'label']}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-334060db7ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training started at'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training duration:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;31m# set stage for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sanity_val_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, max_batches, on_epoch)\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# capture any logged information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-71a8bc6a67ee>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-71a8bc6a67ee>\u001b[0m in \u001b[0;36minfer_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minfer_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-71a8bc6a67ee>\u001b[0m in \u001b[0;36mprepare_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minfer_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzU9CdZdx0oo"
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    }
  ]
}