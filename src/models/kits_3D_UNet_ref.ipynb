{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Monai of kits_download.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVCa_Ll0M2pm",
        "outputId": "b334003a-3090-4e87-cff8-635a05fd0b86"
      },
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "ModuleNotFoundError: No module named 'monai'\n",
            "\u001b[K     |████████████████████████████████| 642 kB 7.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrKEeulfOKtM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa112fa3-51d2-4cc9-9236-556ae0dde3ed"
      },
      "source": [
        "!pip install -q monai==0.6.0\n",
        "!pip install -q tqdm==4.59.0\n",
        "!pip install -q einops==0.3.0\n",
        "!pip install -q nibabel==3.1.1\n",
        "!pip install -q pytorch-lightning==1.4.0\n",
        "!pip install -q lightning-bolts==0.3.4\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 584 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 1.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 913 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 47.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 119 kB 44.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 282 kB 63.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 57.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 47.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 58.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 59.3 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 253 kB 5.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e47cnmoK6qRe"
      },
      "source": [
        "!pip install torchio[plot]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwK-6EzD76DS",
        "outputId": "5c8f42b2-b7f0-4d05-f504-2e63bc8e6ef9"
      },
      "source": [
        "!pip install -q monai==0.5.2\n",
        "!pip install -q pytorch-lightning==1.2.10\n",
        "!pip install -q gdown==3.6.4 matplotlib==3.2.2 pandas==1.1.5 seaborn==0.11.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 495 kB 9.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 841 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 176 kB 74.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 269 kB 72.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 119 kB 70.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 88.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 72.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 71.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 97.9 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYwuawFXsIl3"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyvvdKu6sGh1",
        "outputId": "1d5d406c-b69e-435a-99a5-d6098cfd76fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "import pathlib\n",
        "\n",
        "import os\n",
        "\n",
        "%cd ..\n",
        "%cd ./gdrive/MyDrive/kits21\n",
        "\n",
        "print(os.getcwd())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/\n",
            "/gdrive/MyDrive/kits21\n",
            "/gdrive/MyDrive/kits21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFLSbgJLSrpB",
        "outputId": "f26ce52d-ab1b-46cb-864d-3e1cabee7dc8"
      },
      "source": [
        "%cd ./MyDrive/kits21"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/kits21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDA8yUQCAZ1E"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a70hzbzrNAkY"
      },
      "source": [
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import (\n",
        "    AsDiscrete,\n",
        "    AsDiscreted,\n",
        "    EnsureChannelFirstd,\n",
        "    Compose,\n",
        "    CropForegroundd,\n",
        "    LoadImaged,\n",
        "    Orientationd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    ScaleIntensityRanged,\n",
        "    Spacingd,\n",
        "    EnsureTyped,\n",
        "    EnsureType,\n",
        "    Invertd,\n",
        "    RandAffined\n",
        ")\n",
        "# from monai.handlers.utils import \n",
        "from monai.networks.nets import UNet, UNETR, DynUNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss, DiceCELoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch,SmartCacheDataset\n",
        "from monai.config import print_config\n",
        "from monai.apps import download_and_extract\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmAE4qnIAbVb"
      },
      "source": [
        "import os, sys\n",
        "import numpy as np\n",
        "# import pandas as pd\n",
        "# import cv2\n",
        "# import matplotlib.pyplot as plt\n",
        "# import nibabel as nib\n",
        "# import torch\n",
        "# from torch.utils.data import random_split, DataLoader\n",
        "# import monai\n",
        "# # import gdown\n",
        "# from datetime import datetime\n",
        "# import pandas as pd\n",
        "# import torchio as tio\n",
        "# import pytorch_lightning as pl\n",
        "# import seaborn as sns; sns.set()\n",
        "# sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
        "# %config InlineBackend.figure_format = 'retina'\n",
        "# torch.manual_seed(14041931)\n",
        "# print('TorchIO version:', tio.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtr2FjlOzd2j"
      },
      "source": [
        "# preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfOOkUxdOyds"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfRmSkEHNOai",
        "outputId": "eba3d195-d176-4194-fa30-d242091687aa"
      },
      "source": [
        "root_data='kits21/data/'\n",
        "\n",
        "train_images=[]\n",
        "train_labels=[]\n",
        "for case in list(sorted(os.listdir(root_data))):\n",
        "        train_images.append(root_data+case+\"/imaging.nii.gz\"),\n",
        "        train_labels.append(root_data+case+\"/aggregated_AND_seg.nii.gz\")\n",
        "\n",
        "data_dicts = [\n",
        "    {\"image\": image_name, \"label\": label_name}\n",
        "    for image_name, label_name in zip(train_images, train_labels)\n",
        "]\n",
        "train_files, val_files = data_dicts[:], data_dicts[-9:]\n",
        "print(train_files)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'image': 'kits21/data/case_00000/imaging.nii.gz', 'label': 'kits21/data/case_00000/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00001/imaging.nii.gz', 'label': 'kits21/data/case_00001/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00002/imaging.nii.gz', 'label': 'kits21/data/case_00002/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00003/imaging.nii.gz', 'label': 'kits21/data/case_00003/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00004/imaging.nii.gz', 'label': 'kits21/data/case_00004/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00005/imaging.nii.gz', 'label': 'kits21/data/case_00005/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00006/imaging.nii.gz', 'label': 'kits21/data/case_00006/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00007/imaging.nii.gz', 'label': 'kits21/data/case_00007/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00008/imaging.nii.gz', 'label': 'kits21/data/case_00008/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00009/imaging.nii.gz', 'label': 'kits21/data/case_00009/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00010/imaging.nii.gz', 'label': 'kits21/data/case_00010/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00011/imaging.nii.gz', 'label': 'kits21/data/case_00011/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00012/imaging.nii.gz', 'label': 'kits21/data/case_00012/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00013/imaging.nii.gz', 'label': 'kits21/data/case_00013/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00014/imaging.nii.gz', 'label': 'kits21/data/case_00014/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00015/imaging.nii.gz', 'label': 'kits21/data/case_00015/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00016/imaging.nii.gz', 'label': 'kits21/data/case_00016/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00017/imaging.nii.gz', 'label': 'kits21/data/case_00017/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00018/imaging.nii.gz', 'label': 'kits21/data/case_00018/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00019/imaging.nii.gz', 'label': 'kits21/data/case_00019/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00020/imaging.nii.gz', 'label': 'kits21/data/case_00020/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00021/imaging.nii.gz', 'label': 'kits21/data/case_00021/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00022/imaging.nii.gz', 'label': 'kits21/data/case_00022/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00023/imaging.nii.gz', 'label': 'kits21/data/case_00023/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00024/imaging.nii.gz', 'label': 'kits21/data/case_00024/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00025/imaging.nii.gz', 'label': 'kits21/data/case_00025/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00026/imaging.nii.gz', 'label': 'kits21/data/case_00026/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00027/imaging.nii.gz', 'label': 'kits21/data/case_00027/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00028/imaging.nii.gz', 'label': 'kits21/data/case_00028/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00029/imaging.nii.gz', 'label': 'kits21/data/case_00029/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00030/imaging.nii.gz', 'label': 'kits21/data/case_00030/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00031/imaging.nii.gz', 'label': 'kits21/data/case_00031/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00032/imaging.nii.gz', 'label': 'kits21/data/case_00032/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00033/imaging.nii.gz', 'label': 'kits21/data/case_00033/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00034/imaging.nii.gz', 'label': 'kits21/data/case_00034/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00035/imaging.nii.gz', 'label': 'kits21/data/case_00035/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00036/imaging.nii.gz', 'label': 'kits21/data/case_00036/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00037/imaging.nii.gz', 'label': 'kits21/data/case_00037/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00038/imaging.nii.gz', 'label': 'kits21/data/case_00038/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00039/imaging.nii.gz', 'label': 'kits21/data/case_00039/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00040/imaging.nii.gz', 'label': 'kits21/data/case_00040/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00041/imaging.nii.gz', 'label': 'kits21/data/case_00041/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00042/imaging.nii.gz', 'label': 'kits21/data/case_00042/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00043/imaging.nii.gz', 'label': 'kits21/data/case_00043/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00044/imaging.nii.gz', 'label': 'kits21/data/case_00044/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00045/imaging.nii.gz', 'label': 'kits21/data/case_00045/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00046/imaging.nii.gz', 'label': 'kits21/data/case_00046/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00047/imaging.nii.gz', 'label': 'kits21/data/case_00047/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00048/imaging.nii.gz', 'label': 'kits21/data/case_00048/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00049/imaging.nii.gz', 'label': 'kits21/data/case_00049/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00050/imaging.nii.gz', 'label': 'kits21/data/case_00050/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00051/imaging.nii.gz', 'label': 'kits21/data/case_00051/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00052/imaging.nii.gz', 'label': 'kits21/data/case_00052/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00053/imaging.nii.gz', 'label': 'kits21/data/case_00053/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00054/imaging.nii.gz', 'label': 'kits21/data/case_00054/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00055/imaging.nii.gz', 'label': 'kits21/data/case_00055/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00056/imaging.nii.gz', 'label': 'kits21/data/case_00056/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00057/imaging.nii.gz', 'label': 'kits21/data/case_00057/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00058/imaging.nii.gz', 'label': 'kits21/data/case_00058/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00059/imaging.nii.gz', 'label': 'kits21/data/case_00059/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00060/imaging.nii.gz', 'label': 'kits21/data/case_00060/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00061/imaging.nii.gz', 'label': 'kits21/data/case_00061/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00062/imaging.nii.gz', 'label': 'kits21/data/case_00062/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00063/imaging.nii.gz', 'label': 'kits21/data/case_00063/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00064/imaging.nii.gz', 'label': 'kits21/data/case_00064/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00065/imaging.nii.gz', 'label': 'kits21/data/case_00065/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00066/imaging.nii.gz', 'label': 'kits21/data/case_00066/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00067/imaging.nii.gz', 'label': 'kits21/data/case_00067/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00068/imaging.nii.gz', 'label': 'kits21/data/case_00068/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00069/imaging.nii.gz', 'label': 'kits21/data/case_00069/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00070/imaging.nii.gz', 'label': 'kits21/data/case_00070/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00071/imaging.nii.gz', 'label': 'kits21/data/case_00071/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00072/imaging.nii.gz', 'label': 'kits21/data/case_00072/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00073/imaging.nii.gz', 'label': 'kits21/data/case_00073/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00074/imaging.nii.gz', 'label': 'kits21/data/case_00074/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00075/imaging.nii.gz', 'label': 'kits21/data/case_00075/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00076/imaging.nii.gz', 'label': 'kits21/data/case_00076/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00077/imaging.nii.gz', 'label': 'kits21/data/case_00077/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00078/imaging.nii.gz', 'label': 'kits21/data/case_00078/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00079/imaging.nii.gz', 'label': 'kits21/data/case_00079/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00080/imaging.nii.gz', 'label': 'kits21/data/case_00080/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00081/imaging.nii.gz', 'label': 'kits21/data/case_00081/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00082/imaging.nii.gz', 'label': 'kits21/data/case_00082/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00083/imaging.nii.gz', 'label': 'kits21/data/case_00083/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00084/imaging.nii.gz', 'label': 'kits21/data/case_00084/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00085/imaging.nii.gz', 'label': 'kits21/data/case_00085/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00086/imaging.nii.gz', 'label': 'kits21/data/case_00086/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00087/imaging.nii.gz', 'label': 'kits21/data/case_00087/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00088/imaging.nii.gz', 'label': 'kits21/data/case_00088/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00089/imaging.nii.gz', 'label': 'kits21/data/case_00089/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00090/imaging.nii.gz', 'label': 'kits21/data/case_00090/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00091/imaging.nii.gz', 'label': 'kits21/data/case_00091/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00092/imaging.nii.gz', 'label': 'kits21/data/case_00092/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00093/imaging.nii.gz', 'label': 'kits21/data/case_00093/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00094/imaging.nii.gz', 'label': 'kits21/data/case_00094/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00095/imaging.nii.gz', 'label': 'kits21/data/case_00095/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00096/imaging.nii.gz', 'label': 'kits21/data/case_00096/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00097/imaging.nii.gz', 'label': 'kits21/data/case_00097/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00098/imaging.nii.gz', 'label': 'kits21/data/case_00098/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00099/imaging.nii.gz', 'label': 'kits21/data/case_00099/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00100/imaging.nii.gz', 'label': 'kits21/data/case_00100/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00101/imaging.nii.gz', 'label': 'kits21/data/case_00101/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00102/imaging.nii.gz', 'label': 'kits21/data/case_00102/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00103/imaging.nii.gz', 'label': 'kits21/data/case_00103/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00104/imaging.nii.gz', 'label': 'kits21/data/case_00104/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00105/imaging.nii.gz', 'label': 'kits21/data/case_00105/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00106/imaging.nii.gz', 'label': 'kits21/data/case_00106/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00107/imaging.nii.gz', 'label': 'kits21/data/case_00107/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00108/imaging.nii.gz', 'label': 'kits21/data/case_00108/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00109/imaging.nii.gz', 'label': 'kits21/data/case_00109/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00110/imaging.nii.gz', 'label': 'kits21/data/case_00110/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00111/imaging.nii.gz', 'label': 'kits21/data/case_00111/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00112/imaging.nii.gz', 'label': 'kits21/data/case_00112/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00113/imaging.nii.gz', 'label': 'kits21/data/case_00113/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00114/imaging.nii.gz', 'label': 'kits21/data/case_00114/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00115/imaging.nii.gz', 'label': 'kits21/data/case_00115/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00116/imaging.nii.gz', 'label': 'kits21/data/case_00116/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00117/imaging.nii.gz', 'label': 'kits21/data/case_00117/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00118/imaging.nii.gz', 'label': 'kits21/data/case_00118/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00119/imaging.nii.gz', 'label': 'kits21/data/case_00119/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00120/imaging.nii.gz', 'label': 'kits21/data/case_00120/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00121/imaging.nii.gz', 'label': 'kits21/data/case_00121/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00122/imaging.nii.gz', 'label': 'kits21/data/case_00122/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00123/imaging.nii.gz', 'label': 'kits21/data/case_00123/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00124/imaging.nii.gz', 'label': 'kits21/data/case_00124/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00125/imaging.nii.gz', 'label': 'kits21/data/case_00125/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00126/imaging.nii.gz', 'label': 'kits21/data/case_00126/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00127/imaging.nii.gz', 'label': 'kits21/data/case_00127/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00128/imaging.nii.gz', 'label': 'kits21/data/case_00128/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00129/imaging.nii.gz', 'label': 'kits21/data/case_00129/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00130/imaging.nii.gz', 'label': 'kits21/data/case_00130/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00131/imaging.nii.gz', 'label': 'kits21/data/case_00131/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00132/imaging.nii.gz', 'label': 'kits21/data/case_00132/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00133/imaging.nii.gz', 'label': 'kits21/data/case_00133/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00134/imaging.nii.gz', 'label': 'kits21/data/case_00134/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00135/imaging.nii.gz', 'label': 'kits21/data/case_00135/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00136/imaging.nii.gz', 'label': 'kits21/data/case_00136/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00137/imaging.nii.gz', 'label': 'kits21/data/case_00137/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00138/imaging.nii.gz', 'label': 'kits21/data/case_00138/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00139/imaging.nii.gz', 'label': 'kits21/data/case_00139/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00140/imaging.nii.gz', 'label': 'kits21/data/case_00140/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00141/imaging.nii.gz', 'label': 'kits21/data/case_00141/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00142/imaging.nii.gz', 'label': 'kits21/data/case_00142/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00143/imaging.nii.gz', 'label': 'kits21/data/case_00143/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00144/imaging.nii.gz', 'label': 'kits21/data/case_00144/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00145/imaging.nii.gz', 'label': 'kits21/data/case_00145/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00146/imaging.nii.gz', 'label': 'kits21/data/case_00146/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00147/imaging.nii.gz', 'label': 'kits21/data/case_00147/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00148/imaging.nii.gz', 'label': 'kits21/data/case_00148/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00149/imaging.nii.gz', 'label': 'kits21/data/case_00149/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00150/imaging.nii.gz', 'label': 'kits21/data/case_00150/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00151/imaging.nii.gz', 'label': 'kits21/data/case_00151/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00152/imaging.nii.gz', 'label': 'kits21/data/case_00152/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00153/imaging.nii.gz', 'label': 'kits21/data/case_00153/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00154/imaging.nii.gz', 'label': 'kits21/data/case_00154/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00155/imaging.nii.gz', 'label': 'kits21/data/case_00155/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00156/imaging.nii.gz', 'label': 'kits21/data/case_00156/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00157/imaging.nii.gz', 'label': 'kits21/data/case_00157/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00158/imaging.nii.gz', 'label': 'kits21/data/case_00158/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00159/imaging.nii.gz', 'label': 'kits21/data/case_00159/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00160/imaging.nii.gz', 'label': 'kits21/data/case_00160/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00161/imaging.nii.gz', 'label': 'kits21/data/case_00161/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00162/imaging.nii.gz', 'label': 'kits21/data/case_00162/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00163/imaging.nii.gz', 'label': 'kits21/data/case_00163/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00164/imaging.nii.gz', 'label': 'kits21/data/case_00164/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00165/imaging.nii.gz', 'label': 'kits21/data/case_00165/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00166/imaging.nii.gz', 'label': 'kits21/data/case_00166/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00167/imaging.nii.gz', 'label': 'kits21/data/case_00167/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00168/imaging.nii.gz', 'label': 'kits21/data/case_00168/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00169/imaging.nii.gz', 'label': 'kits21/data/case_00169/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00170/imaging.nii.gz', 'label': 'kits21/data/case_00170/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00171/imaging.nii.gz', 'label': 'kits21/data/case_00171/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00172/imaging.nii.gz', 'label': 'kits21/data/case_00172/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00173/imaging.nii.gz', 'label': 'kits21/data/case_00173/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00174/imaging.nii.gz', 'label': 'kits21/data/case_00174/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00175/imaging.nii.gz', 'label': 'kits21/data/case_00175/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00176/imaging.nii.gz', 'label': 'kits21/data/case_00176/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00177/imaging.nii.gz', 'label': 'kits21/data/case_00177/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00178/imaging.nii.gz', 'label': 'kits21/data/case_00178/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00179/imaging.nii.gz', 'label': 'kits21/data/case_00179/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00180/imaging.nii.gz', 'label': 'kits21/data/case_00180/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00181/imaging.nii.gz', 'label': 'kits21/data/case_00181/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00182/imaging.nii.gz', 'label': 'kits21/data/case_00182/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00183/imaging.nii.gz', 'label': 'kits21/data/case_00183/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00184/imaging.nii.gz', 'label': 'kits21/data/case_00184/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00185/imaging.nii.gz', 'label': 'kits21/data/case_00185/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00186/imaging.nii.gz', 'label': 'kits21/data/case_00186/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00187/imaging.nii.gz', 'label': 'kits21/data/case_00187/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00188/imaging.nii.gz', 'label': 'kits21/data/case_00188/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00189/imaging.nii.gz', 'label': 'kits21/data/case_00189/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00190/imaging.nii.gz', 'label': 'kits21/data/case_00190/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00191/imaging.nii.gz', 'label': 'kits21/data/case_00191/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00192/imaging.nii.gz', 'label': 'kits21/data/case_00192/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00193/imaging.nii.gz', 'label': 'kits21/data/case_00193/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00194/imaging.nii.gz', 'label': 'kits21/data/case_00194/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00195/imaging.nii.gz', 'label': 'kits21/data/case_00195/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00196/imaging.nii.gz', 'label': 'kits21/data/case_00196/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00197/imaging.nii.gz', 'label': 'kits21/data/case_00197/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00198/imaging.nii.gz', 'label': 'kits21/data/case_00198/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00199/imaging.nii.gz', 'label': 'kits21/data/case_00199/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00200/imaging.nii.gz', 'label': 'kits21/data/case_00200/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00201/imaging.nii.gz', 'label': 'kits21/data/case_00201/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00202/imaging.nii.gz', 'label': 'kits21/data/case_00202/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00203/imaging.nii.gz', 'label': 'kits21/data/case_00203/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00204/imaging.nii.gz', 'label': 'kits21/data/case_00204/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00205/imaging.nii.gz', 'label': 'kits21/data/case_00205/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00206/imaging.nii.gz', 'label': 'kits21/data/case_00206/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00207/imaging.nii.gz', 'label': 'kits21/data/case_00207/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00208/imaging.nii.gz', 'label': 'kits21/data/case_00208/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00209/imaging.nii.gz', 'label': 'kits21/data/case_00209/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00210/imaging.nii.gz', 'label': 'kits21/data/case_00210/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00211/imaging.nii.gz', 'label': 'kits21/data/case_00211/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00212/imaging.nii.gz', 'label': 'kits21/data/case_00212/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00213/imaging.nii.gz', 'label': 'kits21/data/case_00213/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00214/imaging.nii.gz', 'label': 'kits21/data/case_00214/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00215/imaging.nii.gz', 'label': 'kits21/data/case_00215/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00216/imaging.nii.gz', 'label': 'kits21/data/case_00216/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00217/imaging.nii.gz', 'label': 'kits21/data/case_00217/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00218/imaging.nii.gz', 'label': 'kits21/data/case_00218/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00219/imaging.nii.gz', 'label': 'kits21/data/case_00219/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00220/imaging.nii.gz', 'label': 'kits21/data/case_00220/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00221/imaging.nii.gz', 'label': 'kits21/data/case_00221/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00222/imaging.nii.gz', 'label': 'kits21/data/case_00222/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00223/imaging.nii.gz', 'label': 'kits21/data/case_00223/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00224/imaging.nii.gz', 'label': 'kits21/data/case_00224/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00225/imaging.nii.gz', 'label': 'kits21/data/case_00225/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00226/imaging.nii.gz', 'label': 'kits21/data/case_00226/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00227/imaging.nii.gz', 'label': 'kits21/data/case_00227/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00228/imaging.nii.gz', 'label': 'kits21/data/case_00228/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00229/imaging.nii.gz', 'label': 'kits21/data/case_00229/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00230/imaging.nii.gz', 'label': 'kits21/data/case_00230/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00231/imaging.nii.gz', 'label': 'kits21/data/case_00231/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00232/imaging.nii.gz', 'label': 'kits21/data/case_00232/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00233/imaging.nii.gz', 'label': 'kits21/data/case_00233/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00234/imaging.nii.gz', 'label': 'kits21/data/case_00234/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00235/imaging.nii.gz', 'label': 'kits21/data/case_00235/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00236/imaging.nii.gz', 'label': 'kits21/data/case_00236/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00237/imaging.nii.gz', 'label': 'kits21/data/case_00237/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00238/imaging.nii.gz', 'label': 'kits21/data/case_00238/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00239/imaging.nii.gz', 'label': 'kits21/data/case_00239/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00240/imaging.nii.gz', 'label': 'kits21/data/case_00240/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00241/imaging.nii.gz', 'label': 'kits21/data/case_00241/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00242/imaging.nii.gz', 'label': 'kits21/data/case_00242/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00243/imaging.nii.gz', 'label': 'kits21/data/case_00243/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00244/imaging.nii.gz', 'label': 'kits21/data/case_00244/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00245/imaging.nii.gz', 'label': 'kits21/data/case_00245/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00246/imaging.nii.gz', 'label': 'kits21/data/case_00246/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00247/imaging.nii.gz', 'label': 'kits21/data/case_00247/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00248/imaging.nii.gz', 'label': 'kits21/data/case_00248/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00249/imaging.nii.gz', 'label': 'kits21/data/case_00249/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00250/imaging.nii.gz', 'label': 'kits21/data/case_00250/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00251/imaging.nii.gz', 'label': 'kits21/data/case_00251/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00252/imaging.nii.gz', 'label': 'kits21/data/case_00252/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00253/imaging.nii.gz', 'label': 'kits21/data/case_00253/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00254/imaging.nii.gz', 'label': 'kits21/data/case_00254/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00255/imaging.nii.gz', 'label': 'kits21/data/case_00255/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00256/imaging.nii.gz', 'label': 'kits21/data/case_00256/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00257/imaging.nii.gz', 'label': 'kits21/data/case_00257/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00258/imaging.nii.gz', 'label': 'kits21/data/case_00258/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00259/imaging.nii.gz', 'label': 'kits21/data/case_00259/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00260/imaging.nii.gz', 'label': 'kits21/data/case_00260/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00261/imaging.nii.gz', 'label': 'kits21/data/case_00261/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00262/imaging.nii.gz', 'label': 'kits21/data/case_00262/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00263/imaging.nii.gz', 'label': 'kits21/data/case_00263/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00264/imaging.nii.gz', 'label': 'kits21/data/case_00264/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00265/imaging.nii.gz', 'label': 'kits21/data/case_00265/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00266/imaging.nii.gz', 'label': 'kits21/data/case_00266/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00267/imaging.nii.gz', 'label': 'kits21/data/case_00267/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00268/imaging.nii.gz', 'label': 'kits21/data/case_00268/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00269/imaging.nii.gz', 'label': 'kits21/data/case_00269/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00270/imaging.nii.gz', 'label': 'kits21/data/case_00270/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00271/imaging.nii.gz', 'label': 'kits21/data/case_00271/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00272/imaging.nii.gz', 'label': 'kits21/data/case_00272/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00273/imaging.nii.gz', 'label': 'kits21/data/case_00273/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00274/imaging.nii.gz', 'label': 'kits21/data/case_00274/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00275/imaging.nii.gz', 'label': 'kits21/data/case_00275/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00276/imaging.nii.gz', 'label': 'kits21/data/case_00276/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00277/imaging.nii.gz', 'label': 'kits21/data/case_00277/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00278/imaging.nii.gz', 'label': 'kits21/data/case_00278/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00279/imaging.nii.gz', 'label': 'kits21/data/case_00279/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00280/imaging.nii.gz', 'label': 'kits21/data/case_00280/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00281/imaging.nii.gz', 'label': 'kits21/data/case_00281/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00282/imaging.nii.gz', 'label': 'kits21/data/case_00282/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00283/imaging.nii.gz', 'label': 'kits21/data/case_00283/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00284/imaging.nii.gz', 'label': 'kits21/data/case_00284/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00285/imaging.nii.gz', 'label': 'kits21/data/case_00285/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00286/imaging.nii.gz', 'label': 'kits21/data/case_00286/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00287/imaging.nii.gz', 'label': 'kits21/data/case_00287/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00288/imaging.nii.gz', 'label': 'kits21/data/case_00288/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00289/imaging.nii.gz', 'label': 'kits21/data/case_00289/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00290/imaging.nii.gz', 'label': 'kits21/data/case_00290/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00291/imaging.nii.gz', 'label': 'kits21/data/case_00291/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00292/imaging.nii.gz', 'label': 'kits21/data/case_00292/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00293/imaging.nii.gz', 'label': 'kits21/data/case_00293/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00294/imaging.nii.gz', 'label': 'kits21/data/case_00294/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00295/imaging.nii.gz', 'label': 'kits21/data/case_00295/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00296/imaging.nii.gz', 'label': 'kits21/data/case_00296/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00297/imaging.nii.gz', 'label': 'kits21/data/case_00297/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00298/imaging.nii.gz', 'label': 'kits21/data/case_00298/aggregated_AND_seg.nii.gz'}, {'image': 'kits21/data/case_00299/imaging.nii.gz', 'label': 'kits21/data/case_00299/aggregated_AND_seg.nii.gz'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_YZyfhCQbXo"
      },
      "source": [
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
        "            2, 1.62, 1.62), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=-80, a_max=305,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "        RandCropByPosNegLabeld(\n",
        "            keys=[\"image\", \"label\"],\n",
        "            label_key=\"label\",\n",
        "            spatial_size=(128, 128, 64),\n",
        "            pos=1,\n",
        "            neg=1,\n",
        "            num_samples=4,\n",
        "            image_key=\"image\",\n",
        "            image_threshold=0,\n",
        "        ),\n",
        "        # user can also add other random transforms\n",
        "        RandAffined(\n",
        "            keys=['image', 'label'],\n",
        "            mode=('bilinear', 'nearest'),\n",
        "            prob=1.0, spatial_size=(128, 128, 64),\n",
        "            rotate_range=(0, 0, np.pi/15),\n",
        "            scale_range=(0.1, 0.1, 0.1)),\n",
        "     \n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
        "            2, 1.62, 1.62), mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"],a_min=-80, a_max=305,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "K2zbq5e-QcWF",
        "outputId": "af645691-8cf8-4096-8264-3cd6e389d811"
      },
      "source": [
        "check_ds = Dataset(data=val_files, transform=train_transforms)\n",
        "check_loader = DataLoader(check_ds, batch_size=1)\n",
        "check_data = first(check_loader)\n",
        "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
        "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
        "# plot the slice [:, :, 80]\n",
        "plt.figure(\"check\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"image\")\n",
        "plt.imshow(image[:, :, 60], cmap=\"gray\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"label\")\n",
        "plt.imshow(label[:, :, 60])\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape: torch.Size([128, 128, 64]), label shape: torch.Size([128, 128, 64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeGvtIbbA4uj"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_64OsZZcQ3Kv",
        "outputId": "3064b67a-e384-45d9-84aa-73a4694e7c39"
      },
      "source": [
        "train_ds = SmartCacheDataset(\n",
        "    data=train_files, transform=train_transforms,\n",
        "    cache_rate=0.5, replace_rate=0.5)\n",
        "# train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "\n",
        "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
        "# to generate 2 x 4 images for network training\n",
        "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
        "\n",
        "val_ds = SmartCacheDataset(\n",
        "    data=val_files, transform=val_transforms, cache_rate=0.5,replace_rate=0.5 )\n",
        "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading dataset: 100%|██████████| 150/150 [09:48<00:00,  3.93s/it]\n",
            "Loading dataset: 100%|██████████| 4/4 [00:33<00:00,  8.48s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WtezIC06RRV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from monai.networks.blocks.convolutions import Convolution, ResidualUnit\n",
        "from monai.networks.layers.factories import Act, Norm\n",
        "from monai.networks.layers.simplelayers import SkipConnection\n",
        "from monai.utils import alias, export\n",
        "\n",
        "# __all__ = [\"UNet\", \"Unet\", \"unet\"]\n",
        "\n",
        "# https://github.com/luuuyi/CBAM.PyTorch/blob/master/model/resnet_cbam.py\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, submodule, in_planes, out_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.submodule = submodule\n",
        "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool3d(1)\n",
        "        self.in_planes = in_planes\n",
        "        self.fc = nn.Sequential(nn.Conv3d(in_planes, in_planes // ratio, 1, bias=False),\n",
        "                               nn.GELU(),\n",
        "                               nn.Conv3d(in_planes // ratio, out_planes, 1, bias=False))\n",
        "        # self.conv_1 = nn.Conv3d()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"CAT X = \", x.shape, flush=True)\n",
        "        y = self.submodule(x)\n",
        "        # print(\"CAT Y = \", y.shape, flush=True)\n",
        "        x_av = self.avg_pool(x)\n",
        "        # print(\"CAT AVG MID = \", x.shape,  self.in_planes, flush=True)\n",
        "        # print(\"FC = \", self.fc, flush=True)\n",
        "        avg_out = self.fc(x_av)\n",
        "        # print(\"CAT AVG = \", avg_out.shape, self.in_planes, flush=True)\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "        # print(\"CA output = \", y.shape, out.shape, avg_out.shape, self.in_planes, flush=True)\n",
        "        # print(\"CHANNEL = \", out.shape)\n",
        "        return y*self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, submodule, in_channels, kernel_size=7, out_channels=None, add_conv_1x1=False):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.submodule = submodule\n",
        "        self.conv_flat = nn.Conv3d(in_channels, in_channels, 1, bias=False)\n",
        "        self.conv1 = nn.Conv3d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        # self.conv2 = nn.Conv3d(4, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.pool_layer = nn.MaxPool3d(2)\n",
        "        self.upscale_layer = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        self.gelu = nn.GELU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.add_conv_1x1 = add_conv_1x1\n",
        "        if add_conv_1x1:\n",
        "            if out_channels is None:\n",
        "                raise Exception(\"Out channels needed for conv 1x1\")\n",
        "            self.conv_1x1 = nn.Conv3d(in_channels, out_channels, 1, bias=False)\n",
        "            self.act = torch.nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"#\"*30)\n",
        "        # print(\"SUB = \", self.submodule, \"\\n\", x.shape, flush=True)\n",
        "        # print(\"ORIG = \", x.shape)\n",
        "        y = self.submodule(x)\n",
        "        # x_2 = self.conv_flat(x)\n",
        "        # print(\"X2 = \", x_2.shape)\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        # print(\"X = \", x.shape, y.shape, avg_out.shape, max_out.shape, flush=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        # print(\"X2 = \", x.shape, flush=True)\n",
        "        x = self.conv1(x)\n",
        "        if x.shape[-1] > y.shape[-1]:\n",
        "            x = self.pool_layer(x)\n",
        "        elif x.shape[-1] < y.shape[-1]:\n",
        "            x = self.upscale_layer(x)\n",
        "        # print(\"X3 = \", x.shape, y.shape, flush=True)\n",
        "        # print(\"SPATIAL = \", x.shape)\n",
        "        x = y*self.sigmoid(x)\n",
        "        if self.add_conv_1x1:\n",
        "            x = self.conv_1x1(x)\n",
        "            x = self.act(x)\n",
        "        return x\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_c=32, out_c=32, kernel_size=3, activation=nn.GELU):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv3d(n_c, out_c, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.batchnorm = nn.BatchNorm3d(out_c)\n",
        "        self.activation = activation()\n",
        "        self.conv2 = nn.Conv3d(out_c, out_c, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.batchnorm2 = nn.BatchNorm3d(out_c)\n",
        "        self.activation2 = activation()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.activation2(x)\n",
        "        return x\n",
        "        \n",
        "# Copyright 2020 - 2021 MONAI Consortium\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "import warnings\n",
        "from typing import Sequence, Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from monai.networks.blocks.convolutions import Convolution, ResidualUnit\n",
        "from monai.networks.layers.factories import Act, Norm\n",
        "from monai.networks.layers.simplelayers import SkipConnection\n",
        "from monai.utils import alias, export\n",
        "\n",
        "__all__ = [\"UNet\", \"Unet\", \"unet\"]\n",
        "\n",
        "\n",
        "@export(\"monai.networks.nets\")\n",
        "@alias(\"Unet\")\n",
        "class UNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dimensions: int,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        channels: Sequence[int],\n",
        "        strides: Sequence[int],\n",
        "        kernel_size: Union[Sequence[int], int] = 3,\n",
        "        up_kernel_size: Union[Sequence[int], int] = 3,\n",
        "        num_res_units: int = 0,\n",
        "        act: Union[Tuple, str] = Act.PRELU,\n",
        "        norm: Union[Tuple, str] = Norm.INSTANCE,\n",
        "        dropout=0.0,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Enhanced version of UNet which has residual units implemented with the ResidualUnit class.\n",
        "        The residual part uses a convolution to change the input dimensions to match the output dimensions\n",
        "        if this is necessary but will use nn.Identity if not.\n",
        "        Refer to: https://link.springer.com/chapter/10.1007/978-3-030-12029-0_40.\n",
        "\n",
        "        Args:\n",
        "            dimensions: number of spatial dimensions.\n",
        "            in_channels: number of input channels.\n",
        "            out_channels: number of output channels.\n",
        "            channels: sequence of channels. Top block first. The length of `channels` should be no less than 2.\n",
        "            strides: sequence of convolution strides. The length of `stride` should equal to `len(channels) - 1`.\n",
        "            kernel_size: convolution kernel size, the value(s) should be odd. If sequence,\n",
        "                its length should equal to dimensions. Defaults to 3.\n",
        "            up_kernel_size: upsampling convolution kernel size, the value(s) should be odd. If sequence,\n",
        "                its length should equal to dimensions. Defaults to 3.\n",
        "            num_res_units: number of residual units. Defaults to 0.\n",
        "            act: activation type and arguments. Defaults to PReLU.\n",
        "            norm: feature normalization type and arguments. Defaults to instance norm.\n",
        "            dropout: dropout ratio. Defaults to no dropout.\n",
        "\n",
        "        Note: The acceptable spatial size of input data depends on the parameters of the network,\n",
        "            to set appropriate spatial size, please check the tutorial for more details:\n",
        "            https://github.com/Project-MONAI/tutorials/blob/master/modules/UNet_input_size_constrains.ipynb.\n",
        "            Typically, when using a stride of 2 in down / up sampling, the output dimensions are either half of the\n",
        "            input when downsampling, or twice when upsampling. In this case with N numbers of layers in the network,\n",
        "            the inputs must have spatial dimensions that are all multiples of 2^N.\n",
        "            Usually, applying `resize`, `pad` or `crop` transforms can help adjust the spatial size of input data.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        if len(channels) < 2:\n",
        "            raise ValueError(\n",
        "                \"the length of `channels` should be no less than 2.\")\n",
        "        delta = len(strides) - (len(channels) - 1)\n",
        "        if delta < 0:\n",
        "            raise ValueError(\n",
        "                \"the length of `strides` should equal to `len(channels) - 1`.\")\n",
        "        if delta > 0:\n",
        "            warnings.warn(f\"`len(strides) > len(channels) - 1`, the last {delta} values of strides will not be used.\")\n",
        "        if isinstance(kernel_size, Sequence):\n",
        "            if len(kernel_size) != dimensions:\n",
        "                raise ValueError(\n",
        "                    \"the length of `kernel_size` should equal to `dimensions`.\")\n",
        "        if isinstance(up_kernel_size, Sequence):\n",
        "            if len(up_kernel_size) != dimensions:\n",
        "                raise ValueError(\n",
        "                    \"the length of `up_kernel_size` should equal to `dimensions`.\")\n",
        "\n",
        "        self.dimensions = dimensions\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.channels = channels\n",
        "        self.strides = strides\n",
        "        self.kernel_size = kernel_size\n",
        "        self.up_kernel_size = up_kernel_size\n",
        "        self.num_res_units = num_res_units\n",
        "        self.act = act\n",
        "        self.norm = norm\n",
        "        self.dropout = dropout\n",
        "        # self.ca1 = ChannelAttention(16)\n",
        "        # self.ca1 = ChannelAttention(16)\n",
        "        # self.sa1 = SpatialAttention()\n",
        "        # self.sa2 = SpatialAttention()\n",
        "        # self.sa3 = SpatialAttention()\n",
        "\n",
        "        def _create_block(\n",
        "            inc: int,\n",
        "            outc: int,\n",
        "            channels: Sequence[int],\n",
        "            strides: Sequence[int],\n",
        "            is_top: bool) -> nn.Sequential:\n",
        "            \"\"\"\n",
        "            Builds the UNet structure from the bottom up by recursing down to the bottom block, then creating sequential\n",
        "            blocks containing the downsample path, a skip connection around the previous block, and the upsample path.\n",
        "\n",
        "            Args:\n",
        "                inc: number of input channels.\n",
        "                outc: number of output channels.\n",
        "                channels: sequence of channels. Top block first.\n",
        "                strides: convolution stride.\n",
        "                is_top: True if this is the top block.\n",
        "            \"\"\"\n",
        "            print(\"IN CREATE BLOCK : \", inc, outc, channels, strides, is_top)\n",
        "            c = channels[0]\n",
        "            s = strides[0]\n",
        "            print(c, channels)\n",
        "            subblock: nn.Module\n",
        "            if len(channels)>2:\n",
        "                # continue recursion down\n",
        "                subblock = _create_block(\n",
        "                    c, c, channels[1:], strides[1:], False)                \n",
        "                upc = c * 2\n",
        "                if len(channels) > len(self.channels)-1:\n",
        "                    add_spatial = True\n",
        "                    add_channel = False\n",
        "                else:\n",
        "                    add_spatial = False\n",
        "                    add_channel = False\n",
        "            else:\n",
        "                # the next layer is the bottom so stop recursion, create the bottom layer as the sublock for this layer\n",
        "                # print(\"## : CHANNELS = \", c, channels)\n",
        "                subblock = self._get_bottom_layer(c, channels[1])\n",
        "                print(\"CREATED bottom LAYER : \", inc, outc, channels, strides, is_top)\n",
        "                subblock = ChannelAttention(subblock, in_planes=c, out_planes=channels[1])\n",
        "                # subblock = ChannelAttention(subblock, in_planes=channels[0])\n",
        "                upc = c + channels[1]\n",
        "                add_spatial = False\n",
        "                add_channel = False\n",
        "\n",
        "            # create layer in downsampling path\n",
        "            down = self._get_down_layer(inc, c, s, is_top)\n",
        "            print(\"CREATED DOWN LAYER : \", inc, c, s, is_top)\n",
        "            if add_spatial:\n",
        "                down = SpatialAttention(down, in_channels=inc)\n",
        "            # if add_channel:\n",
        "            #     down = ChannelAttention(down, in_planes=inc, out_planes=c)\n",
        "\n",
        "            # create layer in upsampling path\n",
        "            if len(channels)==len(self.channels) and add_spatial:\n",
        "                up = self._get_up_layer(upc, upc, s, is_top)\n",
        "            else:\n",
        "                up = self._get_up_layer(upc, outc, s, is_top)\n",
        "            print(\"CREATED UP LAYER : \", upc, outc, s, is_top)\n",
        "            # print(up, flush=True)\n",
        "            if add_spatial:\n",
        "                # print(\"CHANNELS = \", len(channels), channels[0], channels[1], flush=True)\n",
        "                print(\"CH = \",channels, len(channels))\n",
        "                add_conv_1x1 = len(channels)==len(self.channels)\n",
        "                up = SpatialAttention(up, in_channels=upc, out_channels=outc, add_conv_1x1=add_conv_1x1)\n",
        "            # if add_channel:\n",
        "            #     up = ChannelAttention(up, in_planes=upc, out_planes=outc)\n",
        "\n",
        "            print(\"OUT OF CREATE BLOCK : \", inc, outc, channels, strides, is_top)\n",
        "            return nn.Sequential(down, SkipConnection(subblock), up)\n",
        "\n",
        "        self.model = _create_block(\n",
        "            in_channels, out_channels, self.channels, self.strides, True)\n",
        "\n",
        "    def _get_down_layer(self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        strides: int,\n",
        "        is_top: bool) -> nn.Module:\n",
        "        \"\"\" \n",
        "        Args:\n",
        "            in_channels: number of input channels.\n",
        "            out_channels: number of output channels.\n",
        "            strides: convolution stride.\n",
        "            is_top: True if this is the top block.\n",
        "        \"\"\"\n",
        "        # print(\"CREATING DOWN LAYER : \", in_channels, out_channels, strides, is_top)\n",
        "        if self.num_res_units > 0:\n",
        "            return ResidualUnit(\n",
        "                self.dimensions,\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                strides=strides,\n",
        "                kernel_size=self.kernel_size,\n",
        "                subunits=self.num_res_units,\n",
        "                act=self.act,\n",
        "                norm=self.norm,\n",
        "                dropout=self.dropout,\n",
        "            )\n",
        "        return Convolution(\n",
        "            self.dimensions,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            strides=strides,\n",
        "            kernel_size=self.kernel_size,\n",
        "            act=self.act,\n",
        "            norm=self.norm,\n",
        "            dropout=self.dropout,\n",
        "        )\n",
        "\n",
        "    def _get_bottom_layer(self, in_channels: int, out_channels: int) -> nn.Module:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_channels: number of input channels.\n",
        "            out_channels: number of output channels.\n",
        "        \"\"\"\n",
        "        # print(\"CREATING bottom LAYER : \", in_channels, out_channels)\n",
        "        return self._get_down_layer(in_channels, out_channels, 1, False)\n",
        "\n",
        "    def _get_up_layer(self, in_channels: int, out_channels: int, strides: int, is_top: bool) -> nn.Module:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_channels: number of input channels.\n",
        "            out_channels: number of output channels.\n",
        "            strides: convolution stride.\n",
        "            is_top: True if this is the top block.\n",
        "        \"\"\"\n",
        "        # print(\"CREATING UP LAYER : \", in_channels, out_channels, strides, is_top)\n",
        "        conv: Union[Convolution, nn.Sequential]\n",
        "\n",
        "        conv = Convolution(\n",
        "            self.dimensions,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            strides=strides,\n",
        "            kernel_size=self.up_kernel_size,\n",
        "            act=self.act,\n",
        "            norm=self.norm,\n",
        "            dropout=self.dropout,\n",
        "            conv_only=is_top and self.num_res_units == 0,\n",
        "            is_transposed=True,\n",
        "        )\n",
        "\n",
        "        if self.num_res_units > 0:\n",
        "            ru = ResidualUnit(\n",
        "                self.dimensions,\n",
        "                out_channels,\n",
        "                out_channels,\n",
        "                strides=1,\n",
        "                kernel_size=self.kernel_size,\n",
        "                subunits=1,\n",
        "                act=self.act,\n",
        "                norm=self.norm,\n",
        "                dropout=self.dropout,\n",
        "                last_conv_only=is_top,\n",
        "            )\n",
        "            conv = nn.Sequential(conv, ru)\n",
        "\n",
        "        return conv\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "Unet = unet = UNet"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct4tn9fuRFRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3e52a5-32b4-4aa9-c46a-940e6e7c320d"
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# model = UNet(\n",
        "#     dimensions=3,\n",
        "#     in_channels=1,\n",
        "#     out_channels=4,\n",
        "#     channels=(16, 32, 64, 128, 256),\n",
        "#     strides=(2, 2, 2, 2),\n",
        "#     num_res_units=2,\n",
        "#     norm=\"INSTANCE\",\n",
        "# ).to(device)\n",
        "\n",
        "# model=DynUNet(\n",
        "#     spatial_dims =3,\n",
        "#     in_channels=1,\n",
        "#     out_channels=4,\n",
        "#     kernel_size=(3,3,3,3,3), \n",
        "#     strides=(2,2,2,2,2), \n",
        "#     upsample_kernel_size=(3,3,3,3),\n",
        "#     deep_supervision=True, \n",
        "#     deep_supr_num=1, \n",
        "#     res_block=True\n",
        "# ).to(device)\n",
        "\n",
        "# model = UNETR(\n",
        "#             in_channels=1,\n",
        "#             out_channels=4,\n",
        "#             img_size=(96, 96, 64),\n",
        "#             feature_size=16,\n",
        "#             hidden_size=768,\n",
        "#             mlp_dim=3072,\n",
        "#             num_heads=12,\n",
        "#             pos_embed=\"perceptron\",\n",
        "#             norm_name=\"batch\",\n",
        "#             res_block=True,\n",
        "#             conv_block=True,\n",
        "#             dropout_rate=0.0,\n",
        "#         ).to(device)\n",
        "\n",
        "model = UNet(\n",
        "    dimensions=3,\n",
        "    in_channels=1,\n",
        "    out_channels=4,\n",
        "    channels=(32, 64, 128, 128),\n",
        "    strides=(2, 2, 2), \n",
        ").to(device)\n",
        "\n",
        "loss_function = DiceCELoss(to_onehot_y=True, softmax=True)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3)\n",
        "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "\n",
        "\n",
        "root_dir='checkpoints'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IN CREATE BLOCK :  1 4 (32, 64, 128, 128) (2, 2, 2) True\n",
            "32 (32, 64, 128, 128)\n",
            "IN CREATE BLOCK :  32 32 (64, 128, 128) (2, 2) False\n",
            "64 (64, 128, 128)\n",
            "IN CREATE BLOCK :  64 64 (128, 128) (2,) False\n",
            "128 (128, 128)\n",
            "CREATED bottom LAYER :  64 64 (128, 128) (2,) False\n",
            "CREATED DOWN LAYER :  64 128 2 False\n",
            "CREATED UP LAYER :  256 64 2 False\n",
            "OUT OF CREATE BLOCK :  64 64 (128, 128) (2,) False\n",
            "CREATED DOWN LAYER :  32 64 2 False\n",
            "CREATED UP LAYER :  128 32 2 False\n",
            "OUT OF CREATE BLOCK :  32 32 (64, 128, 128) (2, 2) False\n",
            "CREATED DOWN LAYER :  1 32 2 True\n",
            "CREATED UP LAYER :  64 4 2 True\n",
            "CH =  (32, 64, 128, 128) 4\n",
            "OUT OF CREATE BLOCK :  1 4 (32, 64, 128, 128) (2, 2, 2) True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsuWOGD29TUl"
      },
      "source": [
        "mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTu0eFpBPd2A"
      },
      "source": [
        "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-3)\n",
        "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRRrHBmLRJpZ",
        "outputId": "6be3dd3a-4871-41ed-ca4e-a6391e83829f"
      },
      "source": [
        "max_epochs = 300\n",
        "val_interval = 1\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=True, n_classes=4)])\n",
        "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=True, n_classes=4)])\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"label\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        print(\n",
        "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
        "            f\"train_loss: {loss.item():.4f}\")\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = (\n",
        "                    val_data[\"image\"].to(device),\n",
        "                    val_data[\"label\"].to(device),\n",
        "                )\n",
        "                roi_size = (128,128, 64)\n",
        "                sw_batch_size = 4\n",
        "                val_outputs = sliding_window_inference(\n",
        "                    val_inputs, roi_size, sw_batch_size, model)\n",
        "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
        "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
        "                # compute metric for current iteration\n",
        "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "            # aggregate the final mean dice result\n",
        "            metric = dice_metric.aggregate().item()\n",
        "            # reset the status for next validation round\n",
        "            dice_metric.reset()\n",
        "\n",
        "            metric_values.append(metric)\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), os.path.join(\n",
        "                    root_dir, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                f\"at epoch: {best_metric_epoch}\"\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "45/75, train_loss: 0.4758\n",
            "46/75, train_loss: 0.3646\n",
            "47/75, train_loss: 0.5495\n",
            "48/75, train_loss: 0.4747\n",
            "49/75, train_loss: 0.5263\n",
            "50/75, train_loss: 0.4642\n",
            "51/75, train_loss: 0.5477\n",
            "52/75, train_loss: 0.5697\n",
            "53/75, train_loss: 0.5039\n",
            "54/75, train_loss: 0.3999\n",
            "55/75, train_loss: 0.5910\n",
            "56/75, train_loss: 0.4486\n",
            "57/75, train_loss: 0.5930\n",
            "58/75, train_loss: 0.4915\n",
            "59/75, train_loss: 0.4970\n",
            "60/75, train_loss: 0.5383\n",
            "61/75, train_loss: 0.6019\n",
            "62/75, train_loss: 0.5258\n",
            "63/75, train_loss: 0.5205\n",
            "64/75, train_loss: 0.4631\n",
            "65/75, train_loss: 0.4912\n",
            "66/75, train_loss: 0.5457\n",
            "67/75, train_loss: 0.5168\n",
            "68/75, train_loss: 0.5099\n",
            "69/75, train_loss: 0.4417\n",
            "70/75, train_loss: 0.5033\n",
            "71/75, train_loss: 0.5268\n",
            "72/75, train_loss: 0.5420\n",
            "73/75, train_loss: 0.6147\n",
            "74/75, train_loss: 0.6466\n",
            "75/75, train_loss: 0.5530\n",
            "epoch 43 average loss: 0.4972\n",
            "current epoch: 43 current mean dice: 0.7500\n",
            "best mean dice: 0.7549 at epoch: 39\n",
            "----------\n",
            "epoch 44/300\n",
            "1/75, train_loss: 0.5783\n",
            "2/75, train_loss: 0.5932\n",
            "3/75, train_loss: 0.4786\n",
            "4/75, train_loss: 0.5682\n",
            "5/75, train_loss: 0.3951\n",
            "6/75, train_loss: 0.4058\n",
            "7/75, train_loss: 0.4457\n",
            "8/75, train_loss: 0.3080\n",
            "9/75, train_loss: 0.4717\n",
            "10/75, train_loss: 0.5002\n",
            "11/75, train_loss: 0.4302\n",
            "12/75, train_loss: 0.4563\n",
            "13/75, train_loss: 0.3913\n",
            "14/75, train_loss: 0.4483\n",
            "15/75, train_loss: 0.5537\n",
            "16/75, train_loss: 0.4872\n",
            "17/75, train_loss: 0.5295\n",
            "18/75, train_loss: 0.3865\n",
            "19/75, train_loss: 0.4266\n",
            "20/75, train_loss: 0.4952\n",
            "21/75, train_loss: 0.4186\n",
            "22/75, train_loss: 0.5688\n",
            "23/75, train_loss: 0.4832\n",
            "24/75, train_loss: 0.4584\n",
            "25/75, train_loss: 0.5353\n",
            "26/75, train_loss: 0.5186\n",
            "27/75, train_loss: 0.5451\n",
            "28/75, train_loss: 0.6046\n",
            "29/75, train_loss: 0.5835\n",
            "30/75, train_loss: 0.4489\n",
            "31/75, train_loss: 0.5001\n",
            "32/75, train_loss: 0.4718\n",
            "33/75, train_loss: 0.4514\n",
            "34/75, train_loss: 0.5641\n",
            "35/75, train_loss: 0.4907\n",
            "36/75, train_loss: 0.4408\n",
            "37/75, train_loss: 0.4508\n",
            "38/75, train_loss: 0.4891\n",
            "39/75, train_loss: 0.5267\n",
            "40/75, train_loss: 0.5495\n",
            "41/75, train_loss: 0.4594\n",
            "42/75, train_loss: 0.4093\n",
            "43/75, train_loss: 0.6073\n",
            "44/75, train_loss: 0.4812\n",
            "45/75, train_loss: 0.4607\n",
            "46/75, train_loss: 0.5668\n",
            "47/75, train_loss: 0.4731\n",
            "48/75, train_loss: 0.4555\n",
            "49/75, train_loss: 0.5053\n",
            "50/75, train_loss: 0.5151\n",
            "51/75, train_loss: 0.5674\n",
            "52/75, train_loss: 0.5605\n",
            "53/75, train_loss: 0.4865\n",
            "54/75, train_loss: 0.4829\n",
            "55/75, train_loss: 0.4433\n",
            "56/75, train_loss: 0.4805\n",
            "57/75, train_loss: 0.5430\n",
            "58/75, train_loss: 0.4982\n",
            "59/75, train_loss: 0.5455\n",
            "60/75, train_loss: 0.5384\n",
            "61/75, train_loss: 0.5106\n",
            "62/75, train_loss: 0.5150\n",
            "63/75, train_loss: 0.5208\n",
            "64/75, train_loss: 0.5884\n",
            "65/75, train_loss: 0.4892\n",
            "66/75, train_loss: 0.4469\n",
            "67/75, train_loss: 0.5271\n",
            "68/75, train_loss: 0.5562\n",
            "69/75, train_loss: 0.4908\n",
            "70/75, train_loss: 0.5845\n",
            "71/75, train_loss: 0.5597\n",
            "72/75, train_loss: 0.5574\n",
            "73/75, train_loss: 0.5932\n",
            "74/75, train_loss: 0.3977\n",
            "75/75, train_loss: 0.4930\n",
            "epoch 44 average loss: 0.4981\n",
            "current epoch: 44 current mean dice: 0.7416\n",
            "best mean dice: 0.7549 at epoch: 39\n",
            "----------\n",
            "epoch 45/300\n",
            "1/75, train_loss: 0.4298\n",
            "2/75, train_loss: 0.5376\n",
            "3/75, train_loss: 0.4681\n",
            "4/75, train_loss: 0.5383\n",
            "5/75, train_loss: 0.4830\n",
            "6/75, train_loss: 0.4497\n",
            "7/75, train_loss: 0.3862\n",
            "8/75, train_loss: 0.5035\n",
            "9/75, train_loss: 0.5477\n",
            "10/75, train_loss: 0.3693\n",
            "11/75, train_loss: 0.5080\n",
            "12/75, train_loss: 0.4953\n",
            "13/75, train_loss: 0.2798\n",
            "14/75, train_loss: 0.4335\n",
            "15/75, train_loss: 0.5068\n",
            "16/75, train_loss: 0.4195\n",
            "17/75, train_loss: 0.4861\n",
            "18/75, train_loss: 0.4788\n",
            "19/75, train_loss: 0.4130\n",
            "20/75, train_loss: 0.4919\n",
            "21/75, train_loss: 0.4868\n",
            "22/75, train_loss: 0.4474\n",
            "23/75, train_loss: 0.5902\n",
            "24/75, train_loss: 0.4792\n",
            "25/75, train_loss: 0.4560\n",
            "26/75, train_loss: 0.5649\n",
            "27/75, train_loss: 0.4130\n",
            "28/75, train_loss: 0.4716\n",
            "29/75, train_loss: 0.5471\n",
            "30/75, train_loss: 0.5230\n",
            "31/75, train_loss: 0.5887\n",
            "32/75, train_loss: 0.6392\n",
            "33/75, train_loss: 0.5495\n",
            "34/75, train_loss: 0.5090\n",
            "35/75, train_loss: 0.5679\n",
            "36/75, train_loss: 0.6835\n",
            "37/75, train_loss: 0.6567\n",
            "38/75, train_loss: 0.5579\n",
            "39/75, train_loss: 0.4773\n",
            "40/75, train_loss: 0.5384\n",
            "41/75, train_loss: 0.5312\n",
            "42/75, train_loss: 0.5461\n",
            "43/75, train_loss: 0.5052\n",
            "44/75, train_loss: 0.5450\n",
            "45/75, train_loss: 0.5441\n",
            "46/75, train_loss: 0.5502\n",
            "47/75, train_loss: 0.4644\n",
            "48/75, train_loss: 0.4848\n",
            "49/75, train_loss: 0.5195\n",
            "50/75, train_loss: 0.5676\n",
            "51/75, train_loss: 0.6045\n",
            "52/75, train_loss: 0.5575\n",
            "53/75, train_loss: 0.4536\n",
            "54/75, train_loss: 0.4469\n",
            "55/75, train_loss: 0.4927\n",
            "56/75, train_loss: 0.6846\n",
            "57/75, train_loss: 0.5074\n",
            "58/75, train_loss: 0.5016\n",
            "59/75, train_loss: 0.4776\n",
            "60/75, train_loss: 0.5739\n",
            "61/75, train_loss: 0.5334\n",
            "62/75, train_loss: 0.5732\n",
            "63/75, train_loss: 0.4198\n",
            "64/75, train_loss: 0.5092\n",
            "65/75, train_loss: 0.5112\n",
            "66/75, train_loss: 0.5371\n",
            "67/75, train_loss: 0.5045\n",
            "68/75, train_loss: 0.4692\n",
            "69/75, train_loss: 0.5762\n",
            "70/75, train_loss: 0.5435\n",
            "71/75, train_loss: 0.5988\n",
            "72/75, train_loss: 0.5065\n",
            "73/75, train_loss: 0.4612\n",
            "74/75, train_loss: 0.5033\n",
            "75/75, train_loss: 0.5010\n",
            "epoch 45 average loss: 0.5104\n",
            "current epoch: 45 current mean dice: 0.7199\n",
            "best mean dice: 0.7549 at epoch: 39\n",
            "----------\n",
            "epoch 46/300\n",
            "1/75, train_loss: 0.5261\n",
            "2/75, train_loss: 0.5925\n",
            "3/75, train_loss: 0.5266\n",
            "4/75, train_loss: 0.5535\n",
            "5/75, train_loss: 0.5175\n",
            "6/75, train_loss: 0.5535\n",
            "7/75, train_loss: 0.5168\n",
            "8/75, train_loss: 0.4813\n",
            "9/75, train_loss: 0.3171\n",
            "10/75, train_loss: 0.4868\n",
            "11/75, train_loss: 0.5483\n",
            "12/75, train_loss: 0.5026\n",
            "13/75, train_loss: 0.4277\n",
            "14/75, train_loss: 0.3261\n",
            "15/75, train_loss: 0.4419\n",
            "16/75, train_loss: 0.4649\n",
            "17/75, train_loss: 0.3915\n",
            "18/75, train_loss: 0.4201\n",
            "19/75, train_loss: 0.4814\n",
            "20/75, train_loss: 0.4355\n",
            "21/75, train_loss: 0.5386\n",
            "22/75, train_loss: 0.5316\n",
            "23/75, train_loss: 0.4826\n",
            "24/75, train_loss: 0.5334\n",
            "25/75, train_loss: 0.6072\n",
            "26/75, train_loss: 0.5882\n",
            "27/75, train_loss: 0.6069\n",
            "28/75, train_loss: 0.5506\n",
            "29/75, train_loss: 0.3802\n",
            "30/75, train_loss: 0.4143\n",
            "31/75, train_loss: 0.5219\n",
            "32/75, train_loss: 0.5634\n",
            "33/75, train_loss: 0.5832\n",
            "34/75, train_loss: 0.5645\n",
            "35/75, train_loss: 0.4907\n",
            "36/75, train_loss: 0.5618\n",
            "37/75, train_loss: 0.3831\n",
            "38/75, train_loss: 0.5610\n",
            "39/75, train_loss: 0.5481\n",
            "40/75, train_loss: 0.4478\n",
            "41/75, train_loss: 0.5664\n",
            "42/75, train_loss: 0.4839\n",
            "43/75, train_loss: 0.5710\n",
            "44/75, train_loss: 0.5195\n",
            "45/75, train_loss: 0.4550\n",
            "46/75, train_loss: 0.5540\n",
            "47/75, train_loss: 0.3972\n",
            "48/75, train_loss: 0.4039\n",
            "49/75, train_loss: 0.5017\n",
            "50/75, train_loss: 0.6052\n",
            "51/75, train_loss: 0.5003\n",
            "52/75, train_loss: 0.5677\n",
            "53/75, train_loss: 0.3302\n",
            "54/75, train_loss: 0.6030\n",
            "55/75, train_loss: 0.4888\n",
            "56/75, train_loss: 0.4148\n",
            "57/75, train_loss: 0.5268\n",
            "58/75, train_loss: 0.5531\n",
            "59/75, train_loss: 0.4708\n",
            "60/75, train_loss: 0.4383\n",
            "61/75, train_loss: 0.5212\n",
            "62/75, train_loss: 0.4990\n",
            "63/75, train_loss: 0.5278\n",
            "64/75, train_loss: 0.5006\n",
            "65/75, train_loss: 0.4338\n",
            "66/75, train_loss: 0.4181\n",
            "67/75, train_loss: 0.5377\n",
            "68/75, train_loss: 0.4845\n",
            "69/75, train_loss: 0.4677\n",
            "70/75, train_loss: 0.5554\n",
            "71/75, train_loss: 0.5306\n",
            "72/75, train_loss: 0.4336\n",
            "73/75, train_loss: 0.6181\n",
            "74/75, train_loss: 0.5583\n",
            "75/75, train_loss: 0.5458\n",
            "epoch 46 average loss: 0.5007\n",
            "current epoch: 46 current mean dice: 0.7291\n",
            "best mean dice: 0.7549 at epoch: 39\n",
            "----------\n",
            "epoch 47/300\n",
            "1/75, train_loss: 0.4223\n",
            "2/75, train_loss: 0.4734\n",
            "3/75, train_loss: 0.5433\n",
            "4/75, train_loss: 0.4905\n",
            "5/75, train_loss: 0.4337\n",
            "6/75, train_loss: 0.4192\n",
            "7/75, train_loss: 0.5461\n",
            "8/75, train_loss: 0.4814\n",
            "9/75, train_loss: 0.4143\n",
            "10/75, train_loss: 0.4201\n",
            "11/75, train_loss: 0.5387\n",
            "12/75, train_loss: 0.4319\n",
            "13/75, train_loss: 0.4093\n",
            "14/75, train_loss: 0.4783\n",
            "15/75, train_loss: 0.5094\n",
            "16/75, train_loss: 0.4696\n",
            "17/75, train_loss: 0.4727\n",
            "18/75, train_loss: 0.5160\n",
            "19/75, train_loss: 0.4660\n",
            "20/75, train_loss: 0.5162\n",
            "21/75, train_loss: 0.4607\n",
            "22/75, train_loss: 0.4577\n",
            "23/75, train_loss: 0.4958\n",
            "24/75, train_loss: 0.5929\n",
            "25/75, train_loss: 0.6377\n",
            "26/75, train_loss: 0.4822\n",
            "27/75, train_loss: 0.5030\n",
            "28/75, train_loss: 0.5549\n",
            "29/75, train_loss: 0.5401\n",
            "30/75, train_loss: 0.5178\n",
            "31/75, train_loss: 0.5778\n",
            "32/75, train_loss: 0.4559\n",
            "33/75, train_loss: 0.4329\n",
            "34/75, train_loss: 0.5091\n",
            "35/75, train_loss: 0.5520\n",
            "36/75, train_loss: 0.3681\n",
            "37/75, train_loss: 0.4224\n",
            "38/75, train_loss: 0.4541\n",
            "39/75, train_loss: 0.4646\n",
            "40/75, train_loss: 0.6260\n",
            "41/75, train_loss: 0.5401\n",
            "42/75, train_loss: 0.5436\n",
            "43/75, train_loss: 0.4707\n",
            "44/75, train_loss: 0.4974\n",
            "45/75, train_loss: 0.5462\n",
            "46/75, train_loss: 0.4997\n",
            "47/75, train_loss: 0.4159\n",
            "48/75, train_loss: 0.4081\n",
            "49/75, train_loss: 0.4037\n",
            "50/75, train_loss: 0.5263\n",
            "51/75, train_loss: 0.5373\n",
            "52/75, train_loss: 0.5516\n",
            "53/75, train_loss: 0.4149\n",
            "54/75, train_loss: 0.5341\n",
            "55/75, train_loss: 0.4265\n",
            "56/75, train_loss: 0.4849\n",
            "57/75, train_loss: 0.4761\n",
            "58/75, train_loss: 0.3541\n",
            "59/75, train_loss: 0.4719\n",
            "60/75, train_loss: 0.5090\n",
            "61/75, train_loss: 0.5279\n",
            "62/75, train_loss: 0.4496\n",
            "63/75, train_loss: 0.6096\n",
            "64/75, train_loss: 0.5425\n",
            "65/75, train_loss: 0.4738\n",
            "66/75, train_loss: 0.5174\n",
            "67/75, train_loss: 0.5315\n",
            "68/75, train_loss: 0.5302\n",
            "69/75, train_loss: 0.5942\n",
            "70/75, train_loss: 0.4123\n",
            "71/75, train_loss: 0.4810\n",
            "72/75, train_loss: 0.5191\n",
            "73/75, train_loss: 0.5461\n",
            "74/75, train_loss: 0.4521\n",
            "75/75, train_loss: 0.5314\n",
            "epoch 47 average loss: 0.4919\n",
            "current epoch: 47 current mean dice: 0.7411\n",
            "best mean dice: 0.7549 at epoch: 39\n",
            "----------\n",
            "epoch 48/300\n",
            "1/75, train_loss: 0.5502\n",
            "2/75, train_loss: 0.5260\n",
            "3/75, train_loss: 0.5281\n",
            "4/75, train_loss: 0.5227\n",
            "5/75, train_loss: 0.4156\n",
            "6/75, train_loss: 0.4645\n",
            "7/75, train_loss: 0.5605\n",
            "8/75, train_loss: 0.5867\n",
            "9/75, train_loss: 0.5084\n",
            "10/75, train_loss: 0.3464\n",
            "11/75, train_loss: 0.4680\n",
            "12/75, train_loss: 0.4878\n",
            "13/75, train_loss: 0.4664\n",
            "14/75, train_loss: 0.4523\n",
            "15/75, train_loss: 0.5669\n",
            "16/75, train_loss: 0.4346\n",
            "17/75, train_loss: 0.4989\n",
            "18/75, train_loss: 0.4141\n",
            "19/75, train_loss: 0.6273\n",
            "20/75, train_loss: 0.3254\n",
            "21/75, train_loss: 0.5656\n",
            "22/75, train_loss: 0.4655\n",
            "23/75, train_loss: 0.5409\n",
            "24/75, train_loss: 0.4454\n",
            "25/75, train_loss: 0.5391\n",
            "26/75, train_loss: 0.4496\n",
            "27/75, train_loss: 0.3306\n",
            "28/75, train_loss: 0.5473\n",
            "29/75, train_loss: 0.5887\n",
            "30/75, train_loss: 0.5243\n",
            "31/75, train_loss: 0.4637\n",
            "32/75, train_loss: 0.5102\n",
            "33/75, train_loss: 0.3949\n",
            "34/75, train_loss: 0.5580\n",
            "35/75, train_loss: 0.5280\n",
            "36/75, train_loss: 0.4995\n",
            "37/75, train_loss: 0.4285\n",
            "38/75, train_loss: 0.5672\n",
            "39/75, train_loss: 0.4869\n",
            "40/75, train_loss: 0.5236\n",
            "41/75, train_loss: 0.5522\n",
            "42/75, train_loss: 0.4636\n",
            "43/75, train_loss: 0.3761\n",
            "44/75, train_loss: 0.6075\n",
            "45/75, train_loss: 0.5007\n",
            "46/75, train_loss: 0.5734\n",
            "47/75, train_loss: 0.5805\n",
            "48/75, train_loss: 0.6310\n",
            "49/75, train_loss: 0.5301\n",
            "50/75, train_loss: 0.5064\n",
            "51/75, train_loss: 0.4988\n",
            "52/75, train_loss: 0.5355\n",
            "53/75, train_loss: 0.5310\n",
            "54/75, train_loss: 0.4844\n",
            "55/75, train_loss: 0.4604\n",
            "56/75, train_loss: 0.4714\n",
            "57/75, train_loss: 0.6073\n",
            "58/75, train_loss: 0.5708\n",
            "59/75, train_loss: 0.4948\n",
            "60/75, train_loss: 0.4954\n",
            "61/75, train_loss: 0.5862\n",
            "62/75, train_loss: 0.5036\n",
            "63/75, train_loss: 0.4770\n",
            "64/75, train_loss: 0.5326\n",
            "65/75, train_loss: 0.3989\n",
            "66/75, train_loss: 0.5282\n",
            "67/75, train_loss: 0.4669\n",
            "68/75, train_loss: 0.5221\n",
            "69/75, train_loss: 0.5743\n",
            "70/75, train_loss: 0.4516\n",
            "71/75, train_loss: 0.5584\n",
            "72/75, train_loss: 0.6049\n",
            "73/75, train_loss: 0.4871\n",
            "74/75, train_loss: 0.4607\n",
            "75/75, train_loss: 0.5013\n",
            "epoch 48 average loss: 0.5044\n",
            "saved new best metric model\n",
            "current epoch: 48 current mean dice: 0.7678\n",
            "best mean dice: 0.7678 at epoch: 48\n",
            "----------\n",
            "epoch 49/300\n",
            "1/75, train_loss: 0.4974\n",
            "2/75, train_loss: 0.4870\n",
            "3/75, train_loss: 0.4536\n",
            "4/75, train_loss: 0.4856\n",
            "5/75, train_loss: 0.4749\n",
            "6/75, train_loss: 0.5430\n",
            "7/75, train_loss: 0.2489\n",
            "8/75, train_loss: 0.4546\n",
            "9/75, train_loss: 0.4889\n",
            "10/75, train_loss: 0.4668\n",
            "11/75, train_loss: 0.3641\n",
            "12/75, train_loss: 0.3692\n",
            "13/75, train_loss: 0.5371\n",
            "14/75, train_loss: 0.4556\n",
            "15/75, train_loss: 0.5303\n",
            "16/75, train_loss: 0.4559\n",
            "17/75, train_loss: 0.5075\n",
            "18/75, train_loss: 0.5267\n",
            "19/75, train_loss: 0.4437\n",
            "20/75, train_loss: 0.5437\n",
            "21/75, train_loss: 0.4302\n",
            "22/75, train_loss: 0.4422\n",
            "23/75, train_loss: 0.5983\n",
            "24/75, train_loss: 0.5647\n",
            "25/75, train_loss: 0.5311\n",
            "26/75, train_loss: 0.4514\n",
            "27/75, train_loss: 0.4245\n",
            "28/75, train_loss: 0.3792\n",
            "29/75, train_loss: 0.5941\n",
            "30/75, train_loss: 0.4792\n",
            "31/75, train_loss: 0.4428\n",
            "32/75, train_loss: 0.3779\n",
            "33/75, train_loss: 0.5342\n",
            "34/75, train_loss: 0.4364\n",
            "35/75, train_loss: 0.4133\n",
            "36/75, train_loss: 0.4746\n",
            "37/75, train_loss: 0.4151\n",
            "38/75, train_loss: 0.4811\n",
            "39/75, train_loss: 0.5421\n",
            "40/75, train_loss: 0.4128\n",
            "41/75, train_loss: 0.4540\n",
            "42/75, train_loss: 0.6031\n",
            "43/75, train_loss: 0.5367\n",
            "44/75, train_loss: 0.4333\n",
            "45/75, train_loss: 0.5687\n",
            "46/75, train_loss: 0.5641\n",
            "47/75, train_loss: 0.6064\n",
            "48/75, train_loss: 0.4609\n",
            "49/75, train_loss: 0.4493\n",
            "50/75, train_loss: 0.4250\n",
            "51/75, train_loss: 0.4446\n",
            "52/75, train_loss: 0.4621\n",
            "53/75, train_loss: 0.4561\n",
            "54/75, train_loss: 0.4764\n",
            "55/75, train_loss: 0.5418\n",
            "56/75, train_loss: 0.5633\n",
            "57/75, train_loss: 0.4948\n",
            "58/75, train_loss: 0.5433\n",
            "59/75, train_loss: 0.4197\n",
            "60/75, train_loss: 0.5152\n",
            "61/75, train_loss: 0.5034\n",
            "62/75, train_loss: 0.4449\n",
            "63/75, train_loss: 0.5057\n",
            "64/75, train_loss: 0.4727\n",
            "65/75, train_loss: 0.4906\n",
            "66/75, train_loss: 0.4964\n",
            "67/75, train_loss: 0.3726\n",
            "68/75, train_loss: 0.4995\n",
            "69/75, train_loss: 0.5751\n",
            "70/75, train_loss: 0.5235\n",
            "71/75, train_loss: 0.3660\n",
            "72/75, train_loss: 0.4390\n",
            "73/75, train_loss: 0.4358\n",
            "74/75, train_loss: 0.5028\n",
            "75/75, train_loss: 0.5120\n",
            "epoch 49 average loss: 0.4789\n",
            "current epoch: 49 current mean dice: 0.7660\n",
            "best mean dice: 0.7678 at epoch: 48\n",
            "----------\n",
            "epoch 50/300\n",
            "1/75, train_loss: 0.5554\n",
            "2/75, train_loss: 0.5428\n",
            "3/75, train_loss: 0.4587\n",
            "4/75, train_loss: 0.5615\n",
            "5/75, train_loss: 0.5141\n",
            "6/75, train_loss: 0.5056\n",
            "7/75, train_loss: 0.4631\n",
            "8/75, train_loss: 0.4488\n",
            "9/75, train_loss: 0.4984\n",
            "10/75, train_loss: 0.4290\n",
            "11/75, train_loss: 0.4531\n",
            "12/75, train_loss: 0.5345\n",
            "13/75, train_loss: 0.5023\n",
            "14/75, train_loss: 0.5816\n",
            "15/75, train_loss: 0.4236\n",
            "16/75, train_loss: 0.5372\n",
            "17/75, train_loss: 0.5025\n",
            "18/75, train_loss: 0.4471\n",
            "19/75, train_loss: 0.3568\n",
            "20/75, train_loss: 0.4254\n",
            "21/75, train_loss: 0.4756\n",
            "22/75, train_loss: 0.5328\n",
            "23/75, train_loss: 0.4254\n",
            "24/75, train_loss: 0.4851\n",
            "25/75, train_loss: 0.4813\n",
            "26/75, train_loss: 0.5474\n",
            "27/75, train_loss: 0.4891\n",
            "28/75, train_loss: 0.4153\n",
            "29/75, train_loss: 0.4775\n",
            "30/75, train_loss: 0.5159\n",
            "31/75, train_loss: 0.4619\n",
            "32/75, train_loss: 0.5800\n",
            "33/75, train_loss: 0.4694\n",
            "34/75, train_loss: 0.4878\n",
            "35/75, train_loss: 0.5468\n",
            "36/75, train_loss: 0.5009\n",
            "37/75, train_loss: 0.4933\n",
            "38/75, train_loss: 0.4648\n",
            "39/75, train_loss: 0.5215\n",
            "40/75, train_loss: 0.4481\n",
            "41/75, train_loss: 0.4501\n",
            "42/75, train_loss: 0.5540\n",
            "43/75, train_loss: 0.4780\n",
            "44/75, train_loss: 0.5591\n",
            "45/75, train_loss: 0.4583\n",
            "46/75, train_loss: 0.4872\n",
            "47/75, train_loss: 0.4623\n",
            "48/75, train_loss: 0.3913\n",
            "49/75, train_loss: 0.5139\n",
            "50/75, train_loss: 0.4682\n",
            "51/75, train_loss: 0.4100\n",
            "52/75, train_loss: 0.5530\n",
            "53/75, train_loss: 0.6134\n",
            "54/75, train_loss: 0.5711\n",
            "55/75, train_loss: 0.4644\n",
            "56/75, train_loss: 0.4425\n",
            "57/75, train_loss: 0.4438\n",
            "58/75, train_loss: 0.5444\n",
            "59/75, train_loss: 0.4940\n",
            "60/75, train_loss: 0.4910\n",
            "61/75, train_loss: 0.5416\n",
            "62/75, train_loss: 0.4398\n",
            "63/75, train_loss: 0.5700\n",
            "64/75, train_loss: 0.4456\n",
            "65/75, train_loss: 0.4106\n",
            "66/75, train_loss: 0.4051\n",
            "67/75, train_loss: 0.3871\n",
            "68/75, train_loss: 0.3685\n",
            "69/75, train_loss: 0.5381\n",
            "70/75, train_loss: 0.5274\n",
            "71/75, train_loss: 0.5492\n",
            "72/75, train_loss: 0.4746\n",
            "73/75, train_loss: 0.6402\n",
            "74/75, train_loss: 0.4340\n",
            "75/75, train_loss: 0.6897\n",
            "epoch 50 average loss: 0.4911\n",
            "current epoch: 50 current mean dice: 0.7617\n",
            "best mean dice: 0.7678 at epoch: 48\n",
            "----------\n",
            "epoch 51/300\n",
            "1/75, train_loss: 0.5064\n",
            "2/75, train_loss: 0.4859\n",
            "3/75, train_loss: 0.5318\n",
            "4/75, train_loss: 0.4976\n",
            "5/75, train_loss: 0.4790\n",
            "6/75, train_loss: 0.5155\n",
            "7/75, train_loss: 0.5592\n",
            "8/75, train_loss: 0.5868\n",
            "9/75, train_loss: 0.5117\n",
            "10/75, train_loss: 0.4903\n",
            "11/75, train_loss: 0.4829\n",
            "12/75, train_loss: 0.4498\n",
            "13/75, train_loss: 0.4634\n",
            "14/75, train_loss: 0.5574\n",
            "15/75, train_loss: 0.4476\n",
            "16/75, train_loss: 0.3926\n",
            "17/75, train_loss: 0.5193\n",
            "18/75, train_loss: 0.5663\n",
            "19/75, train_loss: 0.5248\n",
            "20/75, train_loss: 0.4487\n",
            "21/75, train_loss: 0.4649\n",
            "22/75, train_loss: 0.4095\n",
            "23/75, train_loss: 0.5316\n",
            "24/75, train_loss: 0.5196\n",
            "25/75, train_loss: 0.4733\n",
            "26/75, train_loss: 0.4374\n",
            "27/75, train_loss: 0.5367\n",
            "28/75, train_loss: 0.4936\n",
            "29/75, train_loss: 0.4463\n",
            "30/75, train_loss: 0.4211\n",
            "31/75, train_loss: 0.4440\n",
            "32/75, train_loss: 0.4785\n",
            "33/75, train_loss: 0.3111\n",
            "34/75, train_loss: 0.5171\n",
            "35/75, train_loss: 0.5625\n",
            "36/75, train_loss: 0.4942\n",
            "37/75, train_loss: 0.4692\n",
            "38/75, train_loss: 0.5220\n",
            "39/75, train_loss: 0.5064\n",
            "40/75, train_loss: 0.5321\n",
            "41/75, train_loss: 0.4063\n",
            "42/75, train_loss: 0.5014\n",
            "43/75, train_loss: 0.5328\n",
            "44/75, train_loss: 0.6106\n",
            "45/75, train_loss: 0.3645\n",
            "46/75, train_loss: 0.5506\n",
            "47/75, train_loss: 0.5328\n",
            "48/75, train_loss: 0.6195\n",
            "49/75, train_loss: 0.5038\n",
            "50/75, train_loss: 0.5330\n",
            "51/75, train_loss: 0.4260\n",
            "52/75, train_loss: 0.6221\n",
            "53/75, train_loss: 0.4445\n",
            "54/75, train_loss: 0.5239\n",
            "55/75, train_loss: 0.4827\n",
            "56/75, train_loss: 0.3817\n",
            "57/75, train_loss: 0.4011\n",
            "58/75, train_loss: 0.6274\n",
            "59/75, train_loss: 0.4912\n",
            "60/75, train_loss: 0.4677\n",
            "61/75, train_loss: 0.5536\n",
            "62/75, train_loss: 0.5936\n",
            "63/75, train_loss: 0.5023\n",
            "64/75, train_loss: 0.4297\n",
            "65/75, train_loss: 0.5180\n",
            "66/75, train_loss: 0.3698\n",
            "67/75, train_loss: 0.4961\n",
            "68/75, train_loss: 0.5248\n",
            "69/75, train_loss: 0.5144\n",
            "70/75, train_loss: 0.4700\n",
            "71/75, train_loss: 0.4201\n",
            "72/75, train_loss: 0.5051\n",
            "73/75, train_loss: 0.4648\n",
            "74/75, train_loss: 0.4936\n",
            "75/75, train_loss: 0.5450\n",
            "epoch 51 average loss: 0.4935\n",
            "current epoch: 51 current mean dice: 0.7436\n",
            "best mean dice: 0.7678 at epoch: 48\n",
            "----------\n",
            "epoch 52/300\n",
            "1/75, train_loss: 0.5024\n",
            "2/75, train_loss: 0.5135\n",
            "3/75, train_loss: 0.4565\n",
            "4/75, train_loss: 0.4597\n",
            "5/75, train_loss: 0.5097\n",
            "6/75, train_loss: 0.4975\n",
            "7/75, train_loss: 0.4405\n",
            "8/75, train_loss: 0.5264\n",
            "9/75, train_loss: 0.2914\n",
            "10/75, train_loss: 0.4836\n",
            "11/75, train_loss: 0.4784\n",
            "12/75, train_loss: 0.4310\n",
            "13/75, train_loss: 0.4758\n",
            "14/75, train_loss: 0.5580\n",
            "15/75, train_loss: 0.5415\n",
            "16/75, train_loss: 0.4305\n",
            "17/75, train_loss: 0.4314\n",
            "18/75, train_loss: 0.4803\n",
            "19/75, train_loss: 0.4945\n",
            "20/75, train_loss: 0.4585\n",
            "21/75, train_loss: 0.5115\n",
            "22/75, train_loss: 0.5546\n",
            "23/75, train_loss: 0.4404\n",
            "24/75, train_loss: 0.4847\n",
            "25/75, train_loss: 0.5050\n",
            "26/75, train_loss: 0.5020\n",
            "27/75, train_loss: 0.5566\n",
            "28/75, train_loss: 0.6278\n",
            "29/75, train_loss: 0.3965\n",
            "30/75, train_loss: 0.4138\n",
            "31/75, train_loss: 0.5811\n",
            "32/75, train_loss: 0.5221\n",
            "33/75, train_loss: 0.4644\n",
            "34/75, train_loss: 0.6165\n",
            "35/75, train_loss: 0.4510\n",
            "36/75, train_loss: 0.5287\n",
            "37/75, train_loss: 0.5980\n",
            "38/75, train_loss: 0.5065\n",
            "39/75, train_loss: 0.5391\n",
            "40/75, train_loss: 0.5511\n",
            "41/75, train_loss: 0.5060\n",
            "42/75, train_loss: 0.3804\n",
            "43/75, train_loss: 0.4257\n",
            "44/75, train_loss: 0.6593\n",
            "45/75, train_loss: 0.6509\n",
            "46/75, train_loss: 0.4889\n",
            "47/75, train_loss: 0.5108\n",
            "48/75, train_loss: 0.5073\n",
            "49/75, train_loss: 0.5085\n",
            "50/75, train_loss: 0.5588\n",
            "51/75, train_loss: 0.4377\n",
            "52/75, train_loss: 0.4278\n",
            "53/75, train_loss: 0.3439\n",
            "54/75, train_loss: 0.5605\n",
            "55/75, train_loss: 0.3904\n",
            "56/75, train_loss: 0.5325\n",
            "57/75, train_loss: 0.5494\n",
            "58/75, train_loss: 0.5625\n",
            "59/75, train_loss: 0.4744\n",
            "60/75, train_loss: 0.4988\n",
            "61/75, train_loss: 0.5451\n",
            "62/75, train_loss: 0.4382\n",
            "63/75, train_loss: 0.4306\n",
            "64/75, train_loss: 0.5211\n",
            "65/75, train_loss: 0.4526\n",
            "66/75, train_loss: 0.4633\n",
            "67/75, train_loss: 0.5049\n",
            "68/75, train_loss: 0.5054\n",
            "69/75, train_loss: 0.5445\n",
            "70/75, train_loss: 0.4254\n",
            "71/75, train_loss: 0.4751\n",
            "72/75, train_loss: 0.5342\n",
            "73/75, train_loss: 0.5451\n",
            "74/75, train_loss: 0.4347\n",
            "75/75, train_loss: 0.6165\n",
            "epoch 52 average loss: 0.4963\n",
            "current epoch: 52 current mean dice: 0.7344\n",
            "best mean dice: 0.7678 at epoch: 48\n",
            "----------\n",
            "epoch 53/300\n",
            "1/75, train_loss: 0.4193\n",
            "2/75, train_loss: 0.3686\n",
            "3/75, train_loss: 0.4510\n",
            "4/75, train_loss: 0.4203\n",
            "5/75, train_loss: 0.4427\n",
            "6/75, train_loss: 0.4901\n",
            "7/75, train_loss: 0.6060\n",
            "8/75, train_loss: 0.5227\n",
            "9/75, train_loss: 0.4216\n",
            "10/75, train_loss: 0.5368\n",
            "11/75, train_loss: 0.4650\n",
            "12/75, train_loss: 0.4186\n",
            "13/75, train_loss: 0.5903\n",
            "14/75, train_loss: 0.4800\n",
            "15/75, train_loss: 0.4149\n",
            "16/75, train_loss: 0.3321\n",
            "17/75, train_loss: 0.5426\n",
            "18/75, train_loss: 0.5200\n",
            "19/75, train_loss: 0.3984\n",
            "20/75, train_loss: 0.5330\n",
            "21/75, train_loss: 0.4739\n",
            "22/75, train_loss: 0.5328\n",
            "23/75, train_loss: 0.5291\n",
            "24/75, train_loss: 0.5268\n",
            "25/75, train_loss: 0.5143\n",
            "26/75, train_loss: 0.4853\n",
            "27/75, train_loss: 0.3105\n",
            "28/75, train_loss: 0.5165\n",
            "29/75, train_loss: 0.4452\n",
            "30/75, train_loss: 0.4662\n",
            "31/75, train_loss: 0.5590\n",
            "32/75, train_loss: 0.4827\n",
            "33/75, train_loss: 0.4218\n",
            "34/75, train_loss: 0.3683\n",
            "35/75, train_loss: 0.5430\n",
            "36/75, train_loss: 0.5508\n",
            "37/75, train_loss: 0.4728\n",
            "38/75, train_loss: 0.5082\n",
            "39/75, train_loss: 0.5464\n",
            "40/75, train_loss: 0.4400\n",
            "41/75, train_loss: 0.3927\n",
            "42/75, train_loss: 0.4928\n",
            "43/75, train_loss: 0.5909\n",
            "44/75, train_loss: 0.4436\n",
            "45/75, train_loss: 0.5945\n",
            "46/75, train_loss: 0.3613\n",
            "47/75, train_loss: 0.5279\n",
            "48/75, train_loss: 0.5254\n",
            "49/75, train_loss: 0.5815\n",
            "50/75, train_loss: 0.2993\n",
            "51/75, train_loss: 0.4258\n",
            "52/75, train_loss: 0.4349\n",
            "53/75, train_loss: 0.3909\n",
            "54/75, train_loss: 0.4557\n",
            "55/75, train_loss: 0.5627\n",
            "56/75, train_loss: 0.4867\n",
            "57/75, train_loss: 0.4524\n",
            "58/75, train_loss: 0.4868\n",
            "59/75, train_loss: 0.5222\n",
            "60/75, train_loss: 0.5394\n",
            "61/75, train_loss: 0.5096\n",
            "62/75, train_loss: 0.4153\n",
            "63/75, train_loss: 0.5567\n",
            "64/75, train_loss: 0.6230\n",
            "65/75, train_loss: 0.4050\n",
            "66/75, train_loss: 0.4949\n",
            "67/75, train_loss: 0.5077\n",
            "68/75, train_loss: 0.4584\n",
            "69/75, train_loss: 0.5801\n",
            "70/75, train_loss: 0.4731\n",
            "71/75, train_loss: 0.4373\n",
            "72/75, train_loss: 0.5639\n",
            "73/75, train_loss: 0.4991\n",
            "74/75, train_loss: 0.5195\n",
            "75/75, train_loss: 0.4707\n",
            "epoch 53 average loss: 0.4820\n",
            "current epoch: 53 current mean dice: 0.7634\n",
            "best mean dice: 0.7678 at epoch: 48\n",
            "----------\n",
            "epoch 54/300\n",
            "1/75, train_loss: 0.5155\n",
            "2/75, train_loss: 0.5090\n",
            "3/75, train_loss: 0.4530\n",
            "4/75, train_loss: 0.4551\n",
            "5/75, train_loss: 0.4681\n",
            "6/75, train_loss: 0.4878\n",
            "7/75, train_loss: 0.5174\n",
            "8/75, train_loss: 0.6079\n",
            "9/75, train_loss: 0.4503\n",
            "10/75, train_loss: 0.4133\n",
            "11/75, train_loss: 0.4433\n",
            "12/75, train_loss: 0.5428\n",
            "13/75, train_loss: 0.4982\n",
            "14/75, train_loss: 0.4036\n",
            "15/75, train_loss: 0.4470\n",
            "16/75, train_loss: 0.4635\n",
            "17/75, train_loss: 0.4970\n",
            "18/75, train_loss: 0.4630\n",
            "19/75, train_loss: 0.5237\n",
            "20/75, train_loss: 0.3495\n",
            "21/75, train_loss: 0.5886\n",
            "22/75, train_loss: 0.4307\n",
            "23/75, train_loss: 0.5881\n",
            "24/75, train_loss: 0.4936\n",
            "25/75, train_loss: 0.4504\n",
            "26/75, train_loss: 0.2948\n",
            "27/75, train_loss: 0.4460\n",
            "28/75, train_loss: 0.4575\n",
            "29/75, train_loss: 0.5310\n",
            "30/75, train_loss: 0.4199\n",
            "31/75, train_loss: 0.6551\n",
            "32/75, train_loss: 0.4727\n",
            "33/75, train_loss: 0.4291\n",
            "34/75, train_loss: 0.5166\n",
            "35/75, train_loss: 0.4203\n",
            "36/75, train_loss: 0.4517\n",
            "37/75, train_loss: 0.4191\n",
            "38/75, train_loss: 0.4684\n",
            "39/75, train_loss: 0.4520\n",
            "40/75, train_loss: 0.4463\n",
            "41/75, train_loss: 0.4579\n",
            "42/75, train_loss: 0.5947\n",
            "43/75, train_loss: 0.4129\n",
            "44/75, train_loss: 0.5037\n",
            "45/75, train_loss: 0.4990\n",
            "46/75, train_loss: 0.4719\n",
            "47/75, train_loss: 0.4585\n",
            "48/75, train_loss: 0.4492\n",
            "49/75, train_loss: 0.4497\n",
            "50/75, train_loss: 0.4532\n",
            "51/75, train_loss: 0.5649\n",
            "52/75, train_loss: 0.5403\n",
            "53/75, train_loss: 0.3816\n",
            "54/75, train_loss: 0.4346\n",
            "55/75, train_loss: 0.5174\n",
            "56/75, train_loss: 0.4292\n",
            "57/75, train_loss: 0.4059\n",
            "58/75, train_loss: 0.4924\n",
            "59/75, train_loss: 0.4663\n",
            "60/75, train_loss: 0.5639\n",
            "61/75, train_loss: 0.5009\n",
            "62/75, train_loss: 0.6347\n",
            "63/75, train_loss: 0.4018\n",
            "64/75, train_loss: 0.4816\n",
            "65/75, train_loss: 0.4764\n",
            "66/75, train_loss: 0.4906\n",
            "67/75, train_loss: 0.4617\n",
            "68/75, train_loss: 0.5437\n",
            "69/75, train_loss: 0.4483\n",
            "70/75, train_loss: 0.5532\n",
            "71/75, train_loss: 0.5386\n",
            "72/75, train_loss: 0.5031\n",
            "73/75, train_loss: 0.5232\n",
            "74/75, train_loss: 0.4717\n",
            "75/75, train_loss: 0.6119\n",
            "epoch 54 average loss: 0.4817\n",
            "saved new best metric model\n",
            "current epoch: 54 current mean dice: 0.7955\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 55/300\n",
            "1/75, train_loss: 0.5291\n",
            "2/75, train_loss: 0.3852\n",
            "3/75, train_loss: 0.4329\n",
            "4/75, train_loss: 0.5925\n",
            "5/75, train_loss: 0.4563\n",
            "6/75, train_loss: 0.4227\n",
            "7/75, train_loss: 0.4744\n",
            "8/75, train_loss: 0.4364\n",
            "9/75, train_loss: 0.4156\n",
            "10/75, train_loss: 0.4870\n",
            "11/75, train_loss: 0.5093\n",
            "12/75, train_loss: 0.4296\n",
            "13/75, train_loss: 0.5102\n",
            "14/75, train_loss: 0.5134\n",
            "15/75, train_loss: 0.4778\n",
            "16/75, train_loss: 0.4262\n",
            "17/75, train_loss: 0.4867\n",
            "18/75, train_loss: 0.4776\n",
            "19/75, train_loss: 0.4597\n",
            "20/75, train_loss: 0.5234\n",
            "21/75, train_loss: 0.5157\n",
            "22/75, train_loss: 0.5766\n",
            "23/75, train_loss: 0.5823\n",
            "24/75, train_loss: 0.4114\n",
            "25/75, train_loss: 0.4670\n",
            "26/75, train_loss: 0.5095\n",
            "27/75, train_loss: 0.5396\n",
            "28/75, train_loss: 0.4902\n",
            "29/75, train_loss: 0.5313\n",
            "30/75, train_loss: 0.4975\n",
            "31/75, train_loss: 0.5447\n",
            "32/75, train_loss: 0.4083\n",
            "33/75, train_loss: 0.4668\n",
            "34/75, train_loss: 0.3704\n",
            "35/75, train_loss: 0.5008\n",
            "36/75, train_loss: 0.4485\n",
            "37/75, train_loss: 0.4523\n",
            "38/75, train_loss: 0.5138\n",
            "39/75, train_loss: 0.5228\n",
            "40/75, train_loss: 0.5081\n",
            "41/75, train_loss: 0.4466\n",
            "42/75, train_loss: 0.5008\n",
            "43/75, train_loss: 0.4865\n",
            "44/75, train_loss: 0.5310\n",
            "45/75, train_loss: 0.5195\n",
            "46/75, train_loss: 0.3647\n",
            "47/75, train_loss: 0.5312\n",
            "48/75, train_loss: 0.3991\n",
            "49/75, train_loss: 0.5484\n",
            "50/75, train_loss: 0.5908\n",
            "51/75, train_loss: 0.5218\n",
            "52/75, train_loss: 0.4403\n",
            "53/75, train_loss: 0.4369\n",
            "54/75, train_loss: 0.4285\n",
            "55/75, train_loss: 0.6313\n",
            "56/75, train_loss: 0.3496\n",
            "57/75, train_loss: 0.5005\n",
            "58/75, train_loss: 0.4071\n",
            "59/75, train_loss: 0.4267\n",
            "60/75, train_loss: 0.3566\n",
            "61/75, train_loss: 0.4432\n",
            "62/75, train_loss: 0.4589\n",
            "63/75, train_loss: 0.4375\n",
            "64/75, train_loss: 0.6220\n",
            "65/75, train_loss: 0.4048\n",
            "66/75, train_loss: 0.5518\n",
            "67/75, train_loss: 0.4758\n",
            "68/75, train_loss: 0.4529\n",
            "69/75, train_loss: 0.5091\n",
            "70/75, train_loss: 0.4998\n",
            "71/75, train_loss: 0.4488\n",
            "72/75, train_loss: 0.5306\n",
            "73/75, train_loss: 0.4620\n",
            "74/75, train_loss: 0.5601\n",
            "75/75, train_loss: 0.5994\n",
            "epoch 55 average loss: 0.4824\n",
            "current epoch: 55 current mean dice: 0.7736\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 56/300\n",
            "1/75, train_loss: 0.5353\n",
            "2/75, train_loss: 0.4289\n",
            "3/75, train_loss: 0.3815\n",
            "4/75, train_loss: 0.4694\n",
            "5/75, train_loss: 0.5047\n",
            "6/75, train_loss: 0.4734\n",
            "7/75, train_loss: 0.4582\n",
            "8/75, train_loss: 0.4792\n",
            "9/75, train_loss: 0.4810\n",
            "10/75, train_loss: 0.4544\n",
            "11/75, train_loss: 0.5105\n",
            "12/75, train_loss: 0.3290\n",
            "13/75, train_loss: 0.4141\n",
            "14/75, train_loss: 0.3718\n",
            "15/75, train_loss: 0.4701\n",
            "16/75, train_loss: 0.4685\n",
            "17/75, train_loss: 0.4006\n",
            "18/75, train_loss: 0.4598\n",
            "19/75, train_loss: 0.4058\n",
            "20/75, train_loss: 0.3731\n",
            "21/75, train_loss: 0.5436\n",
            "22/75, train_loss: 0.4859\n",
            "23/75, train_loss: 0.4723\n",
            "24/75, train_loss: 0.5318\n",
            "25/75, train_loss: 0.4461\n",
            "26/75, train_loss: 0.4340\n",
            "27/75, train_loss: 0.3940\n",
            "28/75, train_loss: 0.4660\n",
            "29/75, train_loss: 0.4772\n",
            "30/75, train_loss: 0.4641\n",
            "31/75, train_loss: 0.5236\n",
            "32/75, train_loss: 0.4580\n",
            "33/75, train_loss: 0.4631\n",
            "34/75, train_loss: 0.4887\n",
            "35/75, train_loss: 0.5041\n",
            "36/75, train_loss: 0.3391\n",
            "37/75, train_loss: 0.4848\n",
            "38/75, train_loss: 0.5657\n",
            "39/75, train_loss: 0.5214\n",
            "40/75, train_loss: 0.3726\n",
            "41/75, train_loss: 0.6030\n",
            "42/75, train_loss: 0.3703\n",
            "43/75, train_loss: 0.4869\n",
            "44/75, train_loss: 0.6475\n",
            "45/75, train_loss: 0.5891\n",
            "46/75, train_loss: 0.5190\n",
            "47/75, train_loss: 0.4539\n",
            "48/75, train_loss: 0.5184\n",
            "49/75, train_loss: 0.4953\n",
            "50/75, train_loss: 0.5272\n",
            "51/75, train_loss: 0.4573\n",
            "52/75, train_loss: 0.5256\n",
            "53/75, train_loss: 0.4331\n",
            "54/75, train_loss: 0.4705\n",
            "55/75, train_loss: 0.6251\n",
            "56/75, train_loss: 0.3899\n",
            "57/75, train_loss: 0.4188\n",
            "58/75, train_loss: 0.4850\n",
            "59/75, train_loss: 0.4592\n",
            "60/75, train_loss: 0.4895\n",
            "61/75, train_loss: 0.4703\n",
            "62/75, train_loss: 0.5521\n",
            "63/75, train_loss: 0.5031\n",
            "64/75, train_loss: 0.4393\n",
            "65/75, train_loss: 0.4346\n",
            "66/75, train_loss: 0.5946\n",
            "67/75, train_loss: 0.4458\n",
            "68/75, train_loss: 0.4444\n",
            "69/75, train_loss: 0.5043\n",
            "70/75, train_loss: 0.4644\n",
            "71/75, train_loss: 0.5192\n",
            "72/75, train_loss: 0.5442\n",
            "73/75, train_loss: 0.4621\n",
            "74/75, train_loss: 0.5164\n",
            "75/75, train_loss: 0.4622\n",
            "epoch 56 average loss: 0.4750\n",
            "current epoch: 56 current mean dice: 0.7670\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 57/300\n",
            "1/75, train_loss: 0.5184\n",
            "2/75, train_loss: 0.5372\n",
            "3/75, train_loss: 0.4296\n",
            "4/75, train_loss: 0.3763\n",
            "5/75, train_loss: 0.4717\n",
            "6/75, train_loss: 0.5035\n",
            "7/75, train_loss: 0.5156\n",
            "8/75, train_loss: 0.5866\n",
            "9/75, train_loss: 0.4772\n",
            "10/75, train_loss: 0.5291\n",
            "11/75, train_loss: 0.3772\n",
            "12/75, train_loss: 0.4608\n",
            "13/75, train_loss: 0.5007\n",
            "14/75, train_loss: 0.3892\n",
            "15/75, train_loss: 0.5671\n",
            "16/75, train_loss: 0.3403\n",
            "17/75, train_loss: 0.4822\n",
            "18/75, train_loss: 0.4446\n",
            "19/75, train_loss: 0.5173\n",
            "20/75, train_loss: 0.5153\n",
            "21/75, train_loss: 0.5146\n",
            "22/75, train_loss: 0.4061\n",
            "23/75, train_loss: 0.5364\n",
            "24/75, train_loss: 0.4721\n",
            "25/75, train_loss: 0.3578\n",
            "26/75, train_loss: 0.4762\n",
            "27/75, train_loss: 0.4701\n",
            "28/75, train_loss: 0.4801\n",
            "29/75, train_loss: 0.4956\n",
            "30/75, train_loss: 0.5519\n",
            "31/75, train_loss: 0.5096\n",
            "32/75, train_loss: 0.5259\n",
            "33/75, train_loss: 0.3860\n",
            "34/75, train_loss: 0.5302\n",
            "35/75, train_loss: 0.4406\n",
            "36/75, train_loss: 0.4211\n",
            "37/75, train_loss: 0.3853\n",
            "38/75, train_loss: 0.4827\n",
            "39/75, train_loss: 0.4103\n",
            "40/75, train_loss: 0.5390\n",
            "41/75, train_loss: 0.4827\n",
            "42/75, train_loss: 0.6066\n",
            "43/75, train_loss: 0.3375\n",
            "44/75, train_loss: 0.4564\n",
            "45/75, train_loss: 0.4884\n",
            "46/75, train_loss: 0.4628\n",
            "47/75, train_loss: 0.5291\n",
            "48/75, train_loss: 0.4553\n",
            "49/75, train_loss: 0.5478\n",
            "50/75, train_loss: 0.5639\n",
            "51/75, train_loss: 0.4721\n",
            "52/75, train_loss: 0.6455\n",
            "53/75, train_loss: 0.4019\n",
            "54/75, train_loss: 0.3109\n",
            "55/75, train_loss: 0.5119\n",
            "56/75, train_loss: 0.4332\n",
            "57/75, train_loss: 0.5076\n",
            "58/75, train_loss: 0.4933\n",
            "59/75, train_loss: 0.5144\n",
            "60/75, train_loss: 0.4893\n",
            "61/75, train_loss: 0.5014\n",
            "62/75, train_loss: 0.4285\n",
            "63/75, train_loss: 0.4299\n",
            "64/75, train_loss: 0.5648\n",
            "65/75, train_loss: 0.4128\n",
            "66/75, train_loss: 0.3563\n",
            "67/75, train_loss: 0.4270\n",
            "68/75, train_loss: 0.4641\n",
            "69/75, train_loss: 0.5587\n",
            "70/75, train_loss: 0.5324\n",
            "71/75, train_loss: 0.6056\n",
            "72/75, train_loss: 0.4505\n",
            "73/75, train_loss: 0.5377\n",
            "74/75, train_loss: 0.4750\n",
            "75/75, train_loss: 0.4931\n",
            "epoch 57 average loss: 0.4784\n",
            "current epoch: 57 current mean dice: 0.7865\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 58/300\n",
            "1/75, train_loss: 0.5191\n",
            "2/75, train_loss: 0.3646\n",
            "3/75, train_loss: 0.5117\n",
            "4/75, train_loss: 0.4152\n",
            "5/75, train_loss: 0.4560\n",
            "6/75, train_loss: 0.4517\n",
            "7/75, train_loss: 0.3491\n",
            "8/75, train_loss: 0.5667\n",
            "9/75, train_loss: 0.3472\n",
            "10/75, train_loss: 0.5611\n",
            "11/75, train_loss: 0.5461\n",
            "12/75, train_loss: 0.4379\n",
            "13/75, train_loss: 0.3548\n",
            "14/75, train_loss: 0.4667\n",
            "15/75, train_loss: 0.5742\n",
            "16/75, train_loss: 0.3477\n",
            "17/75, train_loss: 0.4776\n",
            "18/75, train_loss: 0.4255\n",
            "19/75, train_loss: 0.5152\n",
            "20/75, train_loss: 0.4723\n",
            "21/75, train_loss: 0.4551\n",
            "22/75, train_loss: 0.5174\n",
            "23/75, train_loss: 0.4291\n",
            "24/75, train_loss: 0.4326\n",
            "25/75, train_loss: 0.4517\n",
            "26/75, train_loss: 0.4730\n",
            "27/75, train_loss: 0.4190\n",
            "28/75, train_loss: 0.5308\n",
            "29/75, train_loss: 0.3764\n",
            "30/75, train_loss: 0.4300\n",
            "31/75, train_loss: 0.2951\n",
            "32/75, train_loss: 0.5268\n",
            "33/75, train_loss: 0.4021\n",
            "34/75, train_loss: 0.5304\n",
            "35/75, train_loss: 0.3945\n",
            "36/75, train_loss: 0.4756\n",
            "37/75, train_loss: 0.4514\n",
            "38/75, train_loss: 0.4870\n",
            "39/75, train_loss: 0.4437\n",
            "40/75, train_loss: 0.4524\n",
            "41/75, train_loss: 0.5138\n",
            "42/75, train_loss: 0.5185\n",
            "43/75, train_loss: 0.5293\n",
            "44/75, train_loss: 0.5005\n",
            "45/75, train_loss: 0.5075\n",
            "46/75, train_loss: 0.4975\n",
            "47/75, train_loss: 0.5260\n",
            "48/75, train_loss: 0.4610\n",
            "49/75, train_loss: 0.6651\n",
            "50/75, train_loss: 0.4576\n",
            "51/75, train_loss: 0.4812\n",
            "52/75, train_loss: 0.5298\n",
            "53/75, train_loss: 0.5410\n",
            "54/75, train_loss: 0.5751\n",
            "55/75, train_loss: 0.5883\n",
            "56/75, train_loss: 0.5142\n",
            "57/75, train_loss: 0.4989\n",
            "58/75, train_loss: 0.4816\n",
            "59/75, train_loss: 0.5918\n",
            "60/75, train_loss: 0.5929\n",
            "61/75, train_loss: 0.4697\n",
            "62/75, train_loss: 0.5014\n",
            "63/75, train_loss: 0.5625\n",
            "64/75, train_loss: 0.4255\n",
            "65/75, train_loss: 0.4678\n",
            "66/75, train_loss: 0.4522\n",
            "67/75, train_loss: 0.4804\n",
            "68/75, train_loss: 0.4585\n",
            "69/75, train_loss: 0.6199\n",
            "70/75, train_loss: 0.5029\n",
            "71/75, train_loss: 0.4469\n",
            "72/75, train_loss: 0.3209\n",
            "73/75, train_loss: 0.4701\n",
            "74/75, train_loss: 0.4373\n",
            "75/75, train_loss: 0.6714\n",
            "epoch 58 average loss: 0.4799\n",
            "current epoch: 58 current mean dice: 0.6725\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 59/300\n",
            "1/75, train_loss: 0.5843\n",
            "2/75, train_loss: 0.4895\n",
            "3/75, train_loss: 0.5984\n",
            "4/75, train_loss: 0.4475\n",
            "5/75, train_loss: 0.4537\n",
            "6/75, train_loss: 0.5329\n",
            "7/75, train_loss: 0.4259\n",
            "8/75, train_loss: 0.3927\n",
            "9/75, train_loss: 0.4227\n",
            "10/75, train_loss: 0.4110\n",
            "11/75, train_loss: 0.4808\n",
            "12/75, train_loss: 0.4270\n",
            "13/75, train_loss: 0.5961\n",
            "14/75, train_loss: 0.5023\n",
            "15/75, train_loss: 0.4153\n",
            "16/75, train_loss: 0.4809\n",
            "17/75, train_loss: 0.5706\n",
            "18/75, train_loss: 0.4652\n",
            "19/75, train_loss: 0.5187\n",
            "20/75, train_loss: 0.3723\n",
            "21/75, train_loss: 0.4853\n",
            "22/75, train_loss: 0.5107\n",
            "23/75, train_loss: 0.3983\n",
            "24/75, train_loss: 0.4883\n",
            "25/75, train_loss: 0.4038\n",
            "26/75, train_loss: 0.4995\n",
            "27/75, train_loss: 0.4691\n",
            "28/75, train_loss: 0.4655\n",
            "29/75, train_loss: 0.5787\n",
            "30/75, train_loss: 0.4251\n",
            "31/75, train_loss: 0.4044\n",
            "32/75, train_loss: 0.4491\n",
            "33/75, train_loss: 0.4180\n",
            "34/75, train_loss: 0.5500\n",
            "35/75, train_loss: 0.4586\n",
            "36/75, train_loss: 0.5865\n",
            "37/75, train_loss: 0.5059\n",
            "38/75, train_loss: 0.4515\n",
            "39/75, train_loss: 0.3936\n",
            "40/75, train_loss: 0.3628\n",
            "41/75, train_loss: 0.3589\n",
            "42/75, train_loss: 0.3369\n",
            "43/75, train_loss: 0.5591\n",
            "44/75, train_loss: 0.4430\n",
            "45/75, train_loss: 0.5277\n",
            "46/75, train_loss: 0.4465\n",
            "47/75, train_loss: 0.4744\n",
            "48/75, train_loss: 0.4655\n",
            "49/75, train_loss: 0.4973\n",
            "50/75, train_loss: 0.4444\n",
            "51/75, train_loss: 0.6155\n",
            "52/75, train_loss: 0.4687\n",
            "53/75, train_loss: 0.4871\n",
            "54/75, train_loss: 0.3909\n",
            "55/75, train_loss: 0.4371\n",
            "56/75, train_loss: 0.4746\n",
            "57/75, train_loss: 0.5840\n",
            "58/75, train_loss: 0.5575\n",
            "59/75, train_loss: 0.5177\n",
            "60/75, train_loss: 0.5167\n",
            "61/75, train_loss: 0.5322\n",
            "62/75, train_loss: 0.5550\n",
            "63/75, train_loss: 0.6150\n",
            "64/75, train_loss: 0.4896\n",
            "65/75, train_loss: 0.3999\n",
            "66/75, train_loss: 0.4996\n",
            "67/75, train_loss: 0.4580\n",
            "68/75, train_loss: 0.3414\n",
            "69/75, train_loss: 0.4990\n",
            "70/75, train_loss: 0.3760\n",
            "71/75, train_loss: 0.4092\n",
            "72/75, train_loss: 0.4946\n",
            "73/75, train_loss: 0.5706\n",
            "74/75, train_loss: 0.5718\n",
            "75/75, train_loss: 0.5502\n",
            "epoch 59 average loss: 0.4781\n",
            "current epoch: 59 current mean dice: 0.7634\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 60/300\n",
            "1/75, train_loss: 0.4733\n",
            "2/75, train_loss: 0.4813\n",
            "3/75, train_loss: 0.3955\n",
            "4/75, train_loss: 0.4964\n",
            "5/75, train_loss: 0.4607\n",
            "6/75, train_loss: 0.4787\n",
            "7/75, train_loss: 0.4329\n",
            "8/75, train_loss: 0.4158\n",
            "9/75, train_loss: 0.4704\n",
            "10/75, train_loss: 0.4898\n",
            "11/75, train_loss: 0.5759\n",
            "12/75, train_loss: 0.5061\n",
            "13/75, train_loss: 0.4836\n",
            "14/75, train_loss: 0.4459\n",
            "15/75, train_loss: 0.5005\n",
            "16/75, train_loss: 0.3926\n",
            "17/75, train_loss: 0.4095\n",
            "18/75, train_loss: 0.4494\n",
            "19/75, train_loss: 0.3771\n",
            "20/75, train_loss: 0.4887\n",
            "21/75, train_loss: 0.4088\n",
            "22/75, train_loss: 0.5653\n",
            "23/75, train_loss: 0.5327\n",
            "24/75, train_loss: 0.5446\n",
            "25/75, train_loss: 0.4910\n",
            "26/75, train_loss: 0.5625\n",
            "27/75, train_loss: 0.6695\n",
            "28/75, train_loss: 0.5379\n",
            "29/75, train_loss: 0.5047\n",
            "30/75, train_loss: 0.4259\n",
            "31/75, train_loss: 0.3833\n",
            "32/75, train_loss: 0.4566\n",
            "33/75, train_loss: 0.5269\n",
            "34/75, train_loss: 0.4103\n",
            "35/75, train_loss: 0.5104\n",
            "36/75, train_loss: 0.5240\n",
            "37/75, train_loss: 0.3678\n",
            "38/75, train_loss: 0.5585\n",
            "39/75, train_loss: 0.3816\n",
            "40/75, train_loss: 0.4762\n",
            "41/75, train_loss: 0.5318\n",
            "42/75, train_loss: 0.4598\n",
            "43/75, train_loss: 0.6194\n",
            "44/75, train_loss: 0.4993\n",
            "45/75, train_loss: 0.4703\n",
            "46/75, train_loss: 0.5636\n",
            "47/75, train_loss: 0.4276\n",
            "48/75, train_loss: 0.5424\n",
            "49/75, train_loss: 0.5216\n",
            "50/75, train_loss: 0.4095\n",
            "51/75, train_loss: 0.4298\n",
            "52/75, train_loss: 0.3098\n",
            "53/75, train_loss: 0.4250\n",
            "54/75, train_loss: 0.4966\n",
            "55/75, train_loss: 0.3602\n",
            "56/75, train_loss: 0.4712\n",
            "57/75, train_loss: 0.4796\n",
            "58/75, train_loss: 0.5188\n",
            "59/75, train_loss: 0.4717\n",
            "60/75, train_loss: 0.4596\n",
            "61/75, train_loss: 0.5689\n",
            "62/75, train_loss: 0.4194\n",
            "63/75, train_loss: 0.4775\n",
            "64/75, train_loss: 0.4607\n",
            "65/75, train_loss: 0.5558\n",
            "66/75, train_loss: 0.3535\n",
            "67/75, train_loss: 0.4866\n",
            "68/75, train_loss: 0.3895\n",
            "69/75, train_loss: 0.3575\n",
            "70/75, train_loss: 0.3777\n",
            "71/75, train_loss: 0.4341\n",
            "72/75, train_loss: 0.4621\n",
            "73/75, train_loss: 0.5837\n",
            "74/75, train_loss: 0.4722\n",
            "75/75, train_loss: 0.5361\n",
            "epoch 60 average loss: 0.4729\n",
            "current epoch: 60 current mean dice: 0.7741\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 61/300\n",
            "1/75, train_loss: 0.4907\n",
            "2/75, train_loss: 0.5519\n",
            "3/75, train_loss: 0.4594\n",
            "4/75, train_loss: 0.4038\n",
            "5/75, train_loss: 0.4138\n",
            "6/75, train_loss: 0.4658\n",
            "7/75, train_loss: 0.5676\n",
            "8/75, train_loss: 0.4564\n",
            "9/75, train_loss: 0.4993\n",
            "10/75, train_loss: 0.4488\n",
            "11/75, train_loss: 0.4194\n",
            "12/75, train_loss: 0.4671\n",
            "13/75, train_loss: 0.3884\n",
            "14/75, train_loss: 0.4144\n",
            "15/75, train_loss: 0.4052\n",
            "16/75, train_loss: 0.3674\n",
            "17/75, train_loss: 0.5045\n",
            "18/75, train_loss: 0.3616\n",
            "19/75, train_loss: 0.4826\n",
            "20/75, train_loss: 0.4391\n",
            "21/75, train_loss: 0.5442\n",
            "22/75, train_loss: 0.3939\n",
            "23/75, train_loss: 0.5344\n",
            "24/75, train_loss: 0.4864\n",
            "25/75, train_loss: 0.4424\n",
            "26/75, train_loss: 0.4826\n",
            "27/75, train_loss: 0.4912\n",
            "28/75, train_loss: 0.4512\n",
            "29/75, train_loss: 0.5070\n",
            "30/75, train_loss: 0.3525\n",
            "31/75, train_loss: 0.4613\n",
            "32/75, train_loss: 0.5144\n",
            "33/75, train_loss: 0.4936\n",
            "34/75, train_loss: 0.5124\n",
            "35/75, train_loss: 0.6078\n",
            "36/75, train_loss: 0.4868\n",
            "37/75, train_loss: 0.4506\n",
            "38/75, train_loss: 0.4172\n",
            "39/75, train_loss: 0.4451\n",
            "40/75, train_loss: 0.5214\n",
            "41/75, train_loss: 0.5669\n",
            "42/75, train_loss: 0.3437\n",
            "43/75, train_loss: 0.4382\n",
            "44/75, train_loss: 0.5165\n",
            "45/75, train_loss: 0.5864\n",
            "46/75, train_loss: 0.5694\n",
            "47/75, train_loss: 0.4023\n",
            "48/75, train_loss: 0.3804\n",
            "49/75, train_loss: 0.4705\n",
            "50/75, train_loss: 0.5832\n",
            "51/75, train_loss: 0.5255\n",
            "52/75, train_loss: 0.5220\n",
            "53/75, train_loss: 0.5775\n",
            "54/75, train_loss: 0.5189\n",
            "55/75, train_loss: 0.4903\n",
            "56/75, train_loss: 0.3144\n",
            "57/75, train_loss: 0.5139\n",
            "58/75, train_loss: 0.5407\n",
            "59/75, train_loss: 0.4860\n",
            "60/75, train_loss: 0.4743\n",
            "61/75, train_loss: 0.4240\n",
            "62/75, train_loss: 0.4786\n",
            "63/75, train_loss: 0.5949\n",
            "64/75, train_loss: 0.3570\n",
            "65/75, train_loss: 0.5297\n",
            "66/75, train_loss: 0.3872\n",
            "67/75, train_loss: 0.4874\n",
            "68/75, train_loss: 0.4507\n",
            "69/75, train_loss: 0.5580\n",
            "70/75, train_loss: 0.5385\n",
            "71/75, train_loss: 0.6303\n",
            "72/75, train_loss: 0.4574\n",
            "73/75, train_loss: 0.3938\n",
            "74/75, train_loss: 0.6142\n",
            "75/75, train_loss: 0.4548\n",
            "epoch 61 average loss: 0.4771\n",
            "current epoch: 61 current mean dice: 0.7400\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 62/300\n",
            "1/75, train_loss: 0.5374\n",
            "2/75, train_loss: 0.6452\n",
            "3/75, train_loss: 0.3849\n",
            "4/75, train_loss: 0.4413\n",
            "5/75, train_loss: 0.5174\n",
            "6/75, train_loss: 0.4103\n",
            "7/75, train_loss: 0.3802\n",
            "8/75, train_loss: 0.4532\n",
            "9/75, train_loss: 0.4558\n",
            "10/75, train_loss: 0.4317\n",
            "11/75, train_loss: 0.3579\n",
            "12/75, train_loss: 0.4652\n",
            "13/75, train_loss: 0.4511\n",
            "14/75, train_loss: 0.4000\n",
            "15/75, train_loss: 0.4847\n",
            "16/75, train_loss: 0.3147\n",
            "17/75, train_loss: 0.5464\n",
            "18/75, train_loss: 0.2933\n",
            "19/75, train_loss: 0.5140\n",
            "20/75, train_loss: 0.4679\n",
            "21/75, train_loss: 0.5435\n",
            "22/75, train_loss: 0.5561\n",
            "23/75, train_loss: 0.3935\n",
            "24/75, train_loss: 0.5336\n",
            "25/75, train_loss: 0.4714\n",
            "26/75, train_loss: 0.4623\n",
            "27/75, train_loss: 0.5116\n",
            "28/75, train_loss: 0.5020\n",
            "29/75, train_loss: 0.4277\n",
            "30/75, train_loss: 0.5214\n",
            "31/75, train_loss: 0.2656\n",
            "32/75, train_loss: 0.5309\n",
            "33/75, train_loss: 0.5815\n",
            "34/75, train_loss: 0.6080\n",
            "35/75, train_loss: 0.5448\n",
            "36/75, train_loss: 0.5601\n",
            "37/75, train_loss: 0.4599\n",
            "38/75, train_loss: 0.5393\n",
            "39/75, train_loss: 0.4613\n",
            "40/75, train_loss: 0.4882\n",
            "41/75, train_loss: 0.4478\n",
            "42/75, train_loss: 0.4621\n",
            "43/75, train_loss: 0.4670\n",
            "44/75, train_loss: 0.3805\n",
            "45/75, train_loss: 0.4714\n",
            "46/75, train_loss: 0.4374\n",
            "47/75, train_loss: 0.5714\n",
            "48/75, train_loss: 0.4465\n",
            "49/75, train_loss: 0.4144\n",
            "50/75, train_loss: 0.4899\n",
            "51/75, train_loss: 0.5162\n",
            "52/75, train_loss: 0.5873\n",
            "53/75, train_loss: 0.4159\n",
            "54/75, train_loss: 0.4475\n",
            "55/75, train_loss: 0.4740\n",
            "56/75, train_loss: 0.3756\n",
            "57/75, train_loss: 0.4459\n",
            "58/75, train_loss: 0.3810\n",
            "59/75, train_loss: 0.3793\n",
            "60/75, train_loss: 0.5830\n",
            "61/75, train_loss: 0.4272\n",
            "62/75, train_loss: 0.5188\n",
            "63/75, train_loss: 0.4788\n",
            "64/75, train_loss: 0.4552\n",
            "65/75, train_loss: 0.5804\n",
            "66/75, train_loss: 0.3755\n",
            "67/75, train_loss: 0.4482\n",
            "68/75, train_loss: 0.4385\n",
            "69/75, train_loss: 0.4851\n",
            "70/75, train_loss: 0.4429\n",
            "71/75, train_loss: 0.6107\n",
            "72/75, train_loss: 0.4575\n",
            "73/75, train_loss: 0.4868\n",
            "74/75, train_loss: 0.5238\n",
            "75/75, train_loss: 0.5374\n",
            "epoch 62 average loss: 0.4717\n",
            "current epoch: 62 current mean dice: 0.7809\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 63/300\n",
            "1/75, train_loss: 0.5685\n",
            "2/75, train_loss: 0.4717\n",
            "3/75, train_loss: 0.5277\n",
            "4/75, train_loss: 0.4250\n",
            "5/75, train_loss: 0.4787\n",
            "6/75, train_loss: 0.4212\n",
            "7/75, train_loss: 0.5260\n",
            "8/75, train_loss: 0.4927\n",
            "9/75, train_loss: 0.3810\n",
            "10/75, train_loss: 0.5069\n",
            "11/75, train_loss: 0.4998\n",
            "12/75, train_loss: 0.3715\n",
            "13/75, train_loss: 0.4897\n",
            "14/75, train_loss: 0.5471\n",
            "15/75, train_loss: 0.3800\n",
            "16/75, train_loss: 0.3640\n",
            "17/75, train_loss: 0.4354\n",
            "18/75, train_loss: 0.3658\n",
            "19/75, train_loss: 0.4568\n",
            "20/75, train_loss: 0.5162\n",
            "21/75, train_loss: 0.5017\n",
            "22/75, train_loss: 0.4484\n",
            "23/75, train_loss: 0.4130\n",
            "24/75, train_loss: 0.5297\n",
            "25/75, train_loss: 0.4355\n",
            "26/75, train_loss: 0.5207\n",
            "27/75, train_loss: 0.4712\n",
            "28/75, train_loss: 0.3937\n",
            "29/75, train_loss: 0.4594\n",
            "30/75, train_loss: 0.5806\n",
            "31/75, train_loss: 0.4548\n",
            "32/75, train_loss: 0.3745\n",
            "33/75, train_loss: 0.4861\n",
            "34/75, train_loss: 0.5768\n",
            "35/75, train_loss: 0.5927\n",
            "36/75, train_loss: 0.4241\n",
            "37/75, train_loss: 0.3792\n",
            "38/75, train_loss: 0.5103\n",
            "39/75, train_loss: 0.4925\n",
            "40/75, train_loss: 0.4407\n",
            "41/75, train_loss: 0.5762\n",
            "42/75, train_loss: 0.3761\n",
            "43/75, train_loss: 0.5127\n",
            "44/75, train_loss: 0.5408\n",
            "45/75, train_loss: 0.4717\n",
            "46/75, train_loss: 0.6057\n",
            "47/75, train_loss: 0.6206\n",
            "48/75, train_loss: 0.6579\n",
            "49/75, train_loss: 0.5757\n",
            "50/75, train_loss: 0.4976\n",
            "51/75, train_loss: 0.5094\n",
            "52/75, train_loss: 0.5118\n",
            "53/75, train_loss: 0.4065\n",
            "54/75, train_loss: 0.4089\n",
            "55/75, train_loss: 0.3763\n",
            "56/75, train_loss: 0.5814\n",
            "57/75, train_loss: 0.3792\n",
            "58/75, train_loss: 0.4905\n",
            "59/75, train_loss: 0.4866\n",
            "60/75, train_loss: 0.3937\n",
            "61/75, train_loss: 0.4871\n",
            "62/75, train_loss: 0.5506\n",
            "63/75, train_loss: 0.5652\n",
            "64/75, train_loss: 0.3878\n",
            "65/75, train_loss: 0.4578\n",
            "66/75, train_loss: 0.5083\n",
            "67/75, train_loss: 0.4384\n",
            "68/75, train_loss: 0.3915\n",
            "69/75, train_loss: 0.3074\n",
            "70/75, train_loss: 0.4513\n",
            "71/75, train_loss: 0.5368\n",
            "72/75, train_loss: 0.4417\n",
            "73/75, train_loss: 0.5103\n",
            "74/75, train_loss: 0.6431\n",
            "75/75, train_loss: 0.5111\n",
            "epoch 63 average loss: 0.4784\n",
            "current epoch: 63 current mean dice: 0.7354\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 64/300\n",
            "1/75, train_loss: 0.5275\n",
            "2/75, train_loss: 0.5005\n",
            "3/75, train_loss: 0.4854\n",
            "4/75, train_loss: 0.4722\n",
            "5/75, train_loss: 0.3707\n",
            "6/75, train_loss: 0.5100\n",
            "7/75, train_loss: 0.4414\n",
            "8/75, train_loss: 0.5665\n",
            "9/75, train_loss: 0.4629\n",
            "10/75, train_loss: 0.4820\n",
            "11/75, train_loss: 0.4631\n",
            "12/75, train_loss: 0.4634\n",
            "13/75, train_loss: 0.4874\n",
            "14/75, train_loss: 0.4077\n",
            "15/75, train_loss: 0.4783\n",
            "16/75, train_loss: 0.4956\n",
            "17/75, train_loss: 0.4515\n",
            "18/75, train_loss: 0.4723\n",
            "19/75, train_loss: 0.5338\n",
            "20/75, train_loss: 0.4326\n",
            "21/75, train_loss: 0.4625\n",
            "22/75, train_loss: 0.4645\n",
            "23/75, train_loss: 0.4506\n",
            "24/75, train_loss: 0.4225\n",
            "25/75, train_loss: 0.5351\n",
            "26/75, train_loss: 0.4076\n",
            "27/75, train_loss: 0.4433\n",
            "28/75, train_loss: 0.5542\n",
            "29/75, train_loss: 0.3846\n",
            "30/75, train_loss: 0.4741\n",
            "31/75, train_loss: 0.4340\n",
            "32/75, train_loss: 0.4237\n",
            "33/75, train_loss: 0.4912\n",
            "34/75, train_loss: 0.5158\n",
            "35/75, train_loss: 0.4088\n",
            "36/75, train_loss: 0.5057\n",
            "37/75, train_loss: 0.3964\n",
            "38/75, train_loss: 0.5361\n",
            "39/75, train_loss: 0.5154\n",
            "40/75, train_loss: 0.5238\n",
            "41/75, train_loss: 0.4002\n",
            "42/75, train_loss: 0.4407\n",
            "43/75, train_loss: 0.5114\n",
            "44/75, train_loss: 0.5102\n",
            "45/75, train_loss: 0.3710\n",
            "46/75, train_loss: 0.5250\n",
            "47/75, train_loss: 0.4382\n",
            "48/75, train_loss: 0.4910\n",
            "49/75, train_loss: 0.5086\n",
            "50/75, train_loss: 0.5188\n",
            "51/75, train_loss: 0.3528\n",
            "52/75, train_loss: 0.3937\n",
            "53/75, train_loss: 0.4249\n",
            "54/75, train_loss: 0.4468\n",
            "55/75, train_loss: 0.4151\n",
            "56/75, train_loss: 0.5551\n",
            "57/75, train_loss: 0.4667\n",
            "58/75, train_loss: 0.4476\n",
            "59/75, train_loss: 0.4014\n",
            "60/75, train_loss: 0.5517\n",
            "61/75, train_loss: 0.5466\n",
            "62/75, train_loss: 0.4255\n",
            "63/75, train_loss: 0.5741\n",
            "64/75, train_loss: 0.3262\n",
            "65/75, train_loss: 0.3140\n",
            "66/75, train_loss: 0.5151\n",
            "67/75, train_loss: 0.4379\n",
            "68/75, train_loss: 0.5784\n",
            "69/75, train_loss: 0.4887\n",
            "70/75, train_loss: 0.4015\n",
            "71/75, train_loss: 0.4876\n",
            "72/75, train_loss: 0.4178\n",
            "73/75, train_loss: 0.4018\n",
            "74/75, train_loss: 0.5967\n",
            "75/75, train_loss: 0.4156\n",
            "epoch 64 average loss: 0.4660\n",
            "current epoch: 64 current mean dice: 0.7419\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 65/300\n",
            "1/75, train_loss: 0.5543\n",
            "2/75, train_loss: 0.4500\n",
            "3/75, train_loss: 0.5605\n",
            "4/75, train_loss: 0.5607\n",
            "5/75, train_loss: 0.3701\n",
            "6/75, train_loss: 0.5282\n",
            "7/75, train_loss: 0.4886\n",
            "8/75, train_loss: 0.6023\n",
            "9/75, train_loss: 0.4805\n",
            "10/75, train_loss: 0.4592\n",
            "11/75, train_loss: 0.4666\n",
            "12/75, train_loss: 0.3967\n",
            "13/75, train_loss: 0.5550\n",
            "14/75, train_loss: 0.4234\n",
            "15/75, train_loss: 0.5363\n",
            "16/75, train_loss: 0.4781\n",
            "17/75, train_loss: 0.3627\n",
            "18/75, train_loss: 0.5042\n",
            "19/75, train_loss: 0.4741\n",
            "20/75, train_loss: 0.5131\n",
            "21/75, train_loss: 0.3537\n",
            "22/75, train_loss: 0.4706\n",
            "23/75, train_loss: 0.5007\n",
            "24/75, train_loss: 0.4074\n",
            "25/75, train_loss: 0.4916\n",
            "26/75, train_loss: 0.5042\n",
            "27/75, train_loss: 0.4586\n",
            "28/75, train_loss: 0.4926\n",
            "29/75, train_loss: 0.4354\n",
            "30/75, train_loss: 0.3562\n",
            "31/75, train_loss: 0.3920\n",
            "32/75, train_loss: 0.5060\n",
            "33/75, train_loss: 0.4557\n",
            "34/75, train_loss: 0.5344\n",
            "35/75, train_loss: 0.4513\n",
            "36/75, train_loss: 0.6117\n",
            "37/75, train_loss: 0.5474\n",
            "38/75, train_loss: 0.4503\n",
            "39/75, train_loss: 0.5283\n",
            "40/75, train_loss: 0.5135\n",
            "41/75, train_loss: 0.4327\n",
            "42/75, train_loss: 0.4210\n",
            "43/75, train_loss: 0.4433\n",
            "44/75, train_loss: 0.5014\n",
            "45/75, train_loss: 0.3661\n",
            "46/75, train_loss: 0.5232\n",
            "47/75, train_loss: 0.4939\n",
            "48/75, train_loss: 0.4020\n",
            "49/75, train_loss: 0.5995\n",
            "50/75, train_loss: 0.3725\n",
            "51/75, train_loss: 0.5983\n",
            "52/75, train_loss: 0.4774\n",
            "53/75, train_loss: 0.4012\n",
            "54/75, train_loss: 0.4252\n",
            "55/75, train_loss: 0.5024\n",
            "56/75, train_loss: 0.5013\n",
            "57/75, train_loss: 0.6214\n",
            "58/75, train_loss: 0.4648\n",
            "59/75, train_loss: 0.5103\n",
            "60/75, train_loss: 0.5517\n",
            "61/75, train_loss: 0.5281\n",
            "62/75, train_loss: 0.4534\n",
            "63/75, train_loss: 0.4418\n",
            "64/75, train_loss: 0.3806\n",
            "65/75, train_loss: 0.4591\n",
            "66/75, train_loss: 0.4747\n",
            "67/75, train_loss: 0.5088\n",
            "68/75, train_loss: 0.5770\n",
            "69/75, train_loss: 0.4652\n",
            "70/75, train_loss: 0.6464\n",
            "71/75, train_loss: 0.4685\n",
            "72/75, train_loss: 0.5167\n",
            "73/75, train_loss: 0.4522\n",
            "74/75, train_loss: 0.5740\n",
            "75/75, train_loss: 0.4795\n",
            "epoch 65 average loss: 0.4835\n",
            "current epoch: 65 current mean dice: 0.7577\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 66/300\n",
            "1/75, train_loss: 0.4241\n",
            "2/75, train_loss: 0.5781\n",
            "3/75, train_loss: 0.4530\n",
            "4/75, train_loss: 0.4263\n",
            "5/75, train_loss: 0.3071\n",
            "6/75, train_loss: 0.4335\n",
            "7/75, train_loss: 0.4460\n",
            "8/75, train_loss: 0.4391\n",
            "9/75, train_loss: 0.4918\n",
            "10/75, train_loss: 0.5498\n",
            "11/75, train_loss: 0.3494\n",
            "12/75, train_loss: 0.4017\n",
            "13/75, train_loss: 0.2738\n",
            "14/75, train_loss: 0.4363\n",
            "15/75, train_loss: 0.4509\n",
            "16/75, train_loss: 0.4073\n",
            "17/75, train_loss: 0.4377\n",
            "18/75, train_loss: 0.5490\n",
            "19/75, train_loss: 0.4821\n",
            "20/75, train_loss: 0.5076\n",
            "21/75, train_loss: 0.4977\n",
            "22/75, train_loss: 0.5030\n",
            "23/75, train_loss: 0.5644\n",
            "24/75, train_loss: 0.5350\n",
            "25/75, train_loss: 0.4294\n",
            "26/75, train_loss: 0.4631\n",
            "27/75, train_loss: 0.4193\n",
            "28/75, train_loss: 0.5093\n",
            "29/75, train_loss: 0.4757\n",
            "30/75, train_loss: 0.5598\n",
            "31/75, train_loss: 0.4670\n",
            "32/75, train_loss: 0.4773\n",
            "33/75, train_loss: 0.3161\n",
            "34/75, train_loss: 0.4147\n",
            "35/75, train_loss: 0.4982\n",
            "36/75, train_loss: 0.5676\n",
            "37/75, train_loss: 0.5097\n",
            "38/75, train_loss: 0.4628\n",
            "39/75, train_loss: 0.4871\n",
            "40/75, train_loss: 0.5083\n",
            "41/75, train_loss: 0.4379\n",
            "42/75, train_loss: 0.4039\n",
            "43/75, train_loss: 0.4913\n",
            "44/75, train_loss: 0.5005\n",
            "45/75, train_loss: 0.6089\n",
            "46/75, train_loss: 0.5538\n",
            "47/75, train_loss: 0.4645\n",
            "48/75, train_loss: 0.4838\n",
            "49/75, train_loss: 0.4705\n",
            "50/75, train_loss: 0.4324\n",
            "51/75, train_loss: 0.5442\n",
            "52/75, train_loss: 0.6454\n",
            "53/75, train_loss: 0.5534\n",
            "54/75, train_loss: 0.4265\n",
            "55/75, train_loss: 0.4720\n",
            "56/75, train_loss: 0.3729\n",
            "57/75, train_loss: 0.5998\n",
            "58/75, train_loss: 0.6287\n",
            "59/75, train_loss: 0.4641\n",
            "60/75, train_loss: 0.6114\n",
            "61/75, train_loss: 0.4568\n",
            "62/75, train_loss: 0.3282\n",
            "63/75, train_loss: 0.4799\n",
            "64/75, train_loss: 0.5446\n",
            "65/75, train_loss: 0.4369\n",
            "66/75, train_loss: 0.4297\n",
            "67/75, train_loss: 0.3892\n",
            "68/75, train_loss: 0.4928\n",
            "69/75, train_loss: 0.5385\n",
            "70/75, train_loss: 0.5918\n",
            "71/75, train_loss: 0.6270\n",
            "72/75, train_loss: 0.5280\n",
            "73/75, train_loss: 0.5173\n",
            "74/75, train_loss: 0.3884\n",
            "75/75, train_loss: 0.4681\n",
            "epoch 66 average loss: 0.4786\n",
            "current epoch: 66 current mean dice: 0.7134\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 67/300\n",
            "1/75, train_loss: 0.5278\n",
            "2/75, train_loss: 0.4529\n",
            "3/75, train_loss: 0.4467\n",
            "4/75, train_loss: 0.4163\n",
            "5/75, train_loss: 0.4260\n",
            "6/75, train_loss: 0.5019\n",
            "7/75, train_loss: 0.4211\n",
            "8/75, train_loss: 0.5126\n",
            "9/75, train_loss: 0.4992\n",
            "10/75, train_loss: 0.4131\n",
            "11/75, train_loss: 0.4216\n",
            "12/75, train_loss: 0.4742\n",
            "13/75, train_loss: 0.4445\n",
            "14/75, train_loss: 0.4678\n",
            "15/75, train_loss: 0.5057\n",
            "16/75, train_loss: 0.4808\n",
            "17/75, train_loss: 0.3962\n",
            "18/75, train_loss: 0.4485\n",
            "19/75, train_loss: 0.4197\n",
            "20/75, train_loss: 0.4581\n",
            "21/75, train_loss: 0.5884\n",
            "22/75, train_loss: 0.4148\n",
            "23/75, train_loss: 0.5009\n",
            "24/75, train_loss: 0.5426\n",
            "25/75, train_loss: 0.4751\n",
            "26/75, train_loss: 0.5803\n",
            "27/75, train_loss: 0.4335\n",
            "28/75, train_loss: 0.4669\n",
            "29/75, train_loss: 0.5563\n",
            "30/75, train_loss: 0.4322\n",
            "31/75, train_loss: 0.5190\n",
            "32/75, train_loss: 0.5387\n",
            "33/75, train_loss: 0.4731\n",
            "34/75, train_loss: 0.5279\n",
            "35/75, train_loss: 0.4968\n",
            "36/75, train_loss: 0.4628\n",
            "37/75, train_loss: 0.4122\n",
            "38/75, train_loss: 0.4276\n",
            "39/75, train_loss: 0.5093\n",
            "40/75, train_loss: 0.4870\n",
            "41/75, train_loss: 0.4316\n",
            "42/75, train_loss: 0.4181\n",
            "43/75, train_loss: 0.4577\n",
            "44/75, train_loss: 0.5783\n",
            "45/75, train_loss: 0.5692\n",
            "46/75, train_loss: 0.5500\n",
            "47/75, train_loss: 0.2498\n",
            "48/75, train_loss: 0.5035\n",
            "49/75, train_loss: 0.5639\n",
            "50/75, train_loss: 0.4988\n",
            "51/75, train_loss: 0.3931\n",
            "52/75, train_loss: 0.5478\n",
            "53/75, train_loss: 0.4718\n",
            "54/75, train_loss: 0.4355\n",
            "55/75, train_loss: 0.4534\n",
            "56/75, train_loss: 0.4298\n",
            "57/75, train_loss: 0.3709\n",
            "58/75, train_loss: 0.5592\n",
            "59/75, train_loss: 0.3950\n",
            "60/75, train_loss: 0.5293\n",
            "61/75, train_loss: 0.4060\n",
            "62/75, train_loss: 0.5503\n",
            "63/75, train_loss: 0.5516\n",
            "64/75, train_loss: 0.3602\n",
            "65/75, train_loss: 0.4747\n",
            "66/75, train_loss: 0.4392\n",
            "67/75, train_loss: 0.4907\n",
            "68/75, train_loss: 0.4405\n",
            "69/75, train_loss: 0.4147\n",
            "70/75, train_loss: 0.5216\n",
            "71/75, train_loss: 0.5539\n",
            "72/75, train_loss: 0.4991\n",
            "73/75, train_loss: 0.5160\n",
            "74/75, train_loss: 0.4883\n",
            "75/75, train_loss: 0.4312\n",
            "epoch 67 average loss: 0.4737\n",
            "current epoch: 67 current mean dice: 0.7613\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 68/300\n",
            "1/75, train_loss: 0.4374\n",
            "2/75, train_loss: 0.4918\n",
            "3/75, train_loss: 0.4476\n",
            "4/75, train_loss: 0.5353\n",
            "5/75, train_loss: 0.4595\n",
            "6/75, train_loss: 0.4801\n",
            "7/75, train_loss: 0.4518\n",
            "8/75, train_loss: 0.4334\n",
            "9/75, train_loss: 0.4551\n",
            "10/75, train_loss: 0.4912\n",
            "11/75, train_loss: 0.3894\n",
            "12/75, train_loss: 0.4161\n",
            "13/75, train_loss: 0.5178\n",
            "14/75, train_loss: 0.4449\n",
            "15/75, train_loss: 0.5080\n",
            "16/75, train_loss: 0.5412\n",
            "17/75, train_loss: 0.4481\n",
            "18/75, train_loss: 0.4525\n",
            "19/75, train_loss: 0.5303\n",
            "20/75, train_loss: 0.4239\n",
            "21/75, train_loss: 0.5618\n",
            "22/75, train_loss: 0.4708\n",
            "23/75, train_loss: 0.5302\n",
            "24/75, train_loss: 0.5144\n",
            "25/75, train_loss: 0.5318\n",
            "26/75, train_loss: 0.4697\n",
            "27/75, train_loss: 0.6359\n",
            "28/75, train_loss: 0.4991\n",
            "29/75, train_loss: 0.3779\n",
            "30/75, train_loss: 0.4979\n",
            "31/75, train_loss: 0.3970\n",
            "32/75, train_loss: 0.5152\n",
            "33/75, train_loss: 0.5289\n",
            "34/75, train_loss: 0.3189\n",
            "35/75, train_loss: 0.5800\n",
            "36/75, train_loss: 0.4892\n",
            "37/75, train_loss: 0.3658\n",
            "38/75, train_loss: 0.3475\n",
            "39/75, train_loss: 0.4034\n",
            "40/75, train_loss: 0.5006\n",
            "41/75, train_loss: 0.5268\n",
            "42/75, train_loss: 0.5562\n",
            "43/75, train_loss: 0.5137\n",
            "44/75, train_loss: 0.5774\n",
            "45/75, train_loss: 0.3368\n",
            "46/75, train_loss: 0.4623\n",
            "47/75, train_loss: 0.3690\n",
            "48/75, train_loss: 0.3643\n",
            "49/75, train_loss: 0.6591\n",
            "50/75, train_loss: 0.5529\n",
            "51/75, train_loss: 0.5398\n",
            "52/75, train_loss: 0.5352\n",
            "53/75, train_loss: 0.6298\n",
            "54/75, train_loss: 0.5240\n",
            "55/75, train_loss: 0.3849\n",
            "56/75, train_loss: 0.5294\n",
            "57/75, train_loss: 0.5121\n",
            "58/75, train_loss: 0.5449\n",
            "59/75, train_loss: 0.3203\n",
            "60/75, train_loss: 0.3442\n",
            "61/75, train_loss: 0.4950\n",
            "62/75, train_loss: 0.4495\n",
            "63/75, train_loss: 0.5425\n",
            "64/75, train_loss: 0.4925\n",
            "65/75, train_loss: 0.5343\n",
            "66/75, train_loss: 0.4054\n",
            "67/75, train_loss: 0.5398\n",
            "68/75, train_loss: 0.4566\n",
            "69/75, train_loss: 0.5005\n",
            "70/75, train_loss: 0.5359\n",
            "71/75, train_loss: 0.4966\n",
            "72/75, train_loss: 0.4151\n",
            "73/75, train_loss: 0.6495\n",
            "74/75, train_loss: 0.5406\n",
            "75/75, train_loss: 0.4831\n",
            "epoch 68 average loss: 0.4828\n",
            "current epoch: 68 current mean dice: 0.7834\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 69/300\n",
            "1/75, train_loss: 0.5252\n",
            "2/75, train_loss: 0.5028\n",
            "3/75, train_loss: 0.4883\n",
            "4/75, train_loss: 0.3888\n",
            "5/75, train_loss: 0.4267\n",
            "6/75, train_loss: 0.3922\n",
            "7/75, train_loss: 0.5661\n",
            "8/75, train_loss: 0.4924\n",
            "9/75, train_loss: 0.3590\n",
            "10/75, train_loss: 0.3604\n",
            "11/75, train_loss: 0.3317\n",
            "12/75, train_loss: 0.4656\n",
            "13/75, train_loss: 0.2877\n",
            "14/75, train_loss: 0.4254\n",
            "15/75, train_loss: 0.4895\n",
            "16/75, train_loss: 0.3627\n",
            "17/75, train_loss: 0.5153\n",
            "18/75, train_loss: 0.5615\n",
            "19/75, train_loss: 0.4285\n",
            "20/75, train_loss: 0.3481\n",
            "21/75, train_loss: 0.3852\n",
            "22/75, train_loss: 0.3988\n",
            "23/75, train_loss: 0.5306\n",
            "24/75, train_loss: 0.4754\n",
            "25/75, train_loss: 0.4792\n",
            "26/75, train_loss: 0.5682\n",
            "27/75, train_loss: 0.4753\n",
            "28/75, train_loss: 0.4812\n",
            "29/75, train_loss: 0.5063\n",
            "30/75, train_loss: 0.5806\n",
            "31/75, train_loss: 0.4693\n",
            "32/75, train_loss: 0.3935\n",
            "33/75, train_loss: 0.5018\n",
            "34/75, train_loss: 0.5101\n",
            "35/75, train_loss: 0.4536\n",
            "36/75, train_loss: 0.4734\n",
            "37/75, train_loss: 0.4754\n",
            "38/75, train_loss: 0.4169\n",
            "39/75, train_loss: 0.5825\n",
            "40/75, train_loss: 0.4981\n",
            "41/75, train_loss: 0.4338\n",
            "42/75, train_loss: 0.4867\n",
            "43/75, train_loss: 0.3596\n",
            "44/75, train_loss: 0.5259\n",
            "45/75, train_loss: 0.4463\n",
            "46/75, train_loss: 0.5425\n",
            "47/75, train_loss: 0.5087\n",
            "48/75, train_loss: 0.3961\n",
            "49/75, train_loss: 0.5431\n",
            "50/75, train_loss: 0.4693\n",
            "51/75, train_loss: 0.4943\n",
            "52/75, train_loss: 0.4565\n",
            "53/75, train_loss: 0.5258\n",
            "54/75, train_loss: 0.4169\n",
            "55/75, train_loss: 0.4065\n",
            "56/75, train_loss: 0.4757\n",
            "57/75, train_loss: 0.4101\n",
            "58/75, train_loss: 0.4267\n",
            "59/75, train_loss: 0.3859\n",
            "60/75, train_loss: 0.5913\n",
            "61/75, train_loss: 0.4593\n",
            "62/75, train_loss: 0.5876\n",
            "63/75, train_loss: 0.3926\n",
            "64/75, train_loss: 0.5530\n",
            "65/75, train_loss: 0.4728\n",
            "66/75, train_loss: 0.4501\n",
            "67/75, train_loss: 0.5356\n",
            "68/75, train_loss: 0.4580\n",
            "69/75, train_loss: 0.5311\n",
            "70/75, train_loss: 0.5119\n",
            "71/75, train_loss: 0.5021\n",
            "72/75, train_loss: 0.4885\n",
            "73/75, train_loss: 0.3737\n",
            "74/75, train_loss: 0.4002\n",
            "75/75, train_loss: 0.5202\n",
            "epoch 69 average loss: 0.4655\n",
            "current epoch: 69 current mean dice: 0.7585\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 70/300\n",
            "1/75, train_loss: 0.5080\n",
            "2/75, train_loss: 0.4671\n",
            "3/75, train_loss: 0.4717\n",
            "4/75, train_loss: 0.5481\n",
            "5/75, train_loss: 0.4725\n",
            "6/75, train_loss: 0.4376\n",
            "7/75, train_loss: 0.4637\n",
            "8/75, train_loss: 0.4707\n",
            "9/75, train_loss: 0.3540\n",
            "10/75, train_loss: 0.4657\n",
            "11/75, train_loss: 0.4003\n",
            "12/75, train_loss: 0.4593\n",
            "13/75, train_loss: 0.4193\n",
            "14/75, train_loss: 0.5137\n",
            "15/75, train_loss: 0.4174\n",
            "16/75, train_loss: 0.4137\n",
            "17/75, train_loss: 0.4709\n",
            "18/75, train_loss: 0.4465\n",
            "19/75, train_loss: 0.4314\n",
            "20/75, train_loss: 0.3844\n",
            "21/75, train_loss: 0.5048\n",
            "22/75, train_loss: 0.4500\n",
            "23/75, train_loss: 0.5330\n",
            "24/75, train_loss: 0.5247\n",
            "25/75, train_loss: 0.4946\n",
            "26/75, train_loss: 0.4487\n",
            "27/75, train_loss: 0.4329\n",
            "28/75, train_loss: 0.5163\n",
            "29/75, train_loss: 0.5123\n",
            "30/75, train_loss: 0.7002\n",
            "31/75, train_loss: 0.5681\n",
            "32/75, train_loss: 0.4993\n",
            "33/75, train_loss: 0.5334\n",
            "34/75, train_loss: 0.5491\n",
            "35/75, train_loss: 0.4822\n",
            "36/75, train_loss: 0.4579\n",
            "37/75, train_loss: 0.5436\n",
            "38/75, train_loss: 0.4692\n",
            "39/75, train_loss: 0.4160\n",
            "40/75, train_loss: 0.5727\n",
            "41/75, train_loss: 0.4035\n",
            "42/75, train_loss: 0.5461\n",
            "43/75, train_loss: 0.4350\n",
            "44/75, train_loss: 0.5462\n",
            "45/75, train_loss: 0.2736\n",
            "46/75, train_loss: 0.5358\n",
            "47/75, train_loss: 0.4921\n",
            "48/75, train_loss: 0.4255\n",
            "49/75, train_loss: 0.4620\n",
            "50/75, train_loss: 0.5727\n",
            "51/75, train_loss: 0.4515\n",
            "52/75, train_loss: 0.4372\n",
            "53/75, train_loss: 0.5362\n",
            "54/75, train_loss: 0.4076\n",
            "55/75, train_loss: 0.5857\n",
            "56/75, train_loss: 0.5259\n",
            "57/75, train_loss: 0.5116\n",
            "58/75, train_loss: 0.4455\n",
            "59/75, train_loss: 0.4014\n",
            "60/75, train_loss: 0.5539\n",
            "61/75, train_loss: 0.3425\n",
            "62/75, train_loss: 0.4403\n",
            "63/75, train_loss: 0.5282\n",
            "64/75, train_loss: 0.4054\n",
            "65/75, train_loss: 0.4482\n",
            "66/75, train_loss: 0.4139\n",
            "67/75, train_loss: 0.4790\n",
            "68/75, train_loss: 0.3481\n",
            "69/75, train_loss: 0.4648\n",
            "70/75, train_loss: 0.5873\n",
            "71/75, train_loss: 0.2471\n",
            "72/75, train_loss: 0.5882\n",
            "73/75, train_loss: 0.5783\n",
            "74/75, train_loss: 0.4709\n",
            "75/75, train_loss: 0.4063\n",
            "epoch 70 average loss: 0.4736\n",
            "current epoch: 70 current mean dice: 0.7725\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 71/300\n",
            "1/75, train_loss: 0.4735\n",
            "2/75, train_loss: 0.5325\n",
            "3/75, train_loss: 0.5338\n",
            "4/75, train_loss: 0.5377\n",
            "5/75, train_loss: 0.3228\n",
            "6/75, train_loss: 0.4585\n",
            "7/75, train_loss: 0.4583\n",
            "8/75, train_loss: 0.5511\n",
            "9/75, train_loss: 0.4614\n",
            "10/75, train_loss: 0.4572\n",
            "11/75, train_loss: 0.4112\n",
            "12/75, train_loss: 0.4365\n",
            "13/75, train_loss: 0.3869\n",
            "14/75, train_loss: 0.4015\n",
            "15/75, train_loss: 0.4809\n",
            "16/75, train_loss: 0.3766\n",
            "17/75, train_loss: 0.3867\n",
            "18/75, train_loss: 0.4560\n",
            "19/75, train_loss: 0.4222\n",
            "20/75, train_loss: 0.3682\n",
            "21/75, train_loss: 0.4839\n",
            "22/75, train_loss: 0.4209\n",
            "23/75, train_loss: 0.4488\n",
            "24/75, train_loss: 0.6117\n",
            "25/75, train_loss: 0.4322\n",
            "26/75, train_loss: 0.5428\n",
            "27/75, train_loss: 0.4426\n",
            "28/75, train_loss: 0.5101\n",
            "29/75, train_loss: 0.4465\n",
            "30/75, train_loss: 0.5080\n",
            "31/75, train_loss: 0.4212\n",
            "32/75, train_loss: 0.5391\n",
            "33/75, train_loss: 0.4614\n",
            "34/75, train_loss: 0.4356\n",
            "35/75, train_loss: 0.4545\n",
            "36/75, train_loss: 0.5129\n",
            "37/75, train_loss: 0.5506\n",
            "38/75, train_loss: 0.5138\n",
            "39/75, train_loss: 0.4913\n",
            "40/75, train_loss: 0.3954\n",
            "41/75, train_loss: 0.4593\n",
            "42/75, train_loss: 0.4858\n",
            "43/75, train_loss: 0.3930\n",
            "44/75, train_loss: 0.5352\n",
            "45/75, train_loss: 0.4065\n",
            "46/75, train_loss: 0.5103\n",
            "47/75, train_loss: 0.4221\n",
            "48/75, train_loss: 0.4991\n",
            "49/75, train_loss: 0.3907\n",
            "50/75, train_loss: 0.4195\n",
            "51/75, train_loss: 0.4508\n",
            "52/75, train_loss: 0.5333\n",
            "53/75, train_loss: 0.4754\n",
            "54/75, train_loss: 0.5599\n",
            "55/75, train_loss: 0.4975\n",
            "56/75, train_loss: 0.4284\n",
            "57/75, train_loss: 0.4065\n",
            "58/75, train_loss: 0.4838\n",
            "59/75, train_loss: 0.4005\n",
            "60/75, train_loss: 0.5443\n",
            "61/75, train_loss: 0.3375\n",
            "62/75, train_loss: 0.5304\n",
            "63/75, train_loss: 0.4830\n",
            "64/75, train_loss: 0.4784\n",
            "65/75, train_loss: 0.5023\n",
            "66/75, train_loss: 0.5161\n",
            "67/75, train_loss: 0.4071\n",
            "68/75, train_loss: 0.3901\n",
            "69/75, train_loss: 0.5735\n",
            "70/75, train_loss: 0.4654\n",
            "71/75, train_loss: 0.5417\n",
            "72/75, train_loss: 0.3988\n",
            "73/75, train_loss: 0.4238\n",
            "74/75, train_loss: 0.4099\n",
            "75/75, train_loss: 0.3284\n",
            "epoch 71 average loss: 0.4617\n",
            "current epoch: 71 current mean dice: 0.7329\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 72/300\n",
            "1/75, train_loss: 0.5051\n",
            "2/75, train_loss: 0.4812\n",
            "3/75, train_loss: 0.5278\n",
            "4/75, train_loss: 0.5117\n",
            "5/75, train_loss: 0.5292\n",
            "6/75, train_loss: 0.4406\n",
            "7/75, train_loss: 0.4497\n",
            "8/75, train_loss: 0.4975\n",
            "9/75, train_loss: 0.5151\n",
            "10/75, train_loss: 0.4376\n",
            "11/75, train_loss: 0.5501\n",
            "12/75, train_loss: 0.3643\n",
            "13/75, train_loss: 0.4882\n",
            "14/75, train_loss: 0.4300\n",
            "15/75, train_loss: 0.5016\n",
            "16/75, train_loss: 0.5469\n",
            "17/75, train_loss: 0.4074\n",
            "18/75, train_loss: 0.5132\n",
            "19/75, train_loss: 0.3657\n",
            "20/75, train_loss: 0.5245\n",
            "21/75, train_loss: 0.5423\n",
            "22/75, train_loss: 0.5373\n",
            "23/75, train_loss: 0.4680\n",
            "24/75, train_loss: 0.6380\n",
            "25/75, train_loss: 0.6048\n",
            "26/75, train_loss: 0.4727\n",
            "27/75, train_loss: 0.4786\n",
            "28/75, train_loss: 0.5136\n",
            "29/75, train_loss: 0.4180\n",
            "30/75, train_loss: 0.5629\n",
            "31/75, train_loss: 0.4975\n",
            "32/75, train_loss: 0.3899\n",
            "33/75, train_loss: 0.5181\n",
            "34/75, train_loss: 0.4770\n",
            "35/75, train_loss: 0.6456\n",
            "36/75, train_loss: 0.4516\n",
            "37/75, train_loss: 0.4433\n",
            "38/75, train_loss: 0.4385\n",
            "39/75, train_loss: 0.5318\n",
            "40/75, train_loss: 0.5204\n",
            "41/75, train_loss: 0.5483\n",
            "42/75, train_loss: 0.4256\n",
            "43/75, train_loss: 0.3196\n",
            "44/75, train_loss: 0.5038\n",
            "45/75, train_loss: 0.5171\n",
            "46/75, train_loss: 0.5468\n",
            "47/75, train_loss: 0.5414\n",
            "48/75, train_loss: 0.5382\n",
            "49/75, train_loss: 0.5729\n",
            "50/75, train_loss: 0.5687\n",
            "51/75, train_loss: 0.5324\n",
            "52/75, train_loss: 0.2861\n",
            "53/75, train_loss: 0.4205\n",
            "54/75, train_loss: 0.5184\n",
            "55/75, train_loss: 0.2994\n",
            "56/75, train_loss: 0.5086\n",
            "57/75, train_loss: 0.4908\n",
            "58/75, train_loss: 0.4396\n",
            "59/75, train_loss: 0.3007\n",
            "60/75, train_loss: 0.4734\n",
            "61/75, train_loss: 0.5634\n",
            "62/75, train_loss: 0.4803\n",
            "63/75, train_loss: 0.6079\n",
            "64/75, train_loss: 0.4843\n",
            "65/75, train_loss: 0.4965\n",
            "66/75, train_loss: 0.3866\n",
            "67/75, train_loss: 0.4718\n",
            "68/75, train_loss: 0.4376\n",
            "69/75, train_loss: 0.4840\n",
            "70/75, train_loss: 0.3984\n",
            "71/75, train_loss: 0.5258\n",
            "72/75, train_loss: 0.5565\n",
            "73/75, train_loss: 0.5438\n",
            "74/75, train_loss: 0.4865\n",
            "75/75, train_loss: 0.4114\n",
            "epoch 72 average loss: 0.4857\n",
            "current epoch: 72 current mean dice: 0.7390\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 73/300\n",
            "1/75, train_loss: 0.4567\n",
            "2/75, train_loss: 0.5330\n",
            "3/75, train_loss: 0.4733\n",
            "4/75, train_loss: 0.4929\n",
            "5/75, train_loss: 0.4014\n",
            "6/75, train_loss: 0.4760\n",
            "7/75, train_loss: 0.4887\n",
            "8/75, train_loss: 0.5169\n",
            "9/75, train_loss: 0.5061\n",
            "10/75, train_loss: 0.3890\n",
            "11/75, train_loss: 0.5348\n",
            "12/75, train_loss: 0.3702\n",
            "13/75, train_loss: 0.4109\n",
            "14/75, train_loss: 0.3333\n",
            "15/75, train_loss: 0.4082\n",
            "16/75, train_loss: 0.4315\n",
            "17/75, train_loss: 0.5252\n",
            "18/75, train_loss: 0.3460\n",
            "19/75, train_loss: 0.4423\n",
            "20/75, train_loss: 0.5019\n",
            "21/75, train_loss: 0.4666\n",
            "22/75, train_loss: 0.4875\n",
            "23/75, train_loss: 0.4681\n",
            "24/75, train_loss: 0.4674\n",
            "25/75, train_loss: 0.5184\n",
            "26/75, train_loss: 0.3954\n",
            "27/75, train_loss: 0.4946\n",
            "28/75, train_loss: 0.5406\n",
            "29/75, train_loss: 0.3723\n",
            "30/75, train_loss: 0.5740\n",
            "31/75, train_loss: 0.5222\n",
            "32/75, train_loss: 0.4542\n",
            "33/75, train_loss: 0.4642\n",
            "34/75, train_loss: 0.4746\n",
            "35/75, train_loss: 0.2734\n",
            "36/75, train_loss: 0.5139\n",
            "37/75, train_loss: 0.5155\n",
            "38/75, train_loss: 0.5178\n",
            "39/75, train_loss: 0.4445\n",
            "40/75, train_loss: 0.5771\n",
            "41/75, train_loss: 0.4093\n",
            "42/75, train_loss: 0.6181\n",
            "43/75, train_loss: 0.4927\n",
            "44/75, train_loss: 0.4215\n",
            "45/75, train_loss: 0.4664\n",
            "46/75, train_loss: 0.4883\n",
            "47/75, train_loss: 0.4131\n",
            "48/75, train_loss: 0.4743\n",
            "49/75, train_loss: 0.5275\n",
            "50/75, train_loss: 0.5910\n",
            "51/75, train_loss: 0.5664\n",
            "52/75, train_loss: 0.5898\n",
            "53/75, train_loss: 0.3368\n",
            "54/75, train_loss: 0.4955\n",
            "55/75, train_loss: 0.4754\n",
            "56/75, train_loss: 0.4781\n",
            "57/75, train_loss: 0.4616\n",
            "58/75, train_loss: 0.5439\n",
            "59/75, train_loss: 0.5463\n",
            "60/75, train_loss: 0.3775\n",
            "61/75, train_loss: 0.3960\n",
            "62/75, train_loss: 0.5084\n",
            "63/75, train_loss: 0.5437\n",
            "64/75, train_loss: 0.3911\n",
            "65/75, train_loss: 0.3745\n",
            "66/75, train_loss: 0.4667\n",
            "67/75, train_loss: 0.4013\n",
            "68/75, train_loss: 0.4636\n",
            "69/75, train_loss: 0.5318\n",
            "70/75, train_loss: 0.4611\n",
            "71/75, train_loss: 0.5266\n",
            "72/75, train_loss: 0.5116\n",
            "73/75, train_loss: 0.5151\n",
            "74/75, train_loss: 0.6326\n",
            "75/75, train_loss: 0.4039\n",
            "epoch 73 average loss: 0.4731\n",
            "current epoch: 73 current mean dice: 0.7116\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 74/300\n",
            "1/75, train_loss: 0.4627\n",
            "2/75, train_loss: 0.4310\n",
            "3/75, train_loss: 0.4637\n",
            "4/75, train_loss: 0.3897\n",
            "5/75, train_loss: 0.4875\n",
            "6/75, train_loss: 0.4674\n",
            "7/75, train_loss: 0.4930\n",
            "8/75, train_loss: 0.6070\n",
            "9/75, train_loss: 0.4447\n",
            "10/75, train_loss: 0.4268\n",
            "11/75, train_loss: 0.4397\n",
            "12/75, train_loss: 0.4920\n",
            "13/75, train_loss: 0.4417\n",
            "14/75, train_loss: 0.3348\n",
            "15/75, train_loss: 0.5523\n",
            "16/75, train_loss: 0.2718\n",
            "17/75, train_loss: 0.4181\n",
            "18/75, train_loss: 0.4814\n",
            "19/75, train_loss: 0.4315\n",
            "20/75, train_loss: 0.4386\n",
            "21/75, train_loss: 0.3563\n",
            "22/75, train_loss: 0.5054\n",
            "23/75, train_loss: 0.4900\n",
            "24/75, train_loss: 0.4347\n",
            "25/75, train_loss: 0.5350\n",
            "26/75, train_loss: 0.4102\n",
            "27/75, train_loss: 0.4641\n",
            "28/75, train_loss: 0.3735\n",
            "29/75, train_loss: 0.4084\n",
            "30/75, train_loss: 0.4859\n",
            "31/75, train_loss: 0.4933\n",
            "32/75, train_loss: 0.5487\n",
            "33/75, train_loss: 0.5329\n",
            "34/75, train_loss: 0.4900\n",
            "35/75, train_loss: 0.3750\n",
            "36/75, train_loss: 0.4504\n",
            "37/75, train_loss: 0.4840\n",
            "38/75, train_loss: 0.4074\n",
            "39/75, train_loss: 0.2986\n",
            "40/75, train_loss: 0.4318\n",
            "41/75, train_loss: 0.4404\n",
            "42/75, train_loss: 0.4865\n",
            "43/75, train_loss: 0.4463\n",
            "44/75, train_loss: 0.4821\n",
            "45/75, train_loss: 0.4202\n",
            "46/75, train_loss: 0.6005\n",
            "47/75, train_loss: 0.5932\n",
            "48/75, train_loss: 0.5398\n",
            "49/75, train_loss: 0.4924\n",
            "50/75, train_loss: 0.4537\n",
            "51/75, train_loss: 0.5291\n",
            "52/75, train_loss: 0.3502\n",
            "53/75, train_loss: 0.4645\n",
            "54/75, train_loss: 0.4109\n",
            "55/75, train_loss: 0.4960\n",
            "56/75, train_loss: 0.5092\n",
            "57/75, train_loss: 0.4325\n",
            "58/75, train_loss: 0.4630\n",
            "59/75, train_loss: 0.4080\n",
            "60/75, train_loss: 0.4278\n",
            "61/75, train_loss: 0.4923\n",
            "62/75, train_loss: 0.5093\n",
            "63/75, train_loss: 0.4131\n",
            "64/75, train_loss: 0.4849\n",
            "65/75, train_loss: 0.4726\n",
            "66/75, train_loss: 0.5758\n",
            "67/75, train_loss: 0.5568\n",
            "68/75, train_loss: 0.4322\n",
            "69/75, train_loss: 0.4341\n",
            "70/75, train_loss: 0.5094\n",
            "71/75, train_loss: 0.5651\n",
            "72/75, train_loss: 0.4725\n",
            "73/75, train_loss: 0.4917\n",
            "74/75, train_loss: 0.3772\n",
            "75/75, train_loss: 0.5556\n",
            "epoch 74 average loss: 0.4632\n",
            "current epoch: 74 current mean dice: 0.7697\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 75/300\n",
            "1/75, train_loss: 0.5021\n",
            "2/75, train_loss: 0.6315\n",
            "3/75, train_loss: 0.5283\n",
            "4/75, train_loss: 0.5402\n",
            "5/75, train_loss: 0.4083\n",
            "6/75, train_loss: 0.4822\n",
            "7/75, train_loss: 0.3333\n",
            "8/75, train_loss: 0.4155\n",
            "9/75, train_loss: 0.5044\n",
            "10/75, train_loss: 0.4125\n",
            "11/75, train_loss: 0.4758\n",
            "12/75, train_loss: 0.4235\n",
            "13/75, train_loss: 0.4881\n",
            "14/75, train_loss: 0.4277\n",
            "15/75, train_loss: 0.3751\n",
            "16/75, train_loss: 0.4128\n",
            "17/75, train_loss: 0.3919\n",
            "18/75, train_loss: 0.4888\n",
            "19/75, train_loss: 0.3862\n",
            "20/75, train_loss: 0.4783\n",
            "21/75, train_loss: 0.4826\n",
            "22/75, train_loss: 0.6447\n",
            "23/75, train_loss: 0.4410\n",
            "24/75, train_loss: 0.5497\n",
            "25/75, train_loss: 0.4605\n",
            "26/75, train_loss: 0.5555\n",
            "27/75, train_loss: 0.4859\n",
            "28/75, train_loss: 0.4672\n",
            "29/75, train_loss: 0.4779\n",
            "30/75, train_loss: 0.3969\n",
            "31/75, train_loss: 0.3690\n",
            "32/75, train_loss: 0.4535\n",
            "33/75, train_loss: 0.4961\n",
            "34/75, train_loss: 0.4074\n",
            "35/75, train_loss: 0.4559\n",
            "36/75, train_loss: 0.4039\n",
            "37/75, train_loss: 0.4657\n",
            "38/75, train_loss: 0.5667\n",
            "39/75, train_loss: 0.5071\n",
            "40/75, train_loss: 0.5286\n",
            "41/75, train_loss: 0.3926\n",
            "42/75, train_loss: 0.4596\n",
            "43/75, train_loss: 0.4586\n",
            "44/75, train_loss: 0.5039\n",
            "45/75, train_loss: 0.4941\n",
            "46/75, train_loss: 0.5125\n",
            "47/75, train_loss: 0.4261\n",
            "48/75, train_loss: 0.5168\n",
            "49/75, train_loss: 0.4583\n",
            "50/75, train_loss: 0.6499\n",
            "51/75, train_loss: 0.5963\n",
            "52/75, train_loss: 0.4682\n",
            "53/75, train_loss: 0.4115\n",
            "54/75, train_loss: 0.5039\n",
            "55/75, train_loss: 0.4273\n",
            "56/75, train_loss: 0.3984\n",
            "57/75, train_loss: 0.6361\n",
            "58/75, train_loss: 0.5599\n",
            "59/75, train_loss: 0.5341\n",
            "60/75, train_loss: 0.4432\n",
            "61/75, train_loss: 0.4111\n",
            "62/75, train_loss: 0.2972\n",
            "63/75, train_loss: 0.4760\n",
            "64/75, train_loss: 0.4458\n",
            "65/75, train_loss: 0.4915\n",
            "66/75, train_loss: 0.4983\n",
            "67/75, train_loss: 0.4889\n",
            "68/75, train_loss: 0.3424\n",
            "69/75, train_loss: 0.5585\n",
            "70/75, train_loss: 0.5508\n",
            "71/75, train_loss: 0.5148\n",
            "72/75, train_loss: 0.5758\n",
            "73/75, train_loss: 0.4490\n",
            "74/75, train_loss: 0.5310\n",
            "75/75, train_loss: 0.2878\n",
            "epoch 75 average loss: 0.4732\n",
            "current epoch: 75 current mean dice: 0.7714\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 76/300\n",
            "1/75, train_loss: 0.5595\n",
            "2/75, train_loss: 0.4746\n",
            "3/75, train_loss: 0.4925\n",
            "4/75, train_loss: 0.4902\n",
            "5/75, train_loss: 0.4383\n",
            "6/75, train_loss: 0.5356\n",
            "7/75, train_loss: 0.4441\n",
            "8/75, train_loss: 0.4518\n",
            "9/75, train_loss: 0.4834\n",
            "10/75, train_loss: 0.4854\n",
            "11/75, train_loss: 0.4662\n",
            "12/75, train_loss: 0.4531\n",
            "13/75, train_loss: 0.5242\n",
            "14/75, train_loss: 0.3745\n",
            "15/75, train_loss: 0.5342\n",
            "16/75, train_loss: 0.4077\n",
            "17/75, train_loss: 0.4168\n",
            "18/75, train_loss: 0.4732\n",
            "19/75, train_loss: 0.4723\n",
            "20/75, train_loss: 0.4560\n",
            "21/75, train_loss: 0.5192\n",
            "22/75, train_loss: 0.5570\n",
            "23/75, train_loss: 0.4277\n",
            "24/75, train_loss: 0.3528\n",
            "25/75, train_loss: 0.4572\n",
            "26/75, train_loss: 0.3186\n",
            "27/75, train_loss: 0.3756\n",
            "28/75, train_loss: 0.3950\n",
            "29/75, train_loss: 0.4320\n",
            "30/75, train_loss: 0.5189\n",
            "31/75, train_loss: 0.4767\n",
            "32/75, train_loss: 0.3769\n",
            "33/75, train_loss: 0.5324\n",
            "34/75, train_loss: 0.3199\n",
            "35/75, train_loss: 0.4900\n",
            "36/75, train_loss: 0.4966\n",
            "37/75, train_loss: 0.6254\n",
            "38/75, train_loss: 0.5085\n",
            "39/75, train_loss: 0.5879\n",
            "40/75, train_loss: 0.4099\n",
            "41/75, train_loss: 0.5639\n",
            "42/75, train_loss: 0.4852\n",
            "43/75, train_loss: 0.4377\n",
            "44/75, train_loss: 0.5140\n",
            "45/75, train_loss: 0.4784\n",
            "46/75, train_loss: 0.5221\n",
            "47/75, train_loss: 0.5470\n",
            "48/75, train_loss: 0.4477\n",
            "49/75, train_loss: 0.4346\n",
            "50/75, train_loss: 0.4366\n",
            "51/75, train_loss: 0.4278\n",
            "52/75, train_loss: 0.5626\n",
            "53/75, train_loss: 0.4219\n",
            "54/75, train_loss: 0.4450\n",
            "55/75, train_loss: 0.6415\n",
            "56/75, train_loss: 0.4775\n",
            "57/75, train_loss: 0.4541\n",
            "58/75, train_loss: 0.4371\n",
            "59/75, train_loss: 0.4521\n",
            "60/75, train_loss: 0.4734\n",
            "61/75, train_loss: 0.4812\n",
            "62/75, train_loss: 0.4444\n",
            "63/75, train_loss: 0.4719\n",
            "64/75, train_loss: 0.4255\n",
            "65/75, train_loss: 0.3998\n",
            "66/75, train_loss: 0.5080\n",
            "67/75, train_loss: 0.4199\n",
            "68/75, train_loss: 0.4268\n",
            "69/75, train_loss: 0.3581\n",
            "70/75, train_loss: 0.5933\n",
            "71/75, train_loss: 0.3724\n",
            "72/75, train_loss: 0.5296\n",
            "73/75, train_loss: 0.4751\n",
            "74/75, train_loss: 0.4828\n",
            "75/75, train_loss: 0.5096\n",
            "epoch 76 average loss: 0.4689\n",
            "current epoch: 76 current mean dice: 0.7417\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 77/300\n",
            "1/75, train_loss: 0.3133\n",
            "2/75, train_loss: 0.5040\n",
            "3/75, train_loss: 0.5084\n",
            "4/75, train_loss: 0.4453\n",
            "5/75, train_loss: 0.4685\n",
            "6/75, train_loss: 0.4105\n",
            "7/75, train_loss: 0.5089\n",
            "8/75, train_loss: 0.4171\n",
            "9/75, train_loss: 0.4864\n",
            "10/75, train_loss: 0.4558\n",
            "11/75, train_loss: 0.5772\n",
            "12/75, train_loss: 0.5447\n",
            "13/75, train_loss: 0.4634\n",
            "14/75, train_loss: 0.3930\n",
            "15/75, train_loss: 0.3327\n",
            "16/75, train_loss: 0.4520\n",
            "17/75, train_loss: 0.5449\n",
            "18/75, train_loss: 0.2999\n",
            "19/75, train_loss: 0.4467\n",
            "20/75, train_loss: 0.4508\n",
            "21/75, train_loss: 0.5270\n",
            "22/75, train_loss: 0.5392\n",
            "23/75, train_loss: 0.4839\n",
            "24/75, train_loss: 0.4734\n",
            "25/75, train_loss: 0.4467\n",
            "26/75, train_loss: 0.4457\n",
            "27/75, train_loss: 0.5145\n",
            "28/75, train_loss: 0.4978\n",
            "29/75, train_loss: 0.5219\n",
            "30/75, train_loss: 0.4484\n",
            "31/75, train_loss: 0.5164\n",
            "32/75, train_loss: 0.4948\n",
            "33/75, train_loss: 0.3399\n",
            "34/75, train_loss: 0.5073\n",
            "35/75, train_loss: 0.5899\n",
            "36/75, train_loss: 0.5076\n",
            "37/75, train_loss: 0.4392\n",
            "38/75, train_loss: 0.5353\n",
            "39/75, train_loss: 0.4435\n",
            "40/75, train_loss: 0.3547\n",
            "41/75, train_loss: 0.4470\n",
            "42/75, train_loss: 0.4956\n",
            "43/75, train_loss: 0.5166\n",
            "44/75, train_loss: 0.4712\n",
            "45/75, train_loss: 0.4638\n",
            "46/75, train_loss: 0.4101\n",
            "47/75, train_loss: 0.4892\n",
            "48/75, train_loss: 0.5372\n",
            "49/75, train_loss: 0.5331\n",
            "50/75, train_loss: 0.5510\n",
            "51/75, train_loss: 0.6192\n",
            "52/75, train_loss: 0.4529\n",
            "53/75, train_loss: 0.4089\n",
            "54/75, train_loss: 0.5713\n",
            "55/75, train_loss: 0.4566\n",
            "56/75, train_loss: 0.3887\n",
            "57/75, train_loss: 0.5089\n",
            "58/75, train_loss: 0.4206\n",
            "59/75, train_loss: 0.5392\n",
            "60/75, train_loss: 0.5781\n",
            "61/75, train_loss: 0.4695\n",
            "62/75, train_loss: 0.3997\n",
            "63/75, train_loss: 0.4101\n",
            "64/75, train_loss: 0.3711\n",
            "65/75, train_loss: 0.4921\n",
            "66/75, train_loss: 0.3825\n",
            "67/75, train_loss: 0.5354\n",
            "68/75, train_loss: 0.4235\n",
            "69/75, train_loss: 0.4734\n",
            "70/75, train_loss: 0.4216\n",
            "71/75, train_loss: 0.4096\n",
            "72/75, train_loss: 0.5915\n",
            "73/75, train_loss: 0.3451\n",
            "74/75, train_loss: 0.6154\n",
            "75/75, train_loss: 0.5550\n",
            "epoch 77 average loss: 0.4721\n",
            "current epoch: 77 current mean dice: 0.7815\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 78/300\n",
            "1/75, train_loss: 0.3876\n",
            "2/75, train_loss: 0.4348\n",
            "3/75, train_loss: 0.5099\n",
            "4/75, train_loss: 0.6130\n",
            "5/75, train_loss: 0.4050\n",
            "6/75, train_loss: 0.5280\n",
            "7/75, train_loss: 0.4557\n",
            "8/75, train_loss: 0.4547\n",
            "9/75, train_loss: 0.5350\n",
            "10/75, train_loss: 0.5816\n",
            "11/75, train_loss: 0.3524\n",
            "12/75, train_loss: 0.3797\n",
            "13/75, train_loss: 0.3804\n",
            "14/75, train_loss: 0.4678\n",
            "15/75, train_loss: 0.3474\n",
            "16/75, train_loss: 0.4508\n",
            "17/75, train_loss: 0.3766\n",
            "18/75, train_loss: 0.4066\n",
            "19/75, train_loss: 0.4571\n",
            "20/75, train_loss: 0.4611\n",
            "21/75, train_loss: 0.4996\n",
            "22/75, train_loss: 0.3781\n",
            "23/75, train_loss: 0.4227\n",
            "24/75, train_loss: 0.5996\n",
            "25/75, train_loss: 0.4726\n",
            "26/75, train_loss: 0.4630\n",
            "27/75, train_loss: 0.5508\n",
            "28/75, train_loss: 0.3316\n",
            "29/75, train_loss: 0.4133\n",
            "30/75, train_loss: 0.4845\n",
            "31/75, train_loss: 0.4837\n",
            "32/75, train_loss: 0.4564\n",
            "33/75, train_loss: 0.5987\n",
            "34/75, train_loss: 0.4607\n",
            "35/75, train_loss: 0.4476\n",
            "36/75, train_loss: 0.4775\n",
            "37/75, train_loss: 0.5457\n",
            "38/75, train_loss: 0.5061\n",
            "39/75, train_loss: 0.4090\n",
            "40/75, train_loss: 0.4986\n",
            "41/75, train_loss: 0.4868\n",
            "42/75, train_loss: 0.3592\n",
            "43/75, train_loss: 0.5278\n",
            "44/75, train_loss: 0.3163\n",
            "45/75, train_loss: 0.4245\n",
            "46/75, train_loss: 0.3835\n",
            "47/75, train_loss: 0.4442\n",
            "48/75, train_loss: 0.4975\n",
            "49/75, train_loss: 0.4977\n",
            "50/75, train_loss: 0.4997\n",
            "51/75, train_loss: 0.4839\n",
            "52/75, train_loss: 0.6291\n",
            "53/75, train_loss: 0.4115\n",
            "54/75, train_loss: 0.3269\n",
            "55/75, train_loss: 0.5036\n",
            "56/75, train_loss: 0.5381\n",
            "57/75, train_loss: 0.5142\n",
            "58/75, train_loss: 0.4287\n",
            "59/75, train_loss: 0.4169\n",
            "60/75, train_loss: 0.5660\n",
            "61/75, train_loss: 0.5806\n",
            "62/75, train_loss: 0.4249\n",
            "63/75, train_loss: 0.5913\n",
            "64/75, train_loss: 0.4647\n",
            "65/75, train_loss: 0.3951\n",
            "66/75, train_loss: 0.5348\n",
            "67/75, train_loss: 0.3540\n",
            "68/75, train_loss: 0.4884\n",
            "69/75, train_loss: 0.4630\n",
            "70/75, train_loss: 0.3834\n",
            "71/75, train_loss: 0.5838\n",
            "72/75, train_loss: 0.5253\n",
            "73/75, train_loss: 0.5873\n",
            "74/75, train_loss: 0.4173\n",
            "75/75, train_loss: 0.5426\n",
            "epoch 78 average loss: 0.4677\n",
            "current epoch: 78 current mean dice: 0.7530\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 79/300\n",
            "1/75, train_loss: 0.4944\n",
            "2/75, train_loss: 0.5414\n",
            "3/75, train_loss: 0.4595\n",
            "4/75, train_loss: 0.4821\n",
            "5/75, train_loss: 0.3847\n",
            "6/75, train_loss: 0.4509\n",
            "7/75, train_loss: 0.4946\n",
            "8/75, train_loss: 0.3428\n",
            "9/75, train_loss: 0.4528\n",
            "10/75, train_loss: 0.4048\n",
            "11/75, train_loss: 0.4015\n",
            "12/75, train_loss: 0.3944\n",
            "13/75, train_loss: 0.3266\n",
            "14/75, train_loss: 0.4196\n",
            "15/75, train_loss: 0.5343\n",
            "16/75, train_loss: 0.5357\n",
            "17/75, train_loss: 0.5002\n",
            "18/75, train_loss: 0.4406\n",
            "19/75, train_loss: 0.4105\n",
            "20/75, train_loss: 0.4885\n",
            "21/75, train_loss: 0.4497\n",
            "22/75, train_loss: 0.4665\n",
            "23/75, train_loss: 0.5502\n",
            "24/75, train_loss: 0.4378\n",
            "25/75, train_loss: 0.3984\n",
            "26/75, train_loss: 0.5494\n",
            "27/75, train_loss: 0.5142\n",
            "28/75, train_loss: 0.3458\n",
            "29/75, train_loss: 0.5619\n",
            "30/75, train_loss: 0.4984\n",
            "31/75, train_loss: 0.4722\n",
            "32/75, train_loss: 0.4655\n",
            "33/75, train_loss: 0.4460\n",
            "34/75, train_loss: 0.4359\n",
            "35/75, train_loss: 0.5445\n",
            "36/75, train_loss: 0.3242\n",
            "37/75, train_loss: 0.4068\n",
            "38/75, train_loss: 0.4557\n",
            "39/75, train_loss: 0.4225\n",
            "40/75, train_loss: 0.3482\n",
            "41/75, train_loss: 0.4757\n",
            "42/75, train_loss: 0.4833\n",
            "43/75, train_loss: 0.3581\n",
            "44/75, train_loss: 0.3845\n",
            "45/75, train_loss: 0.5018\n",
            "46/75, train_loss: 0.4031\n",
            "47/75, train_loss: 0.5371\n",
            "48/75, train_loss: 0.3923\n",
            "49/75, train_loss: 0.4683\n",
            "50/75, train_loss: 0.5746\n",
            "51/75, train_loss: 0.5145\n",
            "52/75, train_loss: 0.5659\n",
            "53/75, train_loss: 0.4135\n",
            "54/75, train_loss: 0.5659\n",
            "55/75, train_loss: 0.5706\n",
            "56/75, train_loss: 0.3353\n",
            "57/75, train_loss: 0.4447\n",
            "58/75, train_loss: 0.3999\n",
            "59/75, train_loss: 0.4927\n",
            "60/75, train_loss: 0.4687\n",
            "61/75, train_loss: 0.4334\n",
            "62/75, train_loss: 0.4629\n",
            "63/75, train_loss: 0.4573\n",
            "64/75, train_loss: 0.5131\n",
            "65/75, train_loss: 0.4546\n",
            "66/75, train_loss: 0.5378\n",
            "67/75, train_loss: 0.5015\n",
            "68/75, train_loss: 0.4200\n",
            "69/75, train_loss: 0.4637\n",
            "70/75, train_loss: 0.5311\n",
            "71/75, train_loss: 0.4572\n",
            "72/75, train_loss: 0.5059\n",
            "73/75, train_loss: 0.5192\n",
            "74/75, train_loss: 0.5670\n",
            "75/75, train_loss: 0.4609\n",
            "epoch 79 average loss: 0.4625\n",
            "current epoch: 79 current mean dice: 0.7732\n",
            "best mean dice: 0.7955 at epoch: 54\n",
            "----------\n",
            "epoch 80/300\n",
            "1/75, train_loss: 0.4359\n",
            "2/75, train_loss: 0.4386\n",
            "3/75, train_loss: 0.4642\n",
            "4/75, train_loss: 0.5415\n",
            "5/75, train_loss: 0.4709\n",
            "6/75, train_loss: 0.4084\n",
            "7/75, train_loss: 0.3906\n",
            "8/75, train_loss: 0.3516\n",
            "9/75, train_loss: 0.3998\n",
            "10/75, train_loss: 0.3702\n",
            "11/75, train_loss: 0.4921\n",
            "12/75, train_loss: 0.4147\n",
            "13/75, train_loss: 0.5025\n",
            "14/75, train_loss: 0.4361\n",
            "15/75, train_loss: 0.5444\n",
            "16/75, train_loss: 0.4095\n",
            "17/75, train_loss: 0.4275\n",
            "18/75, train_loss: 0.3898\n",
            "19/75, train_loss: 0.4921\n",
            "20/75, train_loss: 0.5589\n",
            "21/75, train_loss: 0.5314\n",
            "22/75, train_loss: 0.5518\n",
            "23/75, train_loss: 0.3562\n",
            "24/75, train_loss: 0.5139\n",
            "25/75, train_loss: 0.4240\n",
            "26/75, train_loss: 0.3537\n",
            "27/75, train_loss: 0.5604\n",
            "28/75, train_loss: 0.4442\n",
            "29/75, train_loss: 0.5116\n",
            "30/75, train_loss: 0.4032\n",
            "31/75, train_loss: 0.4608\n",
            "32/75, train_loss: 0.4021\n",
            "33/75, train_loss: 0.4573\n",
            "34/75, train_loss: 0.4651\n",
            "35/75, train_loss: 0.5525\n",
            "36/75, train_loss: 0.4663\n",
            "37/75, train_loss: 0.3731\n",
            "38/75, train_loss: 0.4191\n",
            "39/75, train_loss: 0.5557\n",
            "40/75, train_loss: 0.5383\n",
            "41/75, train_loss: 0.4681\n",
            "42/75, train_loss: 0.5287\n",
            "43/75, train_loss: 0.5226\n",
            "44/75, train_loss: 0.6023\n",
            "45/75, train_loss: 0.4712\n",
            "46/75, train_loss: 0.5195\n",
            "47/75, train_loss: 0.5359\n",
            "48/75, train_loss: 0.5026\n",
            "49/75, train_loss: 0.5811\n",
            "50/75, train_loss: 0.6308\n",
            "51/75, train_loss: 0.4989\n",
            "52/75, train_loss: 0.4417\n",
            "53/75, train_loss: 0.5012\n",
            "54/75, train_loss: 0.4113\n",
            "55/75, train_loss: 0.3720\n",
            "56/75, train_loss: 0.5012\n",
            "57/75, train_loss: 0.5024\n",
            "58/75, train_loss: 0.3655\n",
            "59/75, train_loss: 0.4139\n",
            "60/75, train_loss: 0.3506\n",
            "61/75, train_loss: 0.4455\n",
            "62/75, train_loss: 0.4268\n",
            "63/75, train_loss: 0.3573\n",
            "64/75, train_loss: 0.3914\n",
            "65/75, train_loss: 0.4466\n",
            "66/75, train_loss: 0.5817\n",
            "67/75, train_loss: 0.5126\n",
            "68/75, train_loss: 0.4723\n",
            "69/75, train_loss: 0.4968\n",
            "70/75, train_loss: 0.5069\n",
            "71/75, train_loss: 0.5671\n",
            "72/75, train_loss: 0.5574\n",
            "73/75, train_loss: 0.4623\n",
            "74/75, train_loss: 0.3235\n",
            "75/75, train_loss: 0.5072\n",
            "epoch 80 average loss: 0.4674\n",
            "saved new best metric model\n",
            "current epoch: 80 current mean dice: 0.8002\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 81/300\n",
            "1/75, train_loss: 0.4661\n",
            "2/75, train_loss: 0.5012\n",
            "3/75, train_loss: 0.5173\n",
            "4/75, train_loss: 0.4888\n",
            "5/75, train_loss: 0.3022\n",
            "6/75, train_loss: 0.4457\n",
            "7/75, train_loss: 0.4861\n",
            "8/75, train_loss: 0.4111\n",
            "9/75, train_loss: 0.4900\n",
            "10/75, train_loss: 0.4726\n",
            "11/75, train_loss: 0.5242\n",
            "12/75, train_loss: 0.3587\n",
            "13/75, train_loss: 0.5081\n",
            "14/75, train_loss: 0.4396\n",
            "15/75, train_loss: 0.4114\n",
            "16/75, train_loss: 0.4876\n",
            "17/75, train_loss: 0.3992\n",
            "18/75, train_loss: 0.4485\n",
            "19/75, train_loss: 0.4033\n",
            "20/75, train_loss: 0.4053\n",
            "21/75, train_loss: 0.5703\n",
            "22/75, train_loss: 0.4991\n",
            "23/75, train_loss: 0.5099\n",
            "24/75, train_loss: 0.5308\n",
            "25/75, train_loss: 0.5700\n",
            "26/75, train_loss: 0.4506\n",
            "27/75, train_loss: 0.5812\n",
            "28/75, train_loss: 0.4275\n",
            "29/75, train_loss: 0.4301\n",
            "30/75, train_loss: 0.5481\n",
            "31/75, train_loss: 0.3805\n",
            "32/75, train_loss: 0.5460\n",
            "33/75, train_loss: 0.5477\n",
            "34/75, train_loss: 0.5120\n",
            "35/75, train_loss: 0.4841\n",
            "36/75, train_loss: 0.3164\n",
            "37/75, train_loss: 0.5569\n",
            "38/75, train_loss: 0.5332\n",
            "39/75, train_loss: 0.4910\n",
            "40/75, train_loss: 0.4061\n",
            "41/75, train_loss: 0.5882\n",
            "42/75, train_loss: 0.3326\n",
            "43/75, train_loss: 0.4669\n",
            "44/75, train_loss: 0.4259\n",
            "45/75, train_loss: 0.5573\n",
            "46/75, train_loss: 0.5858\n",
            "47/75, train_loss: 0.4220\n",
            "48/75, train_loss: 0.4391\n",
            "49/75, train_loss: 0.3643\n",
            "50/75, train_loss: 0.5195\n",
            "51/75, train_loss: 0.5166\n",
            "52/75, train_loss: 0.4708\n",
            "53/75, train_loss: 0.4247\n",
            "54/75, train_loss: 0.4449\n",
            "55/75, train_loss: 0.4316\n",
            "56/75, train_loss: 0.5296\n",
            "57/75, train_loss: 0.3038\n",
            "58/75, train_loss: 0.4227\n",
            "59/75, train_loss: 0.5869\n",
            "60/75, train_loss: 0.5180\n",
            "61/75, train_loss: 0.4808\n",
            "62/75, train_loss: 0.3187\n",
            "63/75, train_loss: 0.3946\n",
            "64/75, train_loss: 0.5739\n",
            "65/75, train_loss: 0.4770\n",
            "66/75, train_loss: 0.4574\n",
            "67/75, train_loss: 0.4173\n",
            "68/75, train_loss: 0.4496\n",
            "69/75, train_loss: 0.5491\n",
            "70/75, train_loss: 0.5791\n",
            "71/75, train_loss: 0.4171\n",
            "72/75, train_loss: 0.6108\n",
            "73/75, train_loss: 0.6796\n",
            "74/75, train_loss: 0.4739\n",
            "75/75, train_loss: 0.4762\n",
            "epoch 81 average loss: 0.4742\n",
            "current epoch: 81 current mean dice: 0.7413\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 82/300\n",
            "1/75, train_loss: 0.5341\n",
            "2/75, train_loss: 0.4931\n",
            "3/75, train_loss: 0.6223\n",
            "4/75, train_loss: 0.5007\n",
            "5/75, train_loss: 0.5001\n",
            "6/75, train_loss: 0.4410\n",
            "7/75, train_loss: 0.4517\n",
            "8/75, train_loss: 0.4407\n",
            "9/75, train_loss: 0.4174\n",
            "10/75, train_loss: 0.5425\n",
            "11/75, train_loss: 0.3794\n",
            "12/75, train_loss: 0.4626\n",
            "13/75, train_loss: 0.4765\n",
            "14/75, train_loss: 0.5316\n",
            "15/75, train_loss: 0.5145\n",
            "16/75, train_loss: 0.4204\n",
            "17/75, train_loss: 0.3290\n",
            "18/75, train_loss: 0.5166\n",
            "19/75, train_loss: 0.4787\n",
            "20/75, train_loss: 0.4352\n",
            "21/75, train_loss: 0.4335\n",
            "22/75, train_loss: 0.4294\n",
            "23/75, train_loss: 0.5205\n",
            "24/75, train_loss: 0.4776\n",
            "25/75, train_loss: 0.5916\n",
            "26/75, train_loss: 0.5761\n",
            "27/75, train_loss: 0.4430\n",
            "28/75, train_loss: 0.4076\n",
            "29/75, train_loss: 0.5632\n",
            "30/75, train_loss: 0.4654\n",
            "31/75, train_loss: 0.5099\n",
            "32/75, train_loss: 0.3419\n",
            "33/75, train_loss: 0.4179\n",
            "34/75, train_loss: 0.4949\n",
            "35/75, train_loss: 0.4012\n",
            "36/75, train_loss: 0.5435\n",
            "37/75, train_loss: 0.3933\n",
            "38/75, train_loss: 0.4875\n",
            "39/75, train_loss: 0.4796\n",
            "40/75, train_loss: 0.4579\n",
            "41/75, train_loss: 0.4799\n",
            "42/75, train_loss: 0.4756\n",
            "43/75, train_loss: 0.4996\n",
            "44/75, train_loss: 0.3853\n",
            "45/75, train_loss: 0.4345\n",
            "46/75, train_loss: 0.3990\n",
            "47/75, train_loss: 0.4625\n",
            "48/75, train_loss: 0.5186\n",
            "49/75, train_loss: 0.5607\n",
            "50/75, train_loss: 0.4510\n",
            "51/75, train_loss: 0.3434\n",
            "52/75, train_loss: 0.5148\n",
            "53/75, train_loss: 0.5058\n",
            "54/75, train_loss: 0.3732\n",
            "55/75, train_loss: 0.4676\n",
            "56/75, train_loss: 0.5194\n",
            "57/75, train_loss: 0.5373\n",
            "58/75, train_loss: 0.5275\n",
            "59/75, train_loss: 0.4122\n",
            "60/75, train_loss: 0.5035\n",
            "61/75, train_loss: 0.4363\n",
            "62/75, train_loss: 0.4701\n",
            "63/75, train_loss: 0.3482\n",
            "64/75, train_loss: 0.4873\n",
            "65/75, train_loss: 0.4765\n",
            "66/75, train_loss: 0.3504\n",
            "67/75, train_loss: 0.3199\n",
            "68/75, train_loss: 0.4601\n",
            "69/75, train_loss: 0.5446\n",
            "70/75, train_loss: 0.4124\n",
            "71/75, train_loss: 0.5059\n",
            "72/75, train_loss: 0.6077\n",
            "73/75, train_loss: 0.5032\n",
            "74/75, train_loss: 0.5531\n",
            "75/75, train_loss: 0.5808\n",
            "epoch 82 average loss: 0.4714\n",
            "current epoch: 82 current mean dice: 0.7521\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 83/300\n",
            "1/75, train_loss: 0.5026\n",
            "2/75, train_loss: 0.5630\n",
            "3/75, train_loss: 0.4007\n",
            "4/75, train_loss: 0.4727\n",
            "5/75, train_loss: 0.4199\n",
            "6/75, train_loss: 0.4991\n",
            "7/75, train_loss: 0.3451\n",
            "8/75, train_loss: 0.4869\n",
            "9/75, train_loss: 0.5014\n",
            "10/75, train_loss: 0.5494\n",
            "11/75, train_loss: 0.4996\n",
            "12/75, train_loss: 0.4215\n",
            "13/75, train_loss: 0.4318\n",
            "14/75, train_loss: 0.5577\n",
            "15/75, train_loss: 0.5618\n",
            "16/75, train_loss: 0.4952\n",
            "17/75, train_loss: 0.4557\n",
            "18/75, train_loss: 0.4560\n",
            "19/75, train_loss: 0.3385\n",
            "20/75, train_loss: 0.3720\n",
            "21/75, train_loss: 0.5585\n",
            "22/75, train_loss: 0.4521\n",
            "23/75, train_loss: 0.5501\n",
            "24/75, train_loss: 0.5553\n",
            "25/75, train_loss: 0.5023\n",
            "26/75, train_loss: 0.5256\n",
            "27/75, train_loss: 0.5256\n",
            "28/75, train_loss: 0.3441\n",
            "29/75, train_loss: 0.4386\n",
            "30/75, train_loss: 0.4266\n",
            "31/75, train_loss: 0.5391\n",
            "32/75, train_loss: 0.5984\n",
            "33/75, train_loss: 0.3774\n",
            "34/75, train_loss: 0.4315\n",
            "35/75, train_loss: 0.3956\n",
            "36/75, train_loss: 0.4661\n",
            "37/75, train_loss: 0.5143\n",
            "38/75, train_loss: 0.4442\n",
            "39/75, train_loss: 0.4656\n",
            "40/75, train_loss: 0.4001\n",
            "41/75, train_loss: 0.6961\n",
            "42/75, train_loss: 0.4862\n",
            "43/75, train_loss: 0.5272\n",
            "44/75, train_loss: 0.3047\n",
            "45/75, train_loss: 0.4609\n",
            "46/75, train_loss: 0.4305\n",
            "47/75, train_loss: 0.3964\n",
            "48/75, train_loss: 0.4304\n",
            "49/75, train_loss: 0.4970\n",
            "50/75, train_loss: 0.5910\n",
            "51/75, train_loss: 0.4607\n",
            "52/75, train_loss: 0.3916\n",
            "53/75, train_loss: 0.4756\n",
            "54/75, train_loss: 0.4273\n",
            "55/75, train_loss: 0.3966\n",
            "56/75, train_loss: 0.4346\n",
            "57/75, train_loss: 0.5328\n",
            "58/75, train_loss: 0.3742\n",
            "59/75, train_loss: 0.4965\n",
            "60/75, train_loss: 0.4021\n",
            "61/75, train_loss: 0.5749\n",
            "62/75, train_loss: 0.5281\n",
            "63/75, train_loss: 0.4088\n",
            "64/75, train_loss: 0.3777\n",
            "65/75, train_loss: 0.5227\n",
            "66/75, train_loss: 0.3691\n",
            "67/75, train_loss: 0.3667\n",
            "68/75, train_loss: 0.4164\n",
            "69/75, train_loss: 0.4898\n",
            "70/75, train_loss: 0.4760\n",
            "71/75, train_loss: 0.4361\n",
            "72/75, train_loss: 0.4079\n",
            "73/75, train_loss: 0.5270\n",
            "74/75, train_loss: 0.4855\n",
            "75/75, train_loss: 0.5725\n",
            "epoch 83 average loss: 0.4668\n",
            "current epoch: 83 current mean dice: 0.7567\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 84/300\n",
            "1/75, train_loss: 0.5322\n",
            "2/75, train_loss: 0.5158\n",
            "3/75, train_loss: 0.4693\n",
            "4/75, train_loss: 0.4033\n",
            "5/75, train_loss: 0.3870\n",
            "6/75, train_loss: 0.5020\n",
            "7/75, train_loss: 0.4765\n",
            "8/75, train_loss: 0.4880\n",
            "9/75, train_loss: 0.4070\n",
            "10/75, train_loss: 0.3747\n",
            "11/75, train_loss: 0.4560\n",
            "12/75, train_loss: 0.3815\n",
            "13/75, train_loss: 0.4282\n",
            "14/75, train_loss: 0.4478\n",
            "15/75, train_loss: 0.4137\n",
            "16/75, train_loss: 0.4135\n",
            "17/75, train_loss: 0.2946\n",
            "18/75, train_loss: 0.5043\n",
            "19/75, train_loss: 0.3523\n",
            "20/75, train_loss: 0.5102\n",
            "21/75, train_loss: 0.5844\n",
            "22/75, train_loss: 0.4640\n",
            "23/75, train_loss: 0.4963\n",
            "24/75, train_loss: 0.5585\n",
            "25/75, train_loss: 0.4328\n",
            "26/75, train_loss: 0.4611\n",
            "27/75, train_loss: 0.5443\n",
            "28/75, train_loss: 0.4579\n",
            "29/75, train_loss: 0.4223\n",
            "30/75, train_loss: 0.4232\n",
            "31/75, train_loss: 0.4397\n",
            "32/75, train_loss: 0.3660\n",
            "33/75, train_loss: 0.4461\n",
            "34/75, train_loss: 0.4275\n",
            "35/75, train_loss: 0.4100\n",
            "36/75, train_loss: 0.3612\n",
            "37/75, train_loss: 0.5949\n",
            "38/75, train_loss: 0.4009\n",
            "39/75, train_loss: 0.4690\n",
            "40/75, train_loss: 0.4124\n",
            "41/75, train_loss: 0.4532\n",
            "42/75, train_loss: 0.4802\n",
            "43/75, train_loss: 0.4526\n",
            "44/75, train_loss: 0.4243\n",
            "45/75, train_loss: 0.4998\n",
            "46/75, train_loss: 0.5519\n",
            "47/75, train_loss: 0.4396\n",
            "48/75, train_loss: 0.5453\n",
            "49/75, train_loss: 0.4277\n",
            "50/75, train_loss: 0.4857\n",
            "51/75, train_loss: 0.4737\n",
            "52/75, train_loss: 0.4071\n",
            "53/75, train_loss: 0.4897\n",
            "54/75, train_loss: 0.4278\n",
            "55/75, train_loss: 0.4939\n",
            "56/75, train_loss: 0.4516\n",
            "57/75, train_loss: 0.4234\n",
            "58/75, train_loss: 0.5276\n",
            "59/75, train_loss: 0.4324\n",
            "60/75, train_loss: 0.4377\n",
            "61/75, train_loss: 0.4265\n",
            "62/75, train_loss: 0.4215\n",
            "63/75, train_loss: 0.4351\n",
            "64/75, train_loss: 0.3627\n",
            "65/75, train_loss: 0.4719\n",
            "66/75, train_loss: 0.3629\n",
            "67/75, train_loss: 0.4358\n",
            "68/75, train_loss: 0.5563\n",
            "69/75, train_loss: 0.6328\n",
            "70/75, train_loss: 0.5085\n",
            "71/75, train_loss: 0.4954\n",
            "72/75, train_loss: 0.6253\n",
            "73/75, train_loss: 0.3653\n",
            "74/75, train_loss: 0.4821\n",
            "75/75, train_loss: 0.5817\n",
            "epoch 84 average loss: 0.4589\n",
            "current epoch: 84 current mean dice: 0.7748\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 85/300\n",
            "1/75, train_loss: 0.4396\n",
            "2/75, train_loss: 0.6289\n",
            "3/75, train_loss: 0.4360\n",
            "4/75, train_loss: 0.4047\n",
            "5/75, train_loss: 0.5629\n",
            "6/75, train_loss: 0.5093\n",
            "7/75, train_loss: 0.4166\n",
            "8/75, train_loss: 0.5343\n",
            "9/75, train_loss: 0.4311\n",
            "10/75, train_loss: 0.4645\n",
            "11/75, train_loss: 0.4451\n",
            "12/75, train_loss: 0.3684\n",
            "13/75, train_loss: 0.4894\n",
            "14/75, train_loss: 0.5075\n",
            "15/75, train_loss: 0.5092\n",
            "16/75, train_loss: 0.4209\n",
            "17/75, train_loss: 0.4263\n",
            "18/75, train_loss: 0.4478\n",
            "19/75, train_loss: 0.5127\n",
            "20/75, train_loss: 0.4426\n",
            "21/75, train_loss: 0.3281\n",
            "22/75, train_loss: 0.5787\n",
            "23/75, train_loss: 0.5289\n",
            "24/75, train_loss: 0.4806\n",
            "25/75, train_loss: 0.5214\n",
            "26/75, train_loss: 0.4293\n",
            "27/75, train_loss: 0.5560\n",
            "28/75, train_loss: 0.5023\n",
            "29/75, train_loss: 0.3748\n",
            "30/75, train_loss: 0.4411\n",
            "31/75, train_loss: 0.5235\n",
            "32/75, train_loss: 0.3837\n",
            "33/75, train_loss: 0.3987\n",
            "34/75, train_loss: 0.3927\n",
            "35/75, train_loss: 0.5413\n",
            "36/75, train_loss: 0.5269\n",
            "37/75, train_loss: 0.4958\n",
            "38/75, train_loss: 0.5164\n",
            "39/75, train_loss: 0.5470\n",
            "40/75, train_loss: 0.4360\n",
            "41/75, train_loss: 0.3707\n",
            "42/75, train_loss: 0.5339\n",
            "43/75, train_loss: 0.5503\n",
            "44/75, train_loss: 0.4507\n",
            "45/75, train_loss: 0.5739\n",
            "46/75, train_loss: 0.6074\n",
            "47/75, train_loss: 0.4644\n",
            "48/75, train_loss: 0.4583\n",
            "49/75, train_loss: 0.4763\n",
            "50/75, train_loss: 0.4580\n",
            "51/75, train_loss: 0.5133\n",
            "52/75, train_loss: 0.3637\n",
            "53/75, train_loss: 0.4813\n",
            "54/75, train_loss: 0.3328\n",
            "55/75, train_loss: 0.4267\n",
            "56/75, train_loss: 0.3797\n",
            "57/75, train_loss: 0.4909\n",
            "58/75, train_loss: 0.5153\n",
            "59/75, train_loss: 0.4673\n",
            "60/75, train_loss: 0.4853\n",
            "61/75, train_loss: 0.4829\n",
            "62/75, train_loss: 0.3962\n",
            "63/75, train_loss: 0.5380\n",
            "64/75, train_loss: 0.5002\n",
            "65/75, train_loss: 0.3722\n",
            "66/75, train_loss: 0.3746\n",
            "67/75, train_loss: 0.4548\n",
            "68/75, train_loss: 0.4172\n",
            "69/75, train_loss: 0.5559\n",
            "70/75, train_loss: 0.4109\n",
            "71/75, train_loss: 0.4371\n",
            "72/75, train_loss: 0.4833\n",
            "73/75, train_loss: 0.4930\n",
            "74/75, train_loss: 0.5157\n",
            "75/75, train_loss: 0.5528\n",
            "epoch 85 average loss: 0.4705\n",
            "current epoch: 85 current mean dice: 0.7746\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 86/300\n",
            "1/75, train_loss: 0.4104\n",
            "2/75, train_loss: 0.3778\n",
            "3/75, train_loss: 0.4269\n",
            "4/75, train_loss: 0.4649\n",
            "5/75, train_loss: 0.4166\n",
            "6/75, train_loss: 0.3639\n",
            "7/75, train_loss: 0.4702\n",
            "8/75, train_loss: 0.3764\n",
            "9/75, train_loss: 0.4430\n",
            "10/75, train_loss: 0.2687\n",
            "11/75, train_loss: 0.4552\n",
            "12/75, train_loss: 0.4806\n",
            "13/75, train_loss: 0.4063\n",
            "14/75, train_loss: 0.3765\n",
            "15/75, train_loss: 0.4306\n",
            "16/75, train_loss: 0.3565\n",
            "17/75, train_loss: 0.5029\n",
            "18/75, train_loss: 0.4258\n",
            "19/75, train_loss: 0.4090\n",
            "20/75, train_loss: 0.4010\n",
            "21/75, train_loss: 0.3550\n",
            "22/75, train_loss: 0.4457\n",
            "23/75, train_loss: 0.5373\n",
            "24/75, train_loss: 0.4428\n",
            "25/75, train_loss: 0.4732\n",
            "26/75, train_loss: 0.3914\n",
            "27/75, train_loss: 0.5159\n",
            "28/75, train_loss: 0.4697\n",
            "29/75, train_loss: 0.4774\n",
            "30/75, train_loss: 0.4953\n",
            "31/75, train_loss: 0.4731\n",
            "32/75, train_loss: 0.3363\n",
            "33/75, train_loss: 0.5117\n",
            "34/75, train_loss: 0.4628\n",
            "35/75, train_loss: 0.5527\n",
            "36/75, train_loss: 0.5054\n",
            "37/75, train_loss: 0.3831\n",
            "38/75, train_loss: 0.5447\n",
            "39/75, train_loss: 0.3723\n",
            "40/75, train_loss: 0.3750\n",
            "41/75, train_loss: 0.4173\n",
            "42/75, train_loss: 0.6261\n",
            "43/75, train_loss: 0.4070\n",
            "44/75, train_loss: 0.5055\n",
            "45/75, train_loss: 0.3874\n",
            "46/75, train_loss: 0.4591\n",
            "47/75, train_loss: 0.4970\n",
            "48/75, train_loss: 0.4283\n",
            "49/75, train_loss: 0.5821\n",
            "50/75, train_loss: 0.4809\n",
            "51/75, train_loss: 0.5163\n",
            "52/75, train_loss: 0.4050\n",
            "53/75, train_loss: 0.5015\n",
            "54/75, train_loss: 0.2378\n",
            "55/75, train_loss: 0.5417\n",
            "56/75, train_loss: 0.4552\n",
            "57/75, train_loss: 0.4389\n",
            "58/75, train_loss: 0.3820\n",
            "59/75, train_loss: 0.4013\n",
            "60/75, train_loss: 0.4174\n",
            "61/75, train_loss: 0.4630\n",
            "62/75, train_loss: 0.4373\n",
            "63/75, train_loss: 0.3866\n",
            "64/75, train_loss: 0.4372\n",
            "65/75, train_loss: 0.4092\n",
            "66/75, train_loss: 0.4097\n",
            "67/75, train_loss: 0.5009\n",
            "68/75, train_loss: 0.5262\n",
            "69/75, train_loss: 0.4969\n",
            "70/75, train_loss: 0.3751\n",
            "71/75, train_loss: 0.4503\n",
            "72/75, train_loss: 0.6828\n",
            "73/75, train_loss: 0.5299\n",
            "74/75, train_loss: 0.5491\n",
            "75/75, train_loss: 0.4699\n",
            "epoch 86 average loss: 0.4480\n",
            "current epoch: 86 current mean dice: 0.7839\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 87/300\n",
            "1/75, train_loss: 0.5758\n",
            "2/75, train_loss: 0.3869\n",
            "3/75, train_loss: 0.4239\n",
            "4/75, train_loss: 0.3856\n",
            "5/75, train_loss: 0.4542\n",
            "6/75, train_loss: 0.4217\n",
            "7/75, train_loss: 0.3714\n",
            "8/75, train_loss: 0.5099\n",
            "9/75, train_loss: 0.4870\n",
            "10/75, train_loss: 0.3923\n",
            "11/75, train_loss: 0.4516\n",
            "12/75, train_loss: 0.5005\n",
            "13/75, train_loss: 0.4635\n",
            "14/75, train_loss: 0.4731\n",
            "15/75, train_loss: 0.3163\n",
            "16/75, train_loss: 0.3622\n",
            "17/75, train_loss: 0.4982\n",
            "18/75, train_loss: 0.3662\n",
            "19/75, train_loss: 0.4606\n",
            "20/75, train_loss: 0.5310\n",
            "21/75, train_loss: 0.4484\n",
            "22/75, train_loss: 0.5010\n",
            "23/75, train_loss: 0.6605\n",
            "24/75, train_loss: 0.3885\n",
            "25/75, train_loss: 0.5139\n",
            "26/75, train_loss: 0.3960\n",
            "27/75, train_loss: 0.3127\n",
            "28/75, train_loss: 0.4741\n",
            "29/75, train_loss: 0.5369\n",
            "30/75, train_loss: 0.5335\n",
            "31/75, train_loss: 0.3139\n",
            "32/75, train_loss: 0.3911\n",
            "33/75, train_loss: 0.4445\n",
            "34/75, train_loss: 0.4766\n",
            "35/75, train_loss: 0.5066\n",
            "36/75, train_loss: 0.3572\n",
            "37/75, train_loss: 0.3971\n",
            "38/75, train_loss: 0.5732\n",
            "39/75, train_loss: 0.5350\n",
            "40/75, train_loss: 0.4791\n",
            "41/75, train_loss: 0.5541\n",
            "42/75, train_loss: 0.4823\n",
            "43/75, train_loss: 0.4886\n",
            "44/75, train_loss: 0.4464\n",
            "45/75, train_loss: 0.4894\n",
            "46/75, train_loss: 0.5278\n",
            "47/75, train_loss: 0.4620\n",
            "48/75, train_loss: 0.4788\n",
            "49/75, train_loss: 0.5600\n",
            "50/75, train_loss: 0.4316\n",
            "51/75, train_loss: 0.5019\n",
            "52/75, train_loss: 0.4998\n",
            "53/75, train_loss: 0.4139\n",
            "54/75, train_loss: 0.3807\n",
            "55/75, train_loss: 0.4516\n",
            "56/75, train_loss: 0.5883\n",
            "57/75, train_loss: 0.4485\n",
            "58/75, train_loss: 0.3901\n",
            "59/75, train_loss: 0.4111\n",
            "60/75, train_loss: 0.3813\n",
            "61/75, train_loss: 0.4932\n",
            "62/75, train_loss: 0.3775\n",
            "63/75, train_loss: 0.4336\n",
            "64/75, train_loss: 0.3806\n",
            "65/75, train_loss: 0.3869\n",
            "66/75, train_loss: 0.4173\n",
            "67/75, train_loss: 0.2836\n",
            "68/75, train_loss: 0.4488\n",
            "69/75, train_loss: 0.5184\n",
            "70/75, train_loss: 0.5069\n",
            "71/75, train_loss: 0.4562\n",
            "72/75, train_loss: 0.4471\n",
            "73/75, train_loss: 0.4770\n",
            "74/75, train_loss: 0.3600\n",
            "75/75, train_loss: 0.5206\n",
            "epoch 87 average loss: 0.4529\n",
            "current epoch: 87 current mean dice: 0.7377\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 88/300\n",
            "1/75, train_loss: 0.5262\n",
            "2/75, train_loss: 0.5011\n",
            "3/75, train_loss: 0.3474\n",
            "4/75, train_loss: 0.4805\n",
            "5/75, train_loss: 0.4986\n",
            "6/75, train_loss: 0.3581\n",
            "7/75, train_loss: 0.5130\n",
            "8/75, train_loss: 0.4220\n",
            "9/75, train_loss: 0.4659\n",
            "10/75, train_loss: 0.4471\n",
            "11/75, train_loss: 0.4387\n",
            "12/75, train_loss: 0.4634\n",
            "13/75, train_loss: 0.4326\n",
            "14/75, train_loss: 0.3915\n",
            "15/75, train_loss: 0.4917\n",
            "16/75, train_loss: 0.3568\n",
            "17/75, train_loss: 0.4740\n",
            "18/75, train_loss: 0.5010\n",
            "19/75, train_loss: 0.4138\n",
            "20/75, train_loss: 0.4634\n",
            "21/75, train_loss: 0.5640\n",
            "22/75, train_loss: 0.5013\n",
            "23/75, train_loss: 0.5471\n",
            "24/75, train_loss: 0.4479\n",
            "25/75, train_loss: 0.5112\n",
            "26/75, train_loss: 0.3280\n",
            "27/75, train_loss: 0.5631\n",
            "28/75, train_loss: 0.4260\n",
            "29/75, train_loss: 0.3918\n",
            "30/75, train_loss: 0.4633\n",
            "31/75, train_loss: 0.4650\n",
            "32/75, train_loss: 0.4392\n",
            "33/75, train_loss: 0.5673\n",
            "34/75, train_loss: 0.2948\n",
            "35/75, train_loss: 0.4879\n",
            "36/75, train_loss: 0.4777\n",
            "37/75, train_loss: 0.4267\n",
            "38/75, train_loss: 0.3991\n",
            "39/75, train_loss: 0.4358\n",
            "40/75, train_loss: 0.4749\n",
            "41/75, train_loss: 0.5497\n",
            "42/75, train_loss: 0.4616\n",
            "43/75, train_loss: 0.4079\n",
            "44/75, train_loss: 0.5541\n",
            "45/75, train_loss: 0.3963\n",
            "46/75, train_loss: 0.4544\n",
            "47/75, train_loss: 0.4751\n",
            "48/75, train_loss: 0.4016\n",
            "49/75, train_loss: 0.4315\n",
            "50/75, train_loss: 0.5366\n",
            "51/75, train_loss: 0.5674\n",
            "52/75, train_loss: 0.5300\n",
            "53/75, train_loss: 0.3789\n",
            "54/75, train_loss: 0.4083\n",
            "55/75, train_loss: 0.4361\n",
            "56/75, train_loss: 0.4771\n",
            "57/75, train_loss: 0.4799\n",
            "58/75, train_loss: 0.4280\n",
            "59/75, train_loss: 0.4598\n",
            "60/75, train_loss: 0.3845\n",
            "61/75, train_loss: 0.5219\n",
            "62/75, train_loss: 0.3740\n",
            "63/75, train_loss: 0.4170\n",
            "64/75, train_loss: 0.4601\n",
            "65/75, train_loss: 0.5161\n",
            "66/75, train_loss: 0.4704\n",
            "67/75, train_loss: 0.3911\n",
            "68/75, train_loss: 0.4082\n",
            "69/75, train_loss: 0.5183\n",
            "70/75, train_loss: 0.5999\n",
            "71/75, train_loss: 0.4757\n",
            "72/75, train_loss: 0.4572\n",
            "73/75, train_loss: 0.4858\n",
            "74/75, train_loss: 0.3160\n",
            "75/75, train_loss: 0.4103\n",
            "epoch 88 average loss: 0.4565\n",
            "current epoch: 88 current mean dice: 0.7560\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 89/300\n",
            "1/75, train_loss: 0.4603\n",
            "2/75, train_loss: 0.5294\n",
            "3/75, train_loss: 0.3319\n",
            "4/75, train_loss: 0.5202\n",
            "5/75, train_loss: 0.4324\n",
            "6/75, train_loss: 0.5084\n",
            "7/75, train_loss: 0.4820\n",
            "8/75, train_loss: 0.4935\n",
            "9/75, train_loss: 0.3572\n",
            "10/75, train_loss: 0.3169\n",
            "11/75, train_loss: 0.4479\n",
            "12/75, train_loss: 0.3944\n",
            "13/75, train_loss: 0.4486\n",
            "14/75, train_loss: 0.5558\n",
            "15/75, train_loss: 0.4196\n",
            "16/75, train_loss: 0.4236\n",
            "17/75, train_loss: 0.5613\n",
            "18/75, train_loss: 0.3759\n",
            "19/75, train_loss: 0.3889\n",
            "20/75, train_loss: 0.4842\n",
            "21/75, train_loss: 0.4812\n",
            "22/75, train_loss: 0.6026\n",
            "23/75, train_loss: 0.5837\n",
            "24/75, train_loss: 0.5378\n",
            "25/75, train_loss: 0.4579\n",
            "26/75, train_loss: 0.5156\n",
            "27/75, train_loss: 0.5258\n",
            "28/75, train_loss: 0.5002\n",
            "29/75, train_loss: 0.4994\n",
            "30/75, train_loss: 0.4372\n",
            "31/75, train_loss: 0.5403\n",
            "32/75, train_loss: 0.4274\n",
            "33/75, train_loss: 0.5403\n",
            "34/75, train_loss: 0.4846\n",
            "35/75, train_loss: 0.4334\n",
            "36/75, train_loss: 0.5737\n",
            "37/75, train_loss: 0.4076\n",
            "38/75, train_loss: 0.5320\n",
            "39/75, train_loss: 0.5303\n",
            "40/75, train_loss: 0.4375\n",
            "41/75, train_loss: 0.3895\n",
            "42/75, train_loss: 0.5516\n",
            "43/75, train_loss: 0.5262\n",
            "44/75, train_loss: 0.5266\n",
            "45/75, train_loss: 0.4595\n",
            "46/75, train_loss: 0.6312\n",
            "47/75, train_loss: 0.4167\n",
            "48/75, train_loss: 0.3758\n",
            "49/75, train_loss: 0.4899\n",
            "50/75, train_loss: 0.4163\n",
            "51/75, train_loss: 0.4946\n",
            "52/75, train_loss: 0.4776\n",
            "53/75, train_loss: 0.3951\n",
            "54/75, train_loss: 0.4893\n",
            "55/75, train_loss: 0.5018\n",
            "56/75, train_loss: 0.4447\n",
            "57/75, train_loss: 0.3883\n",
            "58/75, train_loss: 0.4724\n",
            "59/75, train_loss: 0.4719\n",
            "60/75, train_loss: 0.5355\n",
            "61/75, train_loss: 0.5000\n",
            "62/75, train_loss: 0.3533\n",
            "63/75, train_loss: 0.5528\n",
            "64/75, train_loss: 0.3742\n",
            "65/75, train_loss: 0.4913\n",
            "66/75, train_loss: 0.4723\n",
            "67/75, train_loss: 0.4876\n",
            "68/75, train_loss: 0.3628\n",
            "69/75, train_loss: 0.3155\n",
            "70/75, train_loss: 0.4698\n",
            "71/75, train_loss: 0.4973\n",
            "72/75, train_loss: 0.4153\n",
            "73/75, train_loss: 0.4782\n",
            "74/75, train_loss: 0.3918\n",
            "75/75, train_loss: 0.5836\n",
            "epoch 89 average loss: 0.4691\n",
            "current epoch: 89 current mean dice: 0.7596\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 90/300\n",
            "1/75, train_loss: 0.3577\n",
            "2/75, train_loss: 0.4638\n",
            "3/75, train_loss: 0.3110\n",
            "4/75, train_loss: 0.5433\n",
            "5/75, train_loss: 0.5478\n",
            "6/75, train_loss: 0.4962\n",
            "7/75, train_loss: 0.3769\n",
            "8/75, train_loss: 0.4108\n",
            "9/75, train_loss: 0.4320\n",
            "10/75, train_loss: 0.3980\n",
            "11/75, train_loss: 0.4908\n",
            "12/75, train_loss: 0.5174\n",
            "13/75, train_loss: 0.4274\n",
            "14/75, train_loss: 0.4952\n",
            "15/75, train_loss: 0.5597\n",
            "16/75, train_loss: 0.4093\n",
            "17/75, train_loss: 0.4558\n",
            "18/75, train_loss: 0.5159\n",
            "19/75, train_loss: 0.4336\n",
            "20/75, train_loss: 0.4332\n",
            "21/75, train_loss: 0.5073\n",
            "22/75, train_loss: 0.5327\n",
            "23/75, train_loss: 0.5721\n",
            "24/75, train_loss: 0.4049\n",
            "25/75, train_loss: 0.5505\n",
            "26/75, train_loss: 0.4365\n",
            "27/75, train_loss: 0.4321\n",
            "28/75, train_loss: 0.4094\n",
            "29/75, train_loss: 0.5086\n",
            "30/75, train_loss: 0.4982\n",
            "31/75, train_loss: 0.4802\n",
            "32/75, train_loss: 0.4896\n",
            "33/75, train_loss: 0.5944\n",
            "34/75, train_loss: 0.3899\n",
            "35/75, train_loss: 0.4561\n",
            "36/75, train_loss: 0.5901\n",
            "37/75, train_loss: 0.4001\n",
            "38/75, train_loss: 0.5214\n",
            "39/75, train_loss: 0.5356\n",
            "40/75, train_loss: 0.4161\n",
            "41/75, train_loss: 0.5068\n",
            "42/75, train_loss: 0.4894\n",
            "43/75, train_loss: 0.3484\n",
            "44/75, train_loss: 0.5317\n",
            "45/75, train_loss: 0.5373\n",
            "46/75, train_loss: 0.4618\n",
            "47/75, train_loss: 0.4067\n",
            "48/75, train_loss: 0.4387\n",
            "49/75, train_loss: 0.4600\n",
            "50/75, train_loss: 0.5640\n",
            "51/75, train_loss: 0.5453\n",
            "52/75, train_loss: 0.4068\n",
            "53/75, train_loss: 0.4187\n",
            "54/75, train_loss: 0.5402\n",
            "55/75, train_loss: 0.3045\n",
            "56/75, train_loss: 0.4766\n",
            "57/75, train_loss: 0.4832\n",
            "58/75, train_loss: 0.4278\n",
            "59/75, train_loss: 0.3339\n",
            "60/75, train_loss: 0.5296\n",
            "61/75, train_loss: 0.5970\n",
            "62/75, train_loss: 0.4251\n",
            "63/75, train_loss: 0.4949\n",
            "64/75, train_loss: 0.4584\n",
            "65/75, train_loss: 0.2469\n",
            "66/75, train_loss: 0.3804\n",
            "67/75, train_loss: 0.4688\n",
            "68/75, train_loss: 0.4432\n",
            "69/75, train_loss: 0.4524\n",
            "70/75, train_loss: 0.6048\n",
            "71/75, train_loss: 0.5157\n",
            "72/75, train_loss: 0.4830\n",
            "73/75, train_loss: 0.4367\n",
            "74/75, train_loss: 0.5174\n",
            "75/75, train_loss: 0.5584\n",
            "epoch 90 average loss: 0.4679\n",
            "current epoch: 90 current mean dice: 0.7957\n",
            "best mean dice: 0.8002 at epoch: 80\n",
            "----------\n",
            "epoch 91/300\n",
            "1/75, train_loss: 0.4721\n",
            "2/75, train_loss: 0.4375\n",
            "3/75, train_loss: 0.4618\n",
            "4/75, train_loss: 0.5017\n",
            "5/75, train_loss: 0.4741\n",
            "6/75, train_loss: 0.4581\n",
            "7/75, train_loss: 0.4089\n",
            "8/75, train_loss: 0.4365\n",
            "9/75, train_loss: 0.3770\n",
            "10/75, train_loss: 0.4071\n",
            "11/75, train_loss: 0.4089\n",
            "12/75, train_loss: 0.4780\n",
            "13/75, train_loss: 0.5033\n",
            "14/75, train_loss: 0.3904\n",
            "15/75, train_loss: 0.5648\n",
            "16/75, train_loss: 0.4084\n",
            "17/75, train_loss: 0.4885\n",
            "18/75, train_loss: 0.4511\n",
            "19/75, train_loss: 0.4070\n",
            "20/75, train_loss: 0.4779\n",
            "21/75, train_loss: 0.4311\n",
            "22/75, train_loss: 0.4380\n",
            "23/75, train_loss: 0.4881\n",
            "24/75, train_loss: 0.4498\n",
            "25/75, train_loss: 0.4378\n",
            "26/75, train_loss: 0.5054\n",
            "27/75, train_loss: 0.4136\n",
            "28/75, train_loss: 0.4544\n",
            "29/75, train_loss: 0.4180\n",
            "30/75, train_loss: 0.4814\n",
            "31/75, train_loss: 0.3869\n",
            "32/75, train_loss: 0.5279\n",
            "33/75, train_loss: 0.5666\n",
            "34/75, train_loss: 0.4200\n",
            "35/75, train_loss: 0.4772\n",
            "36/75, train_loss: 0.5765\n",
            "37/75, train_loss: 0.5438\n",
            "38/75, train_loss: 0.5238\n",
            "39/75, train_loss: 0.4424\n",
            "40/75, train_loss: 0.3797\n",
            "41/75, train_loss: 0.4413\n",
            "42/75, train_loss: 0.3149\n",
            "43/75, train_loss: 0.4180\n",
            "44/75, train_loss: 0.4780\n",
            "45/75, train_loss: 0.4204\n",
            "46/75, train_loss: 0.3520\n",
            "47/75, train_loss: 0.4431\n",
            "48/75, train_loss: 0.5582\n",
            "49/75, train_loss: 0.4833\n",
            "50/75, train_loss: 0.4540\n",
            "51/75, train_loss: 0.5696\n",
            "52/75, train_loss: 0.4050\n",
            "53/75, train_loss: 0.3882\n",
            "54/75, train_loss: 0.5050\n",
            "55/75, train_loss: 0.4029\n",
            "56/75, train_loss: 0.3719\n",
            "57/75, train_loss: 0.4902\n",
            "58/75, train_loss: 0.3663\n",
            "59/75, train_loss: 0.5567\n",
            "60/75, train_loss: 0.5390\n",
            "61/75, train_loss: 0.3929\n",
            "62/75, train_loss: 0.3818\n",
            "63/75, train_loss: 0.5470\n",
            "64/75, train_loss: 0.5245\n",
            "65/75, train_loss: 0.4765\n",
            "66/75, train_loss: 0.4330\n",
            "67/75, train_loss: 0.3709\n",
            "68/75, train_loss: 0.4277\n",
            "69/75, train_loss: 0.5405\n",
            "70/75, train_loss: 0.4132\n",
            "71/75, train_loss: 0.4250\n",
            "72/75, train_loss: 0.5683\n",
            "73/75, train_loss: 0.4892\n",
            "74/75, train_loss: 0.5147\n",
            "75/75, train_loss: 0.5121\n",
            "epoch 91 average loss: 0.4580\n",
            "saved new best metric model\n",
            "current epoch: 91 current mean dice: 0.8300\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 92/300\n",
            "1/75, train_loss: 0.4201\n",
            "2/75, train_loss: 0.4109\n",
            "3/75, train_loss: 0.3480\n",
            "4/75, train_loss: 0.4431\n",
            "5/75, train_loss: 0.5204\n",
            "6/75, train_loss: 0.3114\n",
            "7/75, train_loss: 0.3842\n",
            "8/75, train_loss: 0.4642\n",
            "9/75, train_loss: 0.4227\n",
            "10/75, train_loss: 0.3848\n",
            "11/75, train_loss: 0.3775\n",
            "12/75, train_loss: 0.3778\n",
            "13/75, train_loss: 0.5208\n",
            "14/75, train_loss: 0.3169\n",
            "15/75, train_loss: 0.4631\n",
            "16/75, train_loss: 0.3678\n",
            "17/75, train_loss: 0.4942\n",
            "18/75, train_loss: 0.4596\n",
            "19/75, train_loss: 0.4435\n",
            "20/75, train_loss: 0.4613\n",
            "21/75, train_loss: 0.5097\n",
            "22/75, train_loss: 0.5066\n",
            "23/75, train_loss: 0.6151\n",
            "24/75, train_loss: 0.4629\n",
            "25/75, train_loss: 0.5574\n",
            "26/75, train_loss: 0.4328\n",
            "27/75, train_loss: 0.4405\n",
            "28/75, train_loss: 0.4097\n",
            "29/75, train_loss: 0.4410\n",
            "30/75, train_loss: 0.5117\n",
            "31/75, train_loss: 0.4400\n",
            "32/75, train_loss: 0.5632\n",
            "33/75, train_loss: 0.5383\n",
            "34/75, train_loss: 0.3622\n",
            "35/75, train_loss: 0.4225\n",
            "36/75, train_loss: 0.5226\n",
            "37/75, train_loss: 0.5045\n",
            "38/75, train_loss: 0.4393\n",
            "39/75, train_loss: 0.4929\n",
            "40/75, train_loss: 0.4860\n",
            "41/75, train_loss: 0.3806\n",
            "42/75, train_loss: 0.4653\n",
            "43/75, train_loss: 0.3606\n",
            "44/75, train_loss: 0.4819\n",
            "45/75, train_loss: 0.4669\n",
            "46/75, train_loss: 0.5328\n",
            "47/75, train_loss: 0.4195\n",
            "48/75, train_loss: 0.5134\n",
            "49/75, train_loss: 0.4891\n",
            "50/75, train_loss: 0.4170\n",
            "51/75, train_loss: 0.5785\n",
            "52/75, train_loss: 0.6280\n",
            "53/75, train_loss: 0.5447\n",
            "54/75, train_loss: 0.3520\n",
            "55/75, train_loss: 0.4742\n",
            "56/75, train_loss: 0.3347\n",
            "57/75, train_loss: 0.6264\n",
            "58/75, train_loss: 0.5026\n",
            "59/75, train_loss: 0.3802\n",
            "60/75, train_loss: 0.4791\n",
            "61/75, train_loss: 0.4327\n",
            "62/75, train_loss: 0.4564\n",
            "63/75, train_loss: 0.5042\n",
            "64/75, train_loss: 0.4335\n",
            "65/75, train_loss: 0.3781\n",
            "66/75, train_loss: 0.4470\n",
            "67/75, train_loss: 0.4067\n",
            "68/75, train_loss: 0.3755\n",
            "69/75, train_loss: 0.4611\n",
            "70/75, train_loss: 0.4366\n",
            "71/75, train_loss: 0.5505\n",
            "72/75, train_loss: 0.4561\n",
            "73/75, train_loss: 0.5135\n",
            "74/75, train_loss: 0.4015\n",
            "75/75, train_loss: 0.5317\n",
            "epoch 92 average loss: 0.4569\n",
            "current epoch: 92 current mean dice: 0.7545\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 93/300\n",
            "1/75, train_loss: 0.4292\n",
            "2/75, train_loss: 0.5359\n",
            "3/75, train_loss: 0.4622\n",
            "4/75, train_loss: 0.4036\n",
            "5/75, train_loss: 0.4298\n",
            "6/75, train_loss: 0.5351\n",
            "7/75, train_loss: 0.4494\n",
            "8/75, train_loss: 0.3383\n",
            "9/75, train_loss: 0.4328\n",
            "10/75, train_loss: 0.3472\n",
            "11/75, train_loss: 0.5093\n",
            "12/75, train_loss: 0.4271\n",
            "13/75, train_loss: 0.4212\n",
            "14/75, train_loss: 0.4539\n",
            "15/75, train_loss: 0.4836\n",
            "16/75, train_loss: 0.4035\n",
            "17/75, train_loss: 0.5333\n",
            "18/75, train_loss: 0.4900\n",
            "19/75, train_loss: 0.5073\n",
            "20/75, train_loss: 0.3500\n",
            "21/75, train_loss: 0.4982\n",
            "22/75, train_loss: 0.5354\n",
            "23/75, train_loss: 0.3979\n",
            "24/75, train_loss: 0.3052\n",
            "25/75, train_loss: 0.4165\n",
            "26/75, train_loss: 0.3524\n",
            "27/75, train_loss: 0.5737\n",
            "28/75, train_loss: 0.5032\n",
            "29/75, train_loss: 0.4624\n",
            "30/75, train_loss: 0.4925\n",
            "31/75, train_loss: 0.5226\n",
            "32/75, train_loss: 0.4660\n",
            "33/75, train_loss: 0.5348\n",
            "34/75, train_loss: 0.5596\n",
            "35/75, train_loss: 0.5666\n",
            "36/75, train_loss: 0.4854\n",
            "37/75, train_loss: 0.5195\n",
            "38/75, train_loss: 0.4765\n",
            "39/75, train_loss: 0.4539\n",
            "40/75, train_loss: 0.4466\n",
            "41/75, train_loss: 0.5117\n",
            "42/75, train_loss: 0.4600\n",
            "43/75, train_loss: 0.5508\n",
            "44/75, train_loss: 0.5327\n",
            "45/75, train_loss: 0.4714\n",
            "46/75, train_loss: 0.4844\n",
            "47/75, train_loss: 0.5896\n",
            "48/75, train_loss: 0.4875\n",
            "49/75, train_loss: 0.4417\n",
            "50/75, train_loss: 0.5426\n",
            "51/75, train_loss: 0.5197\n",
            "52/75, train_loss: 0.4193\n",
            "53/75, train_loss: 0.5237\n",
            "54/75, train_loss: 0.4999\n",
            "55/75, train_loss: 0.4747\n",
            "56/75, train_loss: 0.4305\n",
            "57/75, train_loss: 0.4757\n",
            "58/75, train_loss: 0.4706\n",
            "59/75, train_loss: 0.4285\n",
            "60/75, train_loss: 0.4206\n",
            "61/75, train_loss: 0.4873\n",
            "62/75, train_loss: 0.3953\n",
            "63/75, train_loss: 0.5341\n",
            "64/75, train_loss: 0.3539\n",
            "65/75, train_loss: 0.4095\n",
            "66/75, train_loss: 0.4166\n",
            "67/75, train_loss: 0.3629\n",
            "68/75, train_loss: 0.3538\n",
            "69/75, train_loss: 0.5654\n",
            "70/75, train_loss: 0.4261\n",
            "71/75, train_loss: 0.4867\n",
            "72/75, train_loss: 0.5315\n",
            "73/75, train_loss: 0.5390\n",
            "74/75, train_loss: 0.4449\n",
            "75/75, train_loss: 0.5235\n",
            "epoch 93 average loss: 0.4677\n",
            "current epoch: 93 current mean dice: 0.7730\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 94/300\n",
            "1/75, train_loss: 0.5634\n",
            "2/75, train_loss: 0.4727\n",
            "3/75, train_loss: 0.4255\n",
            "4/75, train_loss: 0.3373\n",
            "5/75, train_loss: 0.4532\n",
            "6/75, train_loss: 0.4664\n",
            "7/75, train_loss: 0.3476\n",
            "8/75, train_loss: 0.3760\n",
            "9/75, train_loss: 0.4207\n",
            "10/75, train_loss: 0.4406\n",
            "11/75, train_loss: 0.4236\n",
            "12/75, train_loss: 0.3991\n",
            "13/75, train_loss: 0.3678\n",
            "14/75, train_loss: 0.4594\n",
            "15/75, train_loss: 0.4812\n",
            "16/75, train_loss: 0.4153\n",
            "17/75, train_loss: 0.3677\n",
            "18/75, train_loss: 0.3900\n",
            "19/75, train_loss: 0.3827\n",
            "20/75, train_loss: 0.5150\n",
            "21/75, train_loss: 0.4219\n",
            "22/75, train_loss: 0.4587\n",
            "23/75, train_loss: 0.5571\n",
            "24/75, train_loss: 0.4538\n",
            "25/75, train_loss: 0.5244\n",
            "26/75, train_loss: 0.4056\n",
            "27/75, train_loss: 0.5323\n",
            "28/75, train_loss: 0.4558\n",
            "29/75, train_loss: 0.5273\n",
            "30/75, train_loss: 0.4941\n",
            "31/75, train_loss: 0.5295\n",
            "32/75, train_loss: 0.4324\n",
            "33/75, train_loss: 0.5541\n",
            "34/75, train_loss: 0.3950\n",
            "35/75, train_loss: 0.4987\n",
            "36/75, train_loss: 0.2482\n",
            "37/75, train_loss: 0.4893\n",
            "38/75, train_loss: 0.5032\n",
            "39/75, train_loss: 0.4525\n",
            "40/75, train_loss: 0.4415\n",
            "41/75, train_loss: 0.4170\n",
            "42/75, train_loss: 0.4683\n",
            "43/75, train_loss: 0.5340\n",
            "44/75, train_loss: 0.3908\n",
            "45/75, train_loss: 0.4333\n",
            "46/75, train_loss: 0.6178\n",
            "47/75, train_loss: 0.5056\n",
            "48/75, train_loss: 0.3321\n",
            "49/75, train_loss: 0.3516\n",
            "50/75, train_loss: 0.5036\n",
            "51/75, train_loss: 0.5463\n",
            "52/75, train_loss: 0.5637\n",
            "53/75, train_loss: 0.4285\n",
            "54/75, train_loss: 0.4597\n",
            "55/75, train_loss: 0.5690\n",
            "56/75, train_loss: 0.5182\n",
            "57/75, train_loss: 0.4915\n",
            "58/75, train_loss: 0.3966\n",
            "59/75, train_loss: 0.4142\n",
            "60/75, train_loss: 0.5962\n",
            "61/75, train_loss: 0.4248\n",
            "62/75, train_loss: 0.4204\n",
            "63/75, train_loss: 0.3759\n",
            "64/75, train_loss: 0.4522\n",
            "65/75, train_loss: 0.4802\n",
            "66/75, train_loss: 0.5218\n",
            "67/75, train_loss: 0.4495\n",
            "68/75, train_loss: 0.4735\n",
            "69/75, train_loss: 0.6369\n",
            "70/75, train_loss: 0.4433\n",
            "71/75, train_loss: 0.4134\n",
            "72/75, train_loss: 0.4563\n",
            "73/75, train_loss: 0.4450\n",
            "74/75, train_loss: 0.5347\n",
            "75/75, train_loss: 0.5068\n",
            "epoch 94 average loss: 0.4594\n",
            "current epoch: 94 current mean dice: 0.7859\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 95/300\n",
            "1/75, train_loss: 0.5339\n",
            "2/75, train_loss: 0.4657\n",
            "3/75, train_loss: 0.4673\n",
            "4/75, train_loss: 0.3767\n",
            "5/75, train_loss: 0.4084\n",
            "6/75, train_loss: 0.4502\n",
            "7/75, train_loss: 0.4050\n",
            "8/75, train_loss: 0.3636\n",
            "9/75, train_loss: 0.4992\n",
            "10/75, train_loss: 0.4092\n",
            "11/75, train_loss: 0.4233\n",
            "12/75, train_loss: 0.4289\n",
            "13/75, train_loss: 0.3695\n",
            "14/75, train_loss: 0.4158\n",
            "15/75, train_loss: 0.4153\n",
            "16/75, train_loss: 0.3641\n",
            "17/75, train_loss: 0.4276\n",
            "18/75, train_loss: 0.4646\n",
            "19/75, train_loss: 0.4143\n",
            "20/75, train_loss: 0.4712\n",
            "21/75, train_loss: 0.5460\n",
            "22/75, train_loss: 0.4957\n",
            "23/75, train_loss: 0.5677\n",
            "24/75, train_loss: 0.4435\n",
            "25/75, train_loss: 0.4538\n",
            "26/75, train_loss: 0.5205\n",
            "27/75, train_loss: 0.4488\n",
            "28/75, train_loss: 0.5346\n",
            "29/75, train_loss: 0.4862\n",
            "30/75, train_loss: 0.3648\n",
            "31/75, train_loss: 0.4149\n",
            "32/75, train_loss: 0.4854\n",
            "33/75, train_loss: 0.4927\n",
            "34/75, train_loss: 0.6105\n",
            "35/75, train_loss: 0.5000\n",
            "36/75, train_loss: 0.5005\n",
            "37/75, train_loss: 0.5028\n",
            "38/75, train_loss: 0.4031\n",
            "39/75, train_loss: 0.4731\n",
            "40/75, train_loss: 0.4527\n",
            "41/75, train_loss: 0.5859\n",
            "42/75, train_loss: 0.5144\n",
            "43/75, train_loss: 0.5557\n",
            "44/75, train_loss: 0.4865\n",
            "45/75, train_loss: 0.4632\n",
            "46/75, train_loss: 0.4862\n",
            "47/75, train_loss: 0.4397\n",
            "48/75, train_loss: 0.4428\n",
            "49/75, train_loss: 0.4541\n",
            "50/75, train_loss: 0.4207\n",
            "51/75, train_loss: 0.4383\n",
            "52/75, train_loss: 0.4933\n",
            "53/75, train_loss: 0.5935\n",
            "54/75, train_loss: 0.5298\n",
            "55/75, train_loss: 0.4850\n",
            "56/75, train_loss: 0.3505\n",
            "57/75, train_loss: 0.4109\n",
            "58/75, train_loss: 0.3608\n",
            "59/75, train_loss: 0.4426\n",
            "60/75, train_loss: 0.4525\n",
            "61/75, train_loss: 0.4269\n",
            "62/75, train_loss: 0.5977\n",
            "63/75, train_loss: 0.3752\n",
            "64/75, train_loss: 0.4842\n",
            "65/75, train_loss: 0.4739\n",
            "66/75, train_loss: 0.4977\n",
            "67/75, train_loss: 0.4500\n",
            "68/75, train_loss: 0.4886\n",
            "69/75, train_loss: 0.5917\n",
            "70/75, train_loss: 0.3651\n",
            "71/75, train_loss: 0.5586\n",
            "72/75, train_loss: 0.4164\n",
            "73/75, train_loss: 0.4246\n",
            "74/75, train_loss: 0.6347\n",
            "75/75, train_loss: 0.5261\n",
            "epoch 95 average loss: 0.4665\n",
            "current epoch: 95 current mean dice: 0.7731\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 96/300\n",
            "1/75, train_loss: 0.5208\n",
            "2/75, train_loss: 0.5250\n",
            "3/75, train_loss: 0.3956\n",
            "4/75, train_loss: 0.4722\n",
            "5/75, train_loss: 0.4340\n",
            "6/75, train_loss: 0.5210\n",
            "7/75, train_loss: 0.5252\n",
            "8/75, train_loss: 0.4643\n",
            "9/75, train_loss: 0.4358\n",
            "10/75, train_loss: 0.3656\n",
            "11/75, train_loss: 0.4774\n",
            "12/75, train_loss: 0.3060\n",
            "13/75, train_loss: 0.4643\n",
            "14/75, train_loss: 0.3743\n",
            "15/75, train_loss: 0.3807\n",
            "16/75, train_loss: 0.4536\n",
            "17/75, train_loss: 0.3997\n",
            "18/75, train_loss: 0.4582\n",
            "19/75, train_loss: 0.4148\n",
            "20/75, train_loss: 0.4068\n",
            "21/75, train_loss: 0.4542\n",
            "22/75, train_loss: 0.4889\n",
            "23/75, train_loss: 0.5426\n",
            "24/75, train_loss: 0.5746\n",
            "25/75, train_loss: 0.4605\n",
            "26/75, train_loss: 0.5026\n",
            "27/75, train_loss: 0.3582\n",
            "28/75, train_loss: 0.4395\n",
            "29/75, train_loss: 0.4760\n",
            "30/75, train_loss: 0.5105\n",
            "31/75, train_loss: 0.5586\n",
            "32/75, train_loss: 0.4064\n",
            "33/75, train_loss: 0.5710\n",
            "34/75, train_loss: 0.5345\n",
            "35/75, train_loss: 0.5282\n",
            "36/75, train_loss: 0.4474\n",
            "37/75, train_loss: 0.4787\n",
            "38/75, train_loss: 0.4928\n",
            "39/75, train_loss: 0.5820\n",
            "40/75, train_loss: 0.4100\n",
            "41/75, train_loss: 0.4700\n",
            "42/75, train_loss: 0.4965\n",
            "43/75, train_loss: 0.4077\n",
            "44/75, train_loss: 0.4454\n",
            "45/75, train_loss: 0.5594\n",
            "46/75, train_loss: 0.4107\n",
            "47/75, train_loss: 0.3357\n",
            "48/75, train_loss: 0.4731\n",
            "49/75, train_loss: 0.4907\n",
            "50/75, train_loss: 0.4225\n",
            "51/75, train_loss: 0.3614\n",
            "52/75, train_loss: 0.4565\n",
            "53/75, train_loss: 0.4317\n",
            "54/75, train_loss: 0.3637\n",
            "55/75, train_loss: 0.4383\n",
            "56/75, train_loss: 0.3670\n",
            "57/75, train_loss: 0.4633\n",
            "58/75, train_loss: 0.4823\n",
            "59/75, train_loss: 0.6516\n",
            "60/75, train_loss: 0.4651\n",
            "61/75, train_loss: 0.5218\n",
            "62/75, train_loss: 0.4006\n",
            "63/75, train_loss: 0.5850\n",
            "64/75, train_loss: 0.4270\n",
            "65/75, train_loss: 0.4715\n",
            "66/75, train_loss: 0.5222\n",
            "67/75, train_loss: 0.5399\n",
            "68/75, train_loss: 0.4233\n",
            "69/75, train_loss: 0.5454\n",
            "70/75, train_loss: 0.4442\n",
            "71/75, train_loss: 0.4115\n",
            "72/75, train_loss: 0.4471\n",
            "73/75, train_loss: 0.5773\n",
            "74/75, train_loss: 0.4973\n",
            "75/75, train_loss: 0.3658\n",
            "epoch 96 average loss: 0.4638\n",
            "current epoch: 96 current mean dice: 0.7854\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 97/300\n",
            "1/75, train_loss: 0.5306\n",
            "2/75, train_loss: 0.4242\n",
            "3/75, train_loss: 0.4649\n",
            "4/75, train_loss: 0.4741\n",
            "5/75, train_loss: 0.4772\n",
            "6/75, train_loss: 0.4267\n",
            "7/75, train_loss: 0.4663\n",
            "8/75, train_loss: 0.4632\n",
            "9/75, train_loss: 0.5019\n",
            "10/75, train_loss: 0.4366\n",
            "11/75, train_loss: 0.3755\n",
            "12/75, train_loss: 0.4906\n",
            "13/75, train_loss: 0.5409\n",
            "14/75, train_loss: 0.4418\n",
            "15/75, train_loss: 0.4261\n",
            "16/75, train_loss: 0.4490\n",
            "17/75, train_loss: 0.4677\n",
            "18/75, train_loss: 0.3224\n",
            "19/75, train_loss: 0.3656\n",
            "20/75, train_loss: 0.5043\n",
            "21/75, train_loss: 0.4225\n",
            "22/75, train_loss: 0.4754\n",
            "23/75, train_loss: 0.3046\n",
            "24/75, train_loss: 0.4636\n",
            "25/75, train_loss: 0.4895\n",
            "26/75, train_loss: 0.3900\n",
            "27/75, train_loss: 0.4736\n",
            "28/75, train_loss: 0.5790\n",
            "29/75, train_loss: 0.5096\n",
            "30/75, train_loss: 0.4528\n",
            "31/75, train_loss: 0.5349\n",
            "32/75, train_loss: 0.4959\n",
            "33/75, train_loss: 0.5866\n",
            "34/75, train_loss: 0.4471\n",
            "35/75, train_loss: 0.3087\n",
            "36/75, train_loss: 0.5232\n",
            "37/75, train_loss: 0.3309\n",
            "38/75, train_loss: 0.5025\n",
            "39/75, train_loss: 0.4901\n",
            "40/75, train_loss: 0.2571\n",
            "41/75, train_loss: 0.3607\n",
            "42/75, train_loss: 0.4592\n",
            "43/75, train_loss: 0.6094\n",
            "44/75, train_loss: 0.4252\n",
            "45/75, train_loss: 0.4312\n",
            "46/75, train_loss: 0.6041\n",
            "47/75, train_loss: 0.4789\n",
            "48/75, train_loss: 0.3749\n",
            "49/75, train_loss: 0.5583\n",
            "50/75, train_loss: 0.5274\n",
            "51/75, train_loss: 0.5105\n",
            "52/75, train_loss: 0.5069\n",
            "53/75, train_loss: 0.3860\n",
            "54/75, train_loss: 0.4100\n",
            "55/75, train_loss: 0.4783\n",
            "56/75, train_loss: 0.4626\n",
            "57/75, train_loss: 0.4414\n",
            "58/75, train_loss: 0.3358\n",
            "59/75, train_loss: 0.6273\n",
            "60/75, train_loss: 0.4335\n",
            "61/75, train_loss: 0.5540\n",
            "62/75, train_loss: 0.4120\n",
            "63/75, train_loss: 0.4370\n",
            "64/75, train_loss: 0.5035\n",
            "65/75, train_loss: 0.4855\n",
            "66/75, train_loss: 0.3924\n",
            "67/75, train_loss: 0.5174\n",
            "68/75, train_loss: 0.4466\n",
            "69/75, train_loss: 0.4681\n",
            "70/75, train_loss: 0.4719\n",
            "71/75, train_loss: 0.4001\n",
            "72/75, train_loss: 0.3873\n",
            "73/75, train_loss: 0.4800\n",
            "74/75, train_loss: 0.6045\n",
            "75/75, train_loss: 0.4693\n",
            "epoch 97 average loss: 0.4605\n",
            "current epoch: 97 current mean dice: 0.7600\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 98/300\n",
            "1/75, train_loss: 0.3844\n",
            "2/75, train_loss: 0.4363\n",
            "3/75, train_loss: 0.4473\n",
            "4/75, train_loss: 0.4715\n",
            "5/75, train_loss: 0.4091\n",
            "6/75, train_loss: 0.5000\n",
            "7/75, train_loss: 0.4074\n",
            "8/75, train_loss: 0.4839\n",
            "9/75, train_loss: 0.4242\n",
            "10/75, train_loss: 0.3863\n",
            "11/75, train_loss: 0.4716\n",
            "12/75, train_loss: 0.4601\n",
            "13/75, train_loss: 0.4364\n",
            "14/75, train_loss: 0.5412\n",
            "15/75, train_loss: 0.4387\n",
            "16/75, train_loss: 0.3987\n",
            "17/75, train_loss: 0.4603\n",
            "18/75, train_loss: 0.3900\n",
            "19/75, train_loss: 0.4397\n",
            "20/75, train_loss: 0.4859\n",
            "21/75, train_loss: 0.5563\n",
            "22/75, train_loss: 0.5483\n",
            "23/75, train_loss: 0.4442\n",
            "24/75, train_loss: 0.4569\n",
            "25/75, train_loss: 0.4256\n",
            "26/75, train_loss: 0.4225\n",
            "27/75, train_loss: 0.3753\n",
            "28/75, train_loss: 0.3855\n",
            "29/75, train_loss: 0.4399\n",
            "30/75, train_loss: 0.4567\n",
            "31/75, train_loss: 0.3995\n",
            "32/75, train_loss: 0.4029\n",
            "33/75, train_loss: 0.4868\n",
            "34/75, train_loss: 0.4802\n",
            "35/75, train_loss: 0.5845\n",
            "36/75, train_loss: 0.5032\n",
            "37/75, train_loss: 0.4254\n",
            "38/75, train_loss: 0.5167\n",
            "39/75, train_loss: 0.4715\n",
            "40/75, train_loss: 0.4889\n",
            "41/75, train_loss: 0.5433\n",
            "42/75, train_loss: 0.5025\n",
            "43/75, train_loss: 0.4831\n",
            "44/75, train_loss: 0.4723\n",
            "45/75, train_loss: 0.3996\n",
            "46/75, train_loss: 0.4708\n",
            "47/75, train_loss: 0.4694\n",
            "48/75, train_loss: 0.4752\n",
            "49/75, train_loss: 0.4911\n",
            "50/75, train_loss: 0.5007\n",
            "51/75, train_loss: 0.6485\n",
            "52/75, train_loss: 0.5568\n",
            "53/75, train_loss: 0.4286\n",
            "54/75, train_loss: 0.5905\n",
            "55/75, train_loss: 0.3946\n",
            "56/75, train_loss: 0.3166\n",
            "57/75, train_loss: 0.5209\n",
            "58/75, train_loss: 0.3854\n",
            "59/75, train_loss: 0.4578\n",
            "60/75, train_loss: 0.4010\n",
            "61/75, train_loss: 0.4093\n",
            "62/75, train_loss: 0.4845\n",
            "63/75, train_loss: 0.3466\n",
            "64/75, train_loss: 0.3921\n",
            "65/75, train_loss: 0.5091\n",
            "66/75, train_loss: 0.3439\n",
            "67/75, train_loss: 0.4967\n",
            "68/75, train_loss: 0.3626\n",
            "69/75, train_loss: 0.4480\n",
            "70/75, train_loss: 0.5075\n",
            "71/75, train_loss: 0.6037\n",
            "72/75, train_loss: 0.5252\n",
            "73/75, train_loss: 0.4748\n",
            "74/75, train_loss: 0.4197\n",
            "75/75, train_loss: 0.5395\n",
            "epoch 98 average loss: 0.4602\n",
            "current epoch: 98 current mean dice: 0.7535\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 99/300\n",
            "1/75, train_loss: 0.4546\n",
            "2/75, train_loss: 0.5442\n",
            "3/75, train_loss: 0.3478\n",
            "4/75, train_loss: 0.5009\n",
            "5/75, train_loss: 0.4258\n",
            "6/75, train_loss: 0.4997\n",
            "7/75, train_loss: 0.5831\n",
            "8/75, train_loss: 0.3888\n",
            "9/75, train_loss: 0.5912\n",
            "10/75, train_loss: 0.4317\n",
            "11/75, train_loss: 0.4984\n",
            "12/75, train_loss: 0.4069\n",
            "13/75, train_loss: 0.5486\n",
            "14/75, train_loss: 0.5195\n",
            "15/75, train_loss: 0.5360\n",
            "16/75, train_loss: 0.4597\n",
            "17/75, train_loss: 0.4631\n",
            "18/75, train_loss: 0.4786\n",
            "19/75, train_loss: 0.3778\n",
            "20/75, train_loss: 0.3922\n",
            "21/75, train_loss: 0.4792\n",
            "22/75, train_loss: 0.4856\n",
            "23/75, train_loss: 0.3899\n",
            "24/75, train_loss: 0.4802\n",
            "25/75, train_loss: 0.3512\n",
            "26/75, train_loss: 0.4862\n",
            "27/75, train_loss: 0.2990\n",
            "28/75, train_loss: 0.3417\n",
            "29/75, train_loss: 0.4731\n",
            "30/75, train_loss: 0.3796\n",
            "31/75, train_loss: 0.4253\n",
            "32/75, train_loss: 0.4535\n",
            "33/75, train_loss: 0.5295\n",
            "34/75, train_loss: 0.4387\n",
            "35/75, train_loss: 0.5229\n",
            "36/75, train_loss: 0.5153\n",
            "37/75, train_loss: 0.4712\n",
            "38/75, train_loss: 0.4837\n",
            "39/75, train_loss: 0.5357\n",
            "40/75, train_loss: 0.4751\n",
            "41/75, train_loss: 0.4378\n",
            "42/75, train_loss: 0.4302\n",
            "43/75, train_loss: 0.5121\n",
            "44/75, train_loss: 0.4593\n",
            "45/75, train_loss: 0.4864\n",
            "46/75, train_loss: 0.3378\n",
            "47/75, train_loss: 0.3755\n",
            "48/75, train_loss: 0.4584\n",
            "49/75, train_loss: 0.4826\n",
            "50/75, train_loss: 0.3444\n",
            "51/75, train_loss: 0.4382\n",
            "52/75, train_loss: 0.3736\n",
            "53/75, train_loss: 0.3473\n",
            "54/75, train_loss: 0.5569\n",
            "55/75, train_loss: 0.4314\n",
            "56/75, train_loss: 0.4316\n",
            "57/75, train_loss: 0.4381\n",
            "58/75, train_loss: 0.4251\n",
            "59/75, train_loss: 0.3899\n",
            "60/75, train_loss: 0.4900\n",
            "61/75, train_loss: 0.5270\n",
            "62/75, train_loss: 0.4731\n",
            "63/75, train_loss: 0.4874\n",
            "64/75, train_loss: 0.2961\n",
            "65/75, train_loss: 0.4768\n",
            "66/75, train_loss: 0.4378\n",
            "67/75, train_loss: 0.4848\n",
            "68/75, train_loss: 0.4755\n",
            "69/75, train_loss: 0.5631\n",
            "70/75, train_loss: 0.4877\n",
            "71/75, train_loss: 0.3280\n",
            "72/75, train_loss: 0.4023\n",
            "73/75, train_loss: 0.5499\n",
            "74/75, train_loss: 0.5650\n",
            "75/75, train_loss: 0.3372\n",
            "epoch 99 average loss: 0.4534\n",
            "current epoch: 99 current mean dice: 0.8286\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 100/300\n",
            "1/75, train_loss: 0.4568\n",
            "2/75, train_loss: 0.4918\n",
            "3/75, train_loss: 0.5014\n",
            "4/75, train_loss: 0.4694\n",
            "5/75, train_loss: 0.3965\n",
            "6/75, train_loss: 0.5034\n",
            "7/75, train_loss: 0.4720\n",
            "8/75, train_loss: 0.3768\n",
            "9/75, train_loss: 0.4603\n",
            "10/75, train_loss: 0.4973\n",
            "11/75, train_loss: 0.3981\n",
            "12/75, train_loss: 0.4176\n",
            "13/75, train_loss: 0.3856\n",
            "14/75, train_loss: 0.3454\n",
            "15/75, train_loss: 0.4573\n",
            "16/75, train_loss: 0.4156\n",
            "17/75, train_loss: 0.5180\n",
            "18/75, train_loss: 0.4790\n",
            "19/75, train_loss: 0.4566\n",
            "20/75, train_loss: 0.3890\n",
            "21/75, train_loss: 0.4389\n",
            "22/75, train_loss: 0.4390\n",
            "23/75, train_loss: 0.4482\n",
            "24/75, train_loss: 0.5233\n",
            "25/75, train_loss: 0.4064\n",
            "26/75, train_loss: 0.4769\n",
            "27/75, train_loss: 0.5224\n",
            "28/75, train_loss: 0.5038\n",
            "29/75, train_loss: 0.4406\n",
            "30/75, train_loss: 0.5066\n",
            "31/75, train_loss: 0.4033\n",
            "32/75, train_loss: 0.5374\n",
            "33/75, train_loss: 0.4937\n",
            "34/75, train_loss: 0.3382\n",
            "35/75, train_loss: 0.5049\n",
            "36/75, train_loss: 0.5464\n",
            "37/75, train_loss: 0.4110\n",
            "38/75, train_loss: 0.4974\n",
            "39/75, train_loss: 0.4880\n",
            "40/75, train_loss: 0.4137\n",
            "41/75, train_loss: 0.4110\n",
            "42/75, train_loss: 0.4962\n",
            "43/75, train_loss: 0.4723\n",
            "44/75, train_loss: 0.3984\n",
            "45/75, train_loss: 0.6167\n",
            "46/75, train_loss: 0.5736\n",
            "47/75, train_loss: 0.5718\n",
            "48/75, train_loss: 0.3237\n",
            "49/75, train_loss: 0.4261\n",
            "50/75, train_loss: 0.6097\n",
            "51/75, train_loss: 0.5163\n",
            "52/75, train_loss: 0.5367\n",
            "53/75, train_loss: 0.4047\n",
            "54/75, train_loss: 0.4180\n",
            "55/75, train_loss: 0.4376\n",
            "56/75, train_loss: 0.3803\n",
            "57/75, train_loss: 0.4648\n",
            "58/75, train_loss: 0.4006\n",
            "59/75, train_loss: 0.4236\n",
            "60/75, train_loss: 0.4960\n",
            "61/75, train_loss: 0.3404\n",
            "62/75, train_loss: 0.3912\n",
            "63/75, train_loss: 0.4404\n",
            "64/75, train_loss: 0.4102\n",
            "65/75, train_loss: 0.5352\n",
            "66/75, train_loss: 0.5259\n",
            "67/75, train_loss: 0.3743\n",
            "68/75, train_loss: 0.4170\n",
            "69/75, train_loss: 0.5079\n",
            "70/75, train_loss: 0.3568\n",
            "71/75, train_loss: 0.4765\n",
            "72/75, train_loss: 0.5060\n",
            "73/75, train_loss: 0.4036\n",
            "74/75, train_loss: 0.3240\n",
            "75/75, train_loss: 0.5371\n",
            "epoch 100 average loss: 0.4554\n",
            "current epoch: 100 current mean dice: 0.7637\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 101/300\n",
            "1/75, train_loss: 0.5494\n",
            "2/75, train_loss: 0.2591\n",
            "3/75, train_loss: 0.4698\n",
            "4/75, train_loss: 0.4624\n",
            "5/75, train_loss: 0.5347\n",
            "6/75, train_loss: 0.5957\n",
            "7/75, train_loss: 0.3179\n",
            "8/75, train_loss: 0.3600\n",
            "9/75, train_loss: 0.4562\n",
            "10/75, train_loss: 0.4564\n",
            "11/75, train_loss: 0.3914\n",
            "12/75, train_loss: 0.3776\n",
            "13/75, train_loss: 0.3568\n",
            "14/75, train_loss: 0.4028\n",
            "15/75, train_loss: 0.4337\n",
            "16/75, train_loss: 0.4721\n",
            "17/75, train_loss: 0.5270\n",
            "18/75, train_loss: 0.4262\n",
            "19/75, train_loss: 0.5027\n",
            "20/75, train_loss: 0.3802\n",
            "21/75, train_loss: 0.4537\n",
            "22/75, train_loss: 0.4504\n",
            "23/75, train_loss: 0.3927\n",
            "24/75, train_loss: 0.5122\n",
            "25/75, train_loss: 0.5353\n",
            "26/75, train_loss: 0.4807\n",
            "27/75, train_loss: 0.5104\n",
            "28/75, train_loss: 0.5403\n",
            "29/75, train_loss: 0.4581\n",
            "30/75, train_loss: 0.4686\n",
            "31/75, train_loss: 0.5647\n",
            "32/75, train_loss: 0.4814\n",
            "33/75, train_loss: 0.4643\n",
            "34/75, train_loss: 0.4995\n",
            "35/75, train_loss: 0.3097\n",
            "36/75, train_loss: 0.5235\n",
            "37/75, train_loss: 0.4528\n",
            "38/75, train_loss: 0.4947\n",
            "39/75, train_loss: 0.4285\n",
            "40/75, train_loss: 0.5564\n",
            "41/75, train_loss: 0.4991\n",
            "42/75, train_loss: 0.4849\n",
            "43/75, train_loss: 0.4884\n",
            "44/75, train_loss: 0.4860\n",
            "45/75, train_loss: 0.5375\n",
            "46/75, train_loss: 0.4732\n",
            "47/75, train_loss: 0.3422\n",
            "48/75, train_loss: 0.5131\n",
            "49/75, train_loss: 0.4470\n",
            "50/75, train_loss: 0.3701\n",
            "51/75, train_loss: 0.4228\n",
            "52/75, train_loss: 0.4188\n",
            "53/75, train_loss: 0.5206\n",
            "54/75, train_loss: 0.4257\n",
            "55/75, train_loss: 0.3559\n",
            "56/75, train_loss: 0.4743\n",
            "57/75, train_loss: 0.5489\n",
            "58/75, train_loss: 0.4361\n",
            "59/75, train_loss: 0.4322\n",
            "60/75, train_loss: 0.5018\n",
            "61/75, train_loss: 0.3787\n",
            "62/75, train_loss: 0.4700\n",
            "63/75, train_loss: 0.5163\n",
            "64/75, train_loss: 0.5548\n",
            "65/75, train_loss: 0.3872\n",
            "66/75, train_loss: 0.5338\n",
            "67/75, train_loss: 0.6039\n",
            "68/75, train_loss: 0.3699\n",
            "69/75, train_loss: 0.4862\n",
            "70/75, train_loss: 0.4877\n",
            "71/75, train_loss: 0.5181\n",
            "72/75, train_loss: 0.4066\n",
            "73/75, train_loss: 0.5622\n",
            "74/75, train_loss: 0.4393\n",
            "75/75, train_loss: 0.4634\n",
            "epoch 101 average loss: 0.4622\n",
            "current epoch: 101 current mean dice: 0.7617\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 102/300\n",
            "1/75, train_loss: 0.4297\n",
            "2/75, train_loss: 0.5041\n",
            "3/75, train_loss: 0.5026\n",
            "4/75, train_loss: 0.3675\n",
            "5/75, train_loss: 0.4015\n",
            "6/75, train_loss: 0.4323\n",
            "7/75, train_loss: 0.3262\n",
            "8/75, train_loss: 0.3137\n",
            "9/75, train_loss: 0.3954\n",
            "10/75, train_loss: 0.5301\n",
            "11/75, train_loss: 0.3743\n",
            "12/75, train_loss: 0.4709\n",
            "13/75, train_loss: 0.4354\n",
            "14/75, train_loss: 0.4233\n",
            "15/75, train_loss: 0.4640\n",
            "16/75, train_loss: 0.4470\n",
            "17/75, train_loss: 0.5314\n",
            "18/75, train_loss: 0.2884\n",
            "19/75, train_loss: 0.3955\n",
            "20/75, train_loss: 0.3569\n",
            "21/75, train_loss: 0.3715\n",
            "22/75, train_loss: 0.5779\n",
            "23/75, train_loss: 0.5302\n",
            "24/75, train_loss: 0.3754\n",
            "25/75, train_loss: 0.4250\n",
            "26/75, train_loss: 0.4988\n",
            "27/75, train_loss: 0.4437\n",
            "28/75, train_loss: 0.5224\n",
            "29/75, train_loss: 0.3888\n",
            "30/75, train_loss: 0.4070\n",
            "31/75, train_loss: 0.5340\n",
            "32/75, train_loss: 0.4940\n",
            "33/75, train_loss: 0.4862\n",
            "34/75, train_loss: 0.5261\n",
            "35/75, train_loss: 0.5355\n",
            "36/75, train_loss: 0.5275\n",
            "37/75, train_loss: 0.3753\n",
            "38/75, train_loss: 0.5144\n",
            "39/75, train_loss: 0.5360\n",
            "40/75, train_loss: 0.3924\n",
            "41/75, train_loss: 0.6391\n",
            "42/75, train_loss: 0.5846\n",
            "43/75, train_loss: 0.4483\n",
            "44/75, train_loss: 0.5135\n",
            "45/75, train_loss: 0.4275\n",
            "46/75, train_loss: 0.4404\n",
            "47/75, train_loss: 0.5165\n",
            "48/75, train_loss: 0.4041\n",
            "49/75, train_loss: 0.3993\n",
            "50/75, train_loss: 0.4591\n",
            "51/75, train_loss: 0.4481\n",
            "52/75, train_loss: 0.4874\n",
            "53/75, train_loss: 0.4610\n",
            "54/75, train_loss: 0.4706\n",
            "55/75, train_loss: 0.4453\n",
            "56/75, train_loss: 0.4093\n",
            "57/75, train_loss: 0.4311\n",
            "58/75, train_loss: 0.4715\n",
            "59/75, train_loss: 0.4980\n",
            "60/75, train_loss: 0.5518\n",
            "61/75, train_loss: 0.4525\n",
            "62/75, train_loss: 0.4327\n",
            "63/75, train_loss: 0.4579\n",
            "64/75, train_loss: 0.5660\n",
            "65/75, train_loss: 0.5621\n",
            "66/75, train_loss: 0.4122\n",
            "67/75, train_loss: 0.3638\n",
            "68/75, train_loss: 0.4516\n",
            "69/75, train_loss: 0.4896\n",
            "70/75, train_loss: 0.4975\n",
            "71/75, train_loss: 0.4146\n",
            "72/75, train_loss: 0.3813\n",
            "73/75, train_loss: 0.3166\n",
            "74/75, train_loss: 0.4433\n",
            "75/75, train_loss: 0.3750\n",
            "epoch 102 average loss: 0.4530\n",
            "current epoch: 102 current mean dice: 0.7669\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 103/300\n",
            "1/75, train_loss: 0.4416\n",
            "2/75, train_loss: 0.4517\n",
            "3/75, train_loss: 0.3660\n",
            "4/75, train_loss: 0.5582\n",
            "5/75, train_loss: 0.5241\n",
            "6/75, train_loss: 0.4047\n",
            "7/75, train_loss: 0.4939\n",
            "8/75, train_loss: 0.5034\n",
            "9/75, train_loss: 0.4884\n",
            "10/75, train_loss: 0.4677\n",
            "11/75, train_loss: 0.4433\n",
            "12/75, train_loss: 0.4380\n",
            "13/75, train_loss: 0.3300\n",
            "14/75, train_loss: 0.4550\n",
            "15/75, train_loss: 0.4183\n",
            "16/75, train_loss: 0.4411\n",
            "17/75, train_loss: 0.5173\n",
            "18/75, train_loss: 0.3908\n",
            "19/75, train_loss: 0.4237\n",
            "20/75, train_loss: 0.4382\n",
            "21/75, train_loss: 0.5763\n",
            "22/75, train_loss: 0.6496\n",
            "23/75, train_loss: 0.4306\n",
            "24/75, train_loss: 0.5277\n",
            "25/75, train_loss: 0.3933\n",
            "26/75, train_loss: 0.5513\n",
            "27/75, train_loss: 0.4485\n",
            "28/75, train_loss: 0.3531\n",
            "29/75, train_loss: 0.3421\n",
            "30/75, train_loss: 0.4454\n",
            "31/75, train_loss: 0.5186\n",
            "32/75, train_loss: 0.5705\n",
            "33/75, train_loss: 0.4561\n",
            "34/75, train_loss: 0.4446\n",
            "35/75, train_loss: 0.6194\n",
            "36/75, train_loss: 0.5251\n",
            "37/75, train_loss: 0.3747\n",
            "38/75, train_loss: 0.4338\n",
            "39/75, train_loss: 0.5224\n",
            "40/75, train_loss: 0.4864\n",
            "41/75, train_loss: 0.5974\n",
            "42/75, train_loss: 0.4168\n",
            "43/75, train_loss: 0.4526\n",
            "44/75, train_loss: 0.4489\n",
            "45/75, train_loss: 0.4507\n",
            "46/75, train_loss: 0.4573\n",
            "47/75, train_loss: 0.3901\n",
            "48/75, train_loss: 0.5062\n",
            "49/75, train_loss: 0.5005\n",
            "50/75, train_loss: 0.4188\n",
            "51/75, train_loss: 0.5845\n",
            "52/75, train_loss: 0.3366\n",
            "53/75, train_loss: 0.5396\n",
            "54/75, train_loss: 0.4192\n",
            "55/75, train_loss: 0.3027\n",
            "56/75, train_loss: 0.5250\n",
            "57/75, train_loss: 0.4589\n",
            "58/75, train_loss: 0.4861\n",
            "59/75, train_loss: 0.3748\n",
            "60/75, train_loss: 0.5327\n",
            "61/75, train_loss: 0.4148\n",
            "62/75, train_loss: 0.5105\n",
            "63/75, train_loss: 0.4426\n",
            "64/75, train_loss: 0.4579\n",
            "65/75, train_loss: 0.4796\n",
            "66/75, train_loss: 0.3696\n",
            "67/75, train_loss: 0.3991\n",
            "68/75, train_loss: 0.3856\n",
            "69/75, train_loss: 0.4547\n",
            "70/75, train_loss: 0.4941\n",
            "71/75, train_loss: 0.4291\n",
            "72/75, train_loss: 0.3915\n",
            "73/75, train_loss: 0.4468\n",
            "74/75, train_loss: 0.4135\n",
            "75/75, train_loss: 0.4927\n",
            "epoch 103 average loss: 0.4593\n",
            "current epoch: 103 current mean dice: 0.7883\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 104/300\n",
            "1/75, train_loss: 0.4962\n",
            "2/75, train_loss: 0.4133\n",
            "3/75, train_loss: 0.4757\n",
            "4/75, train_loss: 0.5098\n",
            "5/75, train_loss: 0.4710\n",
            "6/75, train_loss: 0.4041\n",
            "7/75, train_loss: 0.3402\n",
            "8/75, train_loss: 0.3821\n",
            "9/75, train_loss: 0.4822\n",
            "10/75, train_loss: 0.3859\n",
            "11/75, train_loss: 0.3836\n",
            "12/75, train_loss: 0.5196\n",
            "13/75, train_loss: 0.5113\n",
            "14/75, train_loss: 0.4626\n",
            "15/75, train_loss: 0.4968\n",
            "16/75, train_loss: 0.3438\n",
            "17/75, train_loss: 0.4637\n",
            "18/75, train_loss: 0.2608\n",
            "19/75, train_loss: 0.5210\n",
            "20/75, train_loss: 0.2654\n",
            "21/75, train_loss: 0.5560\n",
            "22/75, train_loss: 0.5503\n",
            "23/75, train_loss: 0.4591\n",
            "24/75, train_loss: 0.5334\n",
            "25/75, train_loss: 0.4494\n",
            "26/75, train_loss: 0.5012\n",
            "27/75, train_loss: 0.3670\n",
            "28/75, train_loss: 0.4307\n",
            "29/75, train_loss: 0.4761\n",
            "30/75, train_loss: 0.4098\n",
            "31/75, train_loss: 0.4841\n",
            "32/75, train_loss: 0.4772\n",
            "33/75, train_loss: 0.4212\n",
            "34/75, train_loss: 0.4635\n",
            "35/75, train_loss: 0.4984\n",
            "36/75, train_loss: 0.5158\n",
            "37/75, train_loss: 0.4399\n",
            "38/75, train_loss: 0.4891\n",
            "39/75, train_loss: 0.5265\n",
            "40/75, train_loss: 0.4272\n",
            "41/75, train_loss: 0.5504\n",
            "42/75, train_loss: 0.3752\n",
            "43/75, train_loss: 0.3803\n",
            "44/75, train_loss: 0.4197\n",
            "45/75, train_loss: 0.5293\n",
            "46/75, train_loss: 0.4509\n",
            "47/75, train_loss: 0.4783\n",
            "48/75, train_loss: 0.4481\n",
            "49/75, train_loss: 0.2869\n",
            "50/75, train_loss: 0.4195\n",
            "51/75, train_loss: 0.5008\n",
            "52/75, train_loss: 0.6024\n",
            "53/75, train_loss: 0.3997\n",
            "54/75, train_loss: 0.5697\n",
            "55/75, train_loss: 0.4932\n",
            "56/75, train_loss: 0.5208\n",
            "57/75, train_loss: 0.4001\n",
            "58/75, train_loss: 0.4458\n",
            "59/75, train_loss: 0.4120\n",
            "60/75, train_loss: 0.4243\n",
            "61/75, train_loss: 0.5400\n",
            "62/75, train_loss: 0.4837\n",
            "63/75, train_loss: 0.4264\n",
            "64/75, train_loss: 0.4752\n",
            "65/75, train_loss: 0.3130\n",
            "66/75, train_loss: 0.4593\n",
            "67/75, train_loss: 0.4640\n",
            "68/75, train_loss: 0.5087\n",
            "69/75, train_loss: 0.5727\n",
            "70/75, train_loss: 0.4750\n",
            "71/75, train_loss: 0.5275\n",
            "72/75, train_loss: 0.4258\n",
            "73/75, train_loss: 0.3407\n",
            "74/75, train_loss: 0.5239\n",
            "75/75, train_loss: 0.4026\n",
            "epoch 104 average loss: 0.4548\n",
            "current epoch: 104 current mean dice: 0.7658\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 105/300\n",
            "1/75, train_loss: 0.5072\n",
            "2/75, train_loss: 0.4274\n",
            "3/75, train_loss: 0.6165\n",
            "4/75, train_loss: 0.4338\n",
            "5/75, train_loss: 0.4543\n",
            "6/75, train_loss: 0.4481\n",
            "7/75, train_loss: 0.2798\n",
            "8/75, train_loss: 0.4321\n",
            "9/75, train_loss: 0.4126\n",
            "10/75, train_loss: 0.4059\n",
            "11/75, train_loss: 0.4429\n",
            "12/75, train_loss: 0.5352\n",
            "13/75, train_loss: 0.3535\n",
            "14/75, train_loss: 0.3336\n",
            "15/75, train_loss: 0.4099\n",
            "16/75, train_loss: 0.3606\n",
            "17/75, train_loss: 0.4516\n",
            "18/75, train_loss: 0.4408\n",
            "19/75, train_loss: 0.4887\n",
            "20/75, train_loss: 0.4820\n",
            "21/75, train_loss: 0.5672\n",
            "22/75, train_loss: 0.4555\n",
            "23/75, train_loss: 0.4601\n",
            "24/75, train_loss: 0.6063\n",
            "25/75, train_loss: 0.5213\n",
            "26/75, train_loss: 0.2993\n",
            "27/75, train_loss: 0.5555\n",
            "28/75, train_loss: 0.4789\n",
            "29/75, train_loss: 0.4020\n",
            "30/75, train_loss: 0.4014\n",
            "31/75, train_loss: 0.3871\n",
            "32/75, train_loss: 0.4980\n",
            "33/75, train_loss: 0.4474\n",
            "34/75, train_loss: 0.3775\n",
            "35/75, train_loss: 0.4293\n",
            "36/75, train_loss: 0.4781\n",
            "37/75, train_loss: 0.4491\n",
            "38/75, train_loss: 0.4366\n",
            "39/75, train_loss: 0.3837\n",
            "40/75, train_loss: 0.4522\n",
            "41/75, train_loss: 0.4402\n",
            "42/75, train_loss: 0.4188\n",
            "43/75, train_loss: 0.4301\n",
            "44/75, train_loss: 0.4907\n",
            "45/75, train_loss: 0.5528\n",
            "46/75, train_loss: 0.3086\n",
            "47/75, train_loss: 0.4367\n",
            "48/75, train_loss: 0.5186\n",
            "49/75, train_loss: 0.4691\n",
            "50/75, train_loss: 0.6298\n",
            "51/75, train_loss: 0.5635\n",
            "52/75, train_loss: 0.3563\n",
            "53/75, train_loss: 0.4427\n",
            "54/75, train_loss: 0.4072\n",
            "55/75, train_loss: 0.4538\n",
            "56/75, train_loss: 0.5046\n",
            "57/75, train_loss: 0.4148\n",
            "58/75, train_loss: 0.5067\n",
            "59/75, train_loss: 0.4463\n",
            "60/75, train_loss: 0.4288\n",
            "61/75, train_loss: 0.5069\n",
            "62/75, train_loss: 0.3306\n",
            "63/75, train_loss: 0.5069\n",
            "64/75, train_loss: 0.3665\n",
            "65/75, train_loss: 0.3671\n",
            "66/75, train_loss: 0.5448\n",
            "67/75, train_loss: 0.4620\n",
            "68/75, train_loss: 0.3921\n",
            "69/75, train_loss: 0.3601\n",
            "70/75, train_loss: 0.4082\n",
            "71/75, train_loss: 0.5177\n",
            "72/75, train_loss: 0.4173\n",
            "73/75, train_loss: 0.4557\n",
            "74/75, train_loss: 0.5014\n",
            "75/75, train_loss: 0.4862\n",
            "epoch 105 average loss: 0.4486\n",
            "current epoch: 105 current mean dice: 0.7449\n",
            "best mean dice: 0.8300 at epoch: 91\n",
            "----------\n",
            "epoch 106/300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mu4687akRh6t",
        "outputId": "c765229a-cf7e-4241-a97b-10db1d74c47f"
      },
      "source": [
        "print(\n",
        "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
        "    f\"at epoch: {best_metric_epoch}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train completed, best_metric: 0.4870 at epoch: 88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "MfmOFhx3RkXG",
        "outputId": "b96919b5-3c43-4b01-e4a6-56cd64f2f73a"
      },
      "source": [
        "plt.figure(\"train\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val Mean Dice\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVH7bfJdRndE"
      },
      "source": [
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(root_dir, \"best_metric_model.pth\")))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, val_data in enumerate(val_loader):\n",
        "        roi_size = (128, 128, 64)\n",
        "        sw_batch_size = 4\n",
        "        val_outputs = sliding_window_inference(\n",
        "            val_data[\"image\"].to(device), roi_size, sw_batch_size, model\n",
        "        )\n",
        "        # plot the slice [:, :, 80]\n",
        "        plt.figure(\"check\", (18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(val_data[\"image\"][0, 0, :, :, 40], cmap=\"gray\")\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f\"label {i}\")\n",
        "        plt.imshow(val_data[\"label\"][0, 0, :, :, 40])\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f\"output {i}\")\n",
        "        plt.imshow(torch.argmax(\n",
        "            val_outputs, dim=1).detach().cpu()[0, :, :, 40])\n",
        "        plt.show()\n",
        "        if i == 2:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8qJSwyquC5Z"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY53dseZl77J"
      },
      "source": [
        "val_org_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Spacingd(keys=[\"image\"], pixdim=(\n",
        "             2, 1.62, 1.62), mode=\"bilinear\"),\n",
        "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=-80, a_max=305,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\"], source_key=\"image\"),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_org_ds = Dataset(\n",
        "    data=val_files, transform=val_org_transforms)\n",
        "val_org_loader = DataLoader(val_org_ds, batch_size=1, num_workers=4)\n",
        "\n",
        "post_transforms = Compose([\n",
        "    EnsureTyped(keys=\"pred\"),\n",
        "    Invertd(\n",
        "        keys=\"pred\",\n",
        "        transform=val_org_transforms,\n",
        "        orig_keys=\"image\",\n",
        "        meta_keys=\"pred_meta_dict\",\n",
        "        orig_meta_keys=\"image_meta_dict\",\n",
        "        meta_key_postfix=\"meta_dict\",\n",
        "        nearest_interp=False,\n",
        "        to_tensor=True,\n",
        "    ),\n",
        "    AsDiscreted(keys=\"pred\", argmax=True, to_onehot=True, n_classes=4),\n",
        "    AsDiscreted(keys=\"label\", to_onehot=True, n_classes=4),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui15Mox7vWEI"
      },
      "source": [
        "##Write code to save predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj-2wOZ0l3xm"
      },
      "source": [
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(root_dir, \"best_metric_model.pth\")))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for val_data in val_org_loader:\n",
        "        val_inputs = val_data[\"image\"].to(device)\n",
        "        roi_size = (128, 128, 64)\n",
        "        sw_batch_size = 4\n",
        "        val_data[\"pred\"] = sliding_window_inference(\n",
        "            val_inputs, roi_size, sw_batch_size, model)\n",
        "        val_data = [post_transforms(i) for i in decollate_batch(val_data)]\n",
        "        print(val_data['label'].shape,val_data['pred'].shape)\n",
        "        # val_outputs, val_labels = from_engine([\"pred\", \"label\"])(val_data)\n",
        "        # compute metric for current iteration\n",
        "        # dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "    # aggregate the final mean dice result\n",
        "    metric_org = dice_metric.aggregate().item()\n",
        "    # reset the status for next validation round\n",
        "    dice_metric.reset()\n",
        "\n",
        "print(\"Metric on original image spacing: \", metric_org)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJU3VlhSvQQX"
      },
      "source": [
        "#Extra"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7js6s6z2e4R"
      },
      "source": [
        "tmp=0\n",
        "model.to('cuda')\n",
        "with torch.no_grad():\n",
        "    for batch in data.train_dataloader():\n",
        "        inputs = batch['image'][tio.DATA].to(model.device)\n",
        "        # print(batch['label'][].shape)\n",
        "        labels = model.net(inputs).argmax(dim=1, keepdim=True).cpu()\n",
        "        for i in range(len(inputs)):\n",
        "            break\n",
        "        if tmp==0:\n",
        "          break\n",
        "        tmp+=1   \n",
        "batch_subjects = tio.utils.get_subjects_from_batch(batch)\n",
        "tio.utils.add_images_from_batch(batch_subjects, labels, tio.LabelMap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMirFybS2j3u"
      },
      "source": [
        "for subject in batch_subjects:\n",
        "    subject.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4EuQOizJTXU",
        "outputId": "e37b1500-44f1-4de4-8892-b9d10360733e"
      },
      "source": [
        "subject['label']['data'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 88, 512, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLS00GQAW3y4"
      },
      "source": [
        "fig, axes = plt.subplots(6, 10, figsize=(20, 20))\n",
        "# for channel in subject_a['t1'].numpy():\n",
        "for ax, im in zip(axes.flatten(), subject['prediction']['data'][0]):\n",
        "    # print(np.min(im.numpy()))\n",
        "    ax.imshow(im,cmap='gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkE8mA17XA3z"
      },
      "source": [
        "fig, axes = plt.subplots(6, 10, figsize=(20, 20))\n",
        "# for channel in subject_a['t1'].numpy():\n",
        "for ax, im in zip(axes.flatten(), subject['prediction']['data'][0]):\n",
        "    ax.imshow(im.squeeze(), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}